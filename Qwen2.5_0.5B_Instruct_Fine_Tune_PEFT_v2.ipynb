{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-22T07:15:33.840155Z","iopub.execute_input":"2024-11-22T07:15:33.841058Z","iopub.status.idle":"2024-11-22T07:16:07.149069Z","shell.execute_reply.started":"2024-11-22T07:15:33.841012Z","shell.execute_reply":"2024-11-22T07:16:07.148022Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-11-22T07:16:07.151163Z","iopub.execute_input":"2024-11-22T07:16:07.151550Z","iopub.status.idle":"2024-11-22T07:16:14.189007Z","shell.execute_reply.started":"2024-11-22T07:16:07.151510Z","shell.execute_reply":"2024-11-22T07:16:14.187926Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-11-22T07:16:14.190334Z","iopub.execute_input":"2024-11-22T07:16:14.190678Z","iopub.status.idle":"2024-11-22T07:16:14.197587Z","shell.execute_reply.started":"2024-11-22T07:16:14.190648Z","shell.execute_reply":"2024-11-22T07:16:14.196740Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'Qwen/Qwen2.5-0.5B-Instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-22T07:16:14.199428Z","iopub.execute_input":"2024-11-22T07:16:14.199712Z","iopub.status.idle":"2024-11-22T07:16:14.208713Z","shell.execute_reply.started":"2024-11-22T07:16:14.199686Z","shell.execute_reply":"2024-11-22T07:16:14.207842Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-11-22T07:16:14.209761Z","iopub.execute_input":"2024-11-22T07:16:14.210125Z","iopub.status.idle":"2024-11-22T07:16:14.220157Z","shell.execute_reply.started":"2024-11-22T07:16:14.210066Z","shell.execute_reply":"2024-11-22T07:16:14.219484Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:14.221227Z","iopub.execute_input":"2024-11-22T07:16:14.221469Z","iopub.status.idle":"2024-11-22T07:16:16.628415Z","shell.execute_reply.started":"2024-11-22T07:16:14.221444Z","shell.execute_reply":"2024-11-22T07:16:16.627536Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 896)\n    (layers): ModuleList(\n      (0-23): 24 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=896, out_features=896, bias=True)\n          (k_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n          (v_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n          (o_proj): Linear4bit(in_features=896, out_features=896, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n          (up_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n          (down_proj): Linear4bit(in_features=4864, out_features=896, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:16.629665Z","iopub.execute_input":"2024-11-22T07:16:16.630500Z","iopub.status.idle":"2024-11-22T07:16:16.637462Z","shell.execute_reply.started":"2024-11-22T07:16:16.630455Z","shell.execute_reply":"2024-11-22T07:16:16.636561Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 315119488\nTrainable parameters : 136178560\nTrainable percentage: 43.21%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:16.638647Z","iopub.execute_input":"2024-11-22T07:16:16.638903Z","iopub.status.idle":"2024-11-22T07:16:17.055987Z","shell.execute_reply.started":"2024-11-22T07:16:16.638877Z","shell.execute_reply":"2024-11-22T07:16:17.055290Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'yahma/alpaca-cleaned'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:17.057162Z","iopub.execute_input":"2024-11-22T07:16:17.057519Z","iopub.status.idle":"2024-11-22T07:16:17.062006Z","shell.execute_reply.started":"2024-11-22T07:16:17.057480Z","shell.execute_reply":"2024-11-22T07:16:17.061139Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 512","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:17.064888Z","iopub.execute_input":"2024-11-22T07:16:17.065216Z","iopub.status.idle":"2024-11-22T07:16:17.072977Z","shell.execute_reply.started":"2024-11-22T07:16:17.065168Z","shell.execute_reply":"2024-11-22T07:16:17.072055Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:17.073952Z","iopub.execute_input":"2024-11-22T07:16:17.074258Z","iopub.status.idle":"2024-11-22T07:16:18.574262Z","shell.execute_reply.started":"2024-11-22T07:16:17.074218Z","shell.execute_reply":"2024-11-22T07:16:18.573422Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.575323Z","iopub.execute_input":"2024-11-22T07:16:18.575596Z","iopub.status.idle":"2024-11-22T07:16:18.582377Z","shell.execute_reply.started":"2024-11-22T07:16:18.575569Z","shell.execute_reply":"2024-11-22T07:16:18.581586Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.583387Z","iopub.execute_input":"2024-11-22T07:16:18.583641Z","iopub.status.idle":"2024-11-22T07:16:18.605881Z","shell.execute_reply.started":"2024-11-22T07:16:18.583615Z","shell.execute_reply":"2024-11-22T07:16:18.605214Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.606787Z","iopub.execute_input":"2024-11-22T07:16:18.607040Z","iopub.status.idle":"2024-11-22T07:16:18.612955Z","shell.execute_reply.started":"2024-11-22T07:16:18.607015Z","shell.execute_reply":"2024-11-22T07:16:18.612034Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.613932Z","iopub.execute_input":"2024-11-22T07:16:18.614229Z","iopub.status.idle":"2024-11-22T07:16:18.620865Z","shell.execute_reply.started":"2024-11-22T07:16:18.614188Z","shell.execute_reply":"2024-11-22T07:16:18.620155Z"}},"outputs":[{"name":"stdout","text":"['output', 'input', 'instruction']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.621845Z","iopub.execute_input":"2024-11-22T07:16:18.622167Z","iopub.status.idle":"2024-11-22T07:16:18.630011Z","shell.execute_reply.started":"2024-11-22T07:16:18.622130Z","shell.execute_reply":"2024-11-22T07:16:18.629145Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  instruction = examples['instruction']\n  input = examples['input']\n  output = examples['output']\n  \n  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.631237Z","iopub.execute_input":"2024-11-22T07:16:18.631485Z","iopub.status.idle":"2024-11-22T07:16:18.639040Z","shell.execute_reply.started":"2024-11-22T07:16:18.631460Z","shell.execute_reply":"2024-11-22T07:16:18.638350Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.640042Z","iopub.execute_input":"2024-11-22T07:16:18.640322Z","iopub.status.idle":"2024-11-22T07:16:18.658652Z","shell.execute_reply.started":"2024-11-22T07:16:18.640297Z","shell.execute_reply":"2024-11-22T07:16:18.657949Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"cZya4tPEWUc9","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.659669Z","iopub.execute_input":"2024-11-22T07:16:18.659977Z","iopub.status.idle":"2024-11-22T07:16:18.665674Z","shell.execute_reply.started":"2024-11-22T07:16:18.659951Z","shell.execute_reply":"2024-11-22T07:16:18.664990Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.666791Z","iopub.execute_input":"2024-11-22T07:16:18.667321Z","iopub.status.idle":"2024-11-22T07:16:18.677750Z","shell.execute_reply.started":"2024-11-22T07:16:18.667280Z","shell.execute_reply":"2024-11-22T07:16:18.676605Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:18.679005Z","iopub.execute_input":"2024-11-22T07:16:18.679347Z","iopub.status.idle":"2024-11-22T07:16:27.688295Z","shell.execute_reply.started":"2024-11-22T07:16:18.679306Z","shell.execute_reply":"2024-11-22T07:16:27.687117Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db68484b50354c5a8b6b1bf8728f5618"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.689810Z","iopub.execute_input":"2024-11-22T07:16:27.690216Z","iopub.status.idle":"2024-11-22T07:16:27.696399Z","shell.execute_reply.started":"2024-11-22T07:16:27.690174Z","shell.execute_reply":"2024-11-22T07:16:27.695518Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.697483Z","iopub.execute_input":"2024-11-22T07:16:27.697976Z","iopub.status.idle":"2024-11-22T07:16:27.773075Z","shell.execute_reply.started":"2024-11-22T07:16:27.697927Z","shell.execute_reply":"2024-11-22T07:16:27.772133Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.774077Z","iopub.execute_input":"2024-11-22T07:16:27.774435Z","iopub.status.idle":"2024-11-22T07:16:27.785843Z","shell.execute_reply.started":"2024-11-22T07:16:27.774408Z","shell.execute_reply":"2024-11-22T07:16:27.785024Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.786925Z","iopub.execute_input":"2024-11-22T07:16:27.787325Z","iopub.status.idle":"2024-11-22T07:16:27.811437Z","shell.execute_reply.started":"2024-11-22T07:16:27.787287Z","shell.execute_reply":"2024-11-22T07:16:27.810729Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n1  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n2  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n3  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n4  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.812359Z","iopub.execute_input":"2024-11-22T07:16:27.812677Z","iopub.status.idle":"2024-11-22T07:16:27.817597Z","shell.execute_reply.started":"2024-11-22T07:16:27.812645Z","shell.execute_reply":"2024-11-22T07:16:27.816749Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|im_end|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.818715Z","iopub.execute_input":"2024-11-22T07:16:27.818983Z","iopub.status.idle":"2024-11-22T07:16:27.829179Z","shell.execute_reply.started":"2024-11-22T07:16:27.818956Z","shell.execute_reply":"2024-11-22T07:16:27.828164Z"}},"outputs":[{"name":"stdout","text":"[38214, 374, 458, 7600, 429, 16555, 264, 3383, 11, 34426, 448, 458, 1946, 429, 5707, 4623, 2266, 13, 9645, 264, 2033, 429, 34901, 44595, 279, 1681, 382, 14374, 29051, 510, 2082, 55856, 279, 2661, 32794, 323, 10542, 1181, 1887, 6912, 382, 14374, 5571, 510, 11613, 19241, 36341, 3556, 304, 264, 13753, 7579, 26266, 77, 3036, 14589, 358, 1410, 537, 5821, 2176, 1699, 3036, 387, 825, 62765, 11, 1293, 358, 14638, 1699, 3036, 6966, 1495, 825, 438, 3041, 438, 358, 1410, 1699, 1249, 1380, 432, 29180, 304, 279, 1212, 73089, 17882, 77, 1699, 12209, 3867, 279, 1008, 11, 438, 1101, 438, 6624, 26266, 77, 3036, 3432, 8365, 279, 2664, 3717, 26266, 77, 17949, 432, 572, 16359, 88, 323, 4829, 9850, 17882, 77, 26733, 438, 369, 429, 279, 12299, 1052, 1699, 55468, 23704, 1105, 2167, 911, 279, 1852, 26266, 88230, 19241, 429, 6556, 18308, 10962, 1699, 641, 10901, 902, 3019, 1030, 8185, 10792, 3691, 7110, 77, 11908, 11, 358, 2115, 279, 1156, 369, 2441, 1899, 14771, 77, 28074, 14063, 1246, 1616, 11508, 389, 311, 1616, 26266, 77, 40, 92662, 421, 358, 1265, 3512, 2525, 1182, 7110, 77, 1699, 40, 4880, 387, 11629, 419, 448, 264, 30138, 1699, 49882, 60652, 16639, 323, 16639, 16085, 7190, 77, 11613, 19241, 36341, 3556, 304, 264, 7579, 11, 323, 358, 2293, 59, 77, 40, 3867, 279, 825, 2686, 30696, 553, 26266, 77, 3036, 429, 702, 1865, 678, 279, 6672, 382, 14374, 5949, 510, 785, 1887, 6912, 315, 279, 32794, 374, 279, 12650, 315, 3259, 11454, 323, 279, 5421, 315, 1846, 11454, 389, 825, 594, 2272, 13, 576, 18601, 374, 16601, 448, 264, 5480, 1948, 1378, 12716, 323, 13653, 39911, 279, 825, 2686, 30696, 11, 892, 13653, 20816, 862, 2272, 3139, 13, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.833803Z","iopub.execute_input":"2024-11-22T07:16:27.834054Z","iopub.status.idle":"2024-11-22T07:16:27.840318Z","shell.execute_reply.started":"2024-11-22T07:16:27.834029Z","shell.execute_reply":"2024-11-22T07:16:27.839491Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.841443Z","iopub.execute_input":"2024-11-22T07:16:27.841720Z","iopub.status.idle":"2024-11-22T07:16:27.850952Z","shell.execute_reply.started":"2024-11-22T07:16:27.841695Z","shell.execute_reply":"2024-11-22T07:16:27.850142Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.851852Z","iopub.execute_input":"2024-11-22T07:16:27.852114Z","iopub.status.idle":"2024-11-22T07:16:27.862765Z","shell.execute_reply.started":"2024-11-22T07:16:27.852067Z","shell.execute_reply":"2024-11-22T07:16:27.862035Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.863788Z","iopub.execute_input":"2024-11-22T07:16:27.864035Z","iopub.status.idle":"2024-11-22T07:16:27.871769Z","shell.execute_reply.started":"2024-11-22T07:16:27.864010Z","shell.execute_reply":"2024-11-22T07:16:27.871130Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.872725Z","iopub.execute_input":"2024-11-22T07:16:27.872976Z","iopub.status.idle":"2024-11-22T07:16:27.882958Z","shell.execute_reply.started":"2024-11-22T07:16:27.872952Z","shell.execute_reply":"2024-11-22T07:16:27.882235Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:27.883900Z","iopub.execute_input":"2024-11-22T07:16:27.884279Z","iopub.status.idle":"2024-11-22T07:16:28.444714Z","shell.execute_reply.started":"2024-11-22T07:16:27.884217Z","shell.execute_reply":"2024-11-22T07:16:28.443754Z"}},"outputs":[{"name":"stdout","text":"trainable params: 35,192,832 || all params: 529,225,600 || trainable%: 6.6499\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:28.445881Z","iopub.execute_input":"2024-11-22T07:16:28.446231Z","iopub.status.idle":"2024-11-22T07:16:28.461493Z","shell.execute_reply.started":"2024-11-22T07:16:28.446201Z","shell.execute_reply":"2024-11-22T07:16:28.460559Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 896)\n    (layers): ModuleList(\n      (0-23): 24 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=896, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=896, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=128, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=128, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=896, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=896, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=4864, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=4864, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4864, out_features=896, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4864, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=896, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:28.462543Z","iopub.execute_input":"2024-11-22T07:16:28.462819Z","iopub.status.idle":"2024-11-22T07:16:28.482057Z","shell.execute_reply.started":"2024-11-22T07:16:28.462789Z","shell.execute_reply":"2024-11-22T07:16:28.481261Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 350312320\nTrainable parameters : 35192832\nTrainable percentage: 10.05%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:28.482956Z","iopub.execute_input":"2024-11-22T07:16:28.483243Z","iopub.status.idle":"2024-11-22T07:16:28.491138Z","shell.execute_reply.started":"2024-11-22T07:16:28.483214Z","shell.execute_reply":"2024-11-22T07:16:28.490293Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 4\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:28.492634Z","iopub.execute_input":"2024-11-22T07:16:28.492909Z","iopub.status.idle":"2024-11-22T07:16:28.528488Z","shell.execute_reply.started":"2024-11-22T07:16:28.492884Z","shell.execute_reply":"2024-11-22T07:16:28.527612Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov22_07-16-28_4660872c9ef8,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=4,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:28.529721Z","iopub.execute_input":"2024-11-22T07:16:28.530080Z","iopub.status.idle":"2024-11-22T07:16:29.594233Z","shell.execute_reply.started":"2024-11-22T07:16:28.530040Z","shell.execute_reply":"2024-11-22T07:16:29.593245Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7b16162d7c70>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:16:29.595411Z","iopub.execute_input":"2024-11-22T07:16:29.595691Z","iopub.status.idle":"2024-11-22T07:34:04.889558Z","shell.execute_reply.started":"2024-11-22T07:16:29.595663Z","shell.execute_reply":"2024-11-22T07:34:04.888661Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 4\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 4\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 35,192,832\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113913099997161, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d683d279467e4055b492e9dc63179d59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241122_071631-yz9luiqj</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/yz9luiqj' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/yz9luiqj' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/yz9luiqj</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 17:26, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>1.892700</td>\n      <td>1.731238</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.529700</td>\n      <td>1.415069</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.340800</td>\n      <td>1.308879</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.262500</td>\n      <td>1.282678</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.232000</td>\n      <td>1.276315</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.253200</td>\n      <td>1.271406</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.236300</td>\n      <td>1.268887</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.229100</td>\n      <td>1.267584</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.249900</td>\n      <td>1.267091</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.240600</td>\n      <td>1.266981</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=1.3466674613952636, metrics={'train_runtime': 1054.8942, 'train_samples_per_second': 3.033, 'train_steps_per_second': 0.19, 'total_flos': 4210200831590400.0, 'train_loss': 1.3466674613952636, 'epoch': 0.35555555555555557})"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:34:04.890679Z","iopub.execute_input":"2024-11-22T07:34:04.890944Z","iopub.status.idle":"2024-11-22T07:34:27.856965Z","shell.execute_reply.started":"2024-11-22T07:34:04.890917Z","shell.execute_reply":"2024-11-22T07:34:27.855937Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 00:22]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 1.2669814825057983, 'eval_runtime': 22.954, 'eval_samples_per_second': 8.713, 'eval_steps_per_second': 2.178, 'epoch': 0.35555555555555557}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:34:27.858252Z","iopub.execute_input":"2024-11-22T07:34:27.858607Z","iopub.status.idle":"2024-11-22T07:34:28.748022Z","shell.execute_reply.started":"2024-11-22T07:34:27.858566Z","shell.execute_reply":"2024-11-22T07:34:28.747059Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:34:28.749378Z","iopub.execute_input":"2024-11-22T07:34:28.749752Z","iopub.status.idle":"2024-11-22T07:34:29.126498Z","shell.execute_reply.started":"2024-11-22T07:34:28.749711Z","shell.execute_reply":"2024-11-22T07:34:29.125653Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:34:29.127566Z","iopub.execute_input":"2024-11-22T07:34:29.127854Z","iopub.status.idle":"2024-11-22T07:34:29.145802Z","shell.execute_reply.started":"2024-11-22T07:34:29.127825Z","shell.execute_reply":"2024-11-22T07:34:29.145134Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:34:29.146953Z","iopub.execute_input":"2024-11-22T07:34:29.147310Z","iopub.status.idle":"2024-11-22T07:34:29.789360Z","shell.execute_reply.started":"2024-11-22T07:34:29.147271Z","shell.execute_reply":"2024-11-22T07:34:29.788510Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:34:29.790358Z","iopub.execute_input":"2024-11-22T07:34:29.790624Z","iopub.status.idle":"2024-11-22T07:34:31.709979Z","shell.execute_reply.started":"2024-11-22T07:34:29.790597Z","shell.execute_reply":"2024-11-22T07:34:31.709148Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/model.safetensors\nInstantiating Qwen2ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645\n}\n\nAll model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-0.5B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    151645,\n    151643\n  ],\n  \"pad_token_id\": 151643,\n  \"repetition_penalty\": 1.1,\n  \"temperature\": 0.7,\n  \"top_k\": 20,\n  \"top_p\": 0.8\n}\n\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 896)\n    (layers): ModuleList(\n      (0-23): 24 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=896, out_features=896, bias=True)\n          (k_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n          (v_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n          (o_proj): Linear4bit(in_features=896, out_features=896, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n          (up_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n          (down_proj): Linear4bit(in_features=4864, out_features=896, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:34:31.710962Z","iopub.execute_input":"2024-11-22T07:34:31.711242Z","iopub.status.idle":"2024-11-22T07:34:31.720376Z","shell.execute_reply.started":"2024-11-22T07:34:31.711215Z","shell.execute_reply":"2024-11-22T07:34:31.719550Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 315119488\nTrainable parameters : 136178560\nTrainable percentage: 43.21%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:34:31.721360Z","iopub.execute_input":"2024-11-22T07:34:31.721614Z","iopub.status.idle":"2024-11-22T07:34:31.741378Z","shell.execute_reply.started":"2024-11-22T07:34:31.721589Z","shell.execute_reply":"2024-11-22T07:34:31.740562Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(151936, 896)\n        (layers): ModuleList(\n          (0-23): 24 x Qwen2DecoderLayer(\n            (self_attn): Qwen2SdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=896, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=896, bias=False)\n                  (default): Linear(in_features=64, out_features=896, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=128, bias=False)\n                  (default): Linear(in_features=64, out_features=128, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=128, bias=False)\n                  (default): Linear(in_features=64, out_features=128, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=896, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=896, bias=False)\n                  (default): Linear(in_features=64, out_features=896, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): Qwen2RotaryEmbedding()\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=4864, bias=False)\n                  (default): Linear(in_features=64, out_features=4864, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=4864, bias=False)\n                  (default): Linear(in_features=64, out_features=4864, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4864, out_features=896, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4864, out_features=64, bias=False)\n                  (default): Linear(in_features=4864, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=896, bias=False)\n                  (default): Linear(in_features=64, out_features=896, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((896,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:34:31.742474Z","iopub.execute_input":"2024-11-22T07:34:31.742797Z","iopub.status.idle":"2024-11-22T07:34:31.762725Z","shell.execute_reply.started":"2024-11-22T07:34:31.742760Z","shell.execute_reply":"2024-11-22T07:34:31.762000Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 385505152\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## 13 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      '',\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:45:31.361669Z","iopub.execute_input":"2024-11-22T07:45:31.362036Z","iopub.status.idle":"2024-11-22T07:45:31.368233Z","shell.execute_reply.started":"2024-11-22T07:45:31.362002Z","shell.execute_reply":"2024-11-22T07:45:31.367343Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"def post_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      '',\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:45:33.819708Z","iopub.execute_input":"2024-11-22T07:45:33.820068Z","iopub.status.idle":"2024-11-22T07:45:33.826037Z","shell.execute_reply.started":"2024-11-22T07:45:33.820034Z","shell.execute_reply":"2024-11-22T07:45:33.825149Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T07:45:36.001475Z","iopub.execute_input":"2024-11-22T07:45:36.001813Z","iopub.status.idle":"2024-11-22T07:45:36.008682Z","shell.execute_reply.started":"2024-11-22T07:45:36.001784Z","shell.execute_reply":"2024-11-22T07:45:36.007784Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:07:13.368989Z","iopub.execute_input":"2024-11-22T08:07:13.369276Z","iopub.status.idle":"2024-11-22T08:09:37.816798Z","shell.execute_reply.started":"2024-11-22T08:07:13.369248Z","shell.execute_reply":"2024-11-22T08:09:37.815896Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Think of   |  completes the request.  ### Instruction: Think of \nan example of a moral dilemma and explain why it    |  an example of a moral dilemma and explain why it  \nis difficult to make a decision.  ### Input:   ###  |  is difficult to make a decision.  ### Input:   ###\nResponse: Certainly, I can provide an example of a  |  Response: Certainly, I can provide an example of a\nmoral dilemma. One example is the decision of       |  moral dilemma. One example is the decision of     \nwhether to go to work or to go to the gym. The      |  whether to tell a lie or not.   A lie is a        \ndecision is difficult because working at a job can  |  deception that is intended to deceive others, and \nlead to financial instability, stress, and lack of  |  it is a form of deception that is considered      \ntime for personal and family time. On the other     |  unethical. On the other hand, telling a lie can be\nhand, going to the gym can lead to physical and     |  seen as a form of honesty, as it allows the person\nmental health benefits, but it also requires time   |  to deceive others without causing harm.           \nand effort to maintain a healthy lifestyle.         |  Therefore, it is difficult to make a decision     \nTherefore, it is difficult to make a decision       |  between telling a lie or not, as it depends on the\nbetween going to work or going to the gym because   |  context and the situation. It is important to     \nit depends on individual values and priorities. It  |  consider the consequences of each option and weigh\nis important to consider the consequences of each   |  the pros and cons before making a decision.   In  \ndecision and make a decision that aligns with       |  this case, the decision of whether to tell a lie  \none's values and goals.   ### Response: I can       |  or not is a moral dilemma because it involves     \nprovide an example of a moral dilemma. One example  |  making a choice between two actions that have     \nis the decision of whether to go to work or to go   |  different consequences. It is important to        \nto the gym. The decision is difficult because       |  consider the ethical implications of each option  \nworking at a job can lead to financial              |  and make a decision based on the best course of   \ninstability, stress, and lack of time for personal  |  action.   Therefore, it is difficult to make a    \nand family time. On the other hand, going to the    |  decision between telling a lie or not, as it      \ngym can lead to physical and mental health          |  depends on the context and the situation. It is   \nbenefits, but it also requires time and effort to   |  important to consider the ethical implications of \nmaintain a healthy lifestyle. Therefore, it is      |  each option and make a decision based on the best \ndifficult to make a decision between going to work  |  course of action.   In this case, the decision of \nor going to the gym because it depends on           |  whether to tell a lie or not is a moral dilemma   \nindividual values and priorities. It is important   |  because it involves making a choice between two   \nto consider the consequences of each decision and   |  actions that have different consequences. It is   \nmake a decision that aligns with one's values and   |  important to consider the ethical implications of \ngoals.   ### Response: I can provide an example of  |  each option and make a decision based on the best \na moral dilemma. One example is the decision of     |  course of action.   Therefore, it is difficult to \nwhether to go to work or to go to the gym. The      |  make a decision between telling a lie or not, as  \ndecision is difficult because working at a job can  |  it depends on the context and the situation. It is\nlead to financial instability, stress, and lack of  |  important to consider the ethical implications of \ntime for personal and family time. On the other     |  each option and make a decision based on the best \nhand, going to the gym can lead to physical and     |  course of action.   In this case, the decision of \nmental health benefits, but it also requires time   |  whether to tell a lie or not is a moral dilemma   \nand effort to maintain a healthy lifestyle.         |  because it involves making a choice between two   \nTherefore, it is difficult to make a decision       |  actions that have different consequences. It is   \nbetween going to work or going to the gym because   |  important to consider the ethical implications of \nit depends on individual values and priorities. It  |  each option and make a decision based on the best \nis important to consider the consequences of each   |  course of action.   Therefore, it is difficult to \ndecision and make a decision that aligns with       |  make a decision between telling a lie or not, as  \none's values and goals.   ### Response: I can       |  it depends on the context and the situation. It is\nprovide an example of a moral dilemma. One example  |  important to consider the ethical implications of \nis the decision of whether to go to work or to go   |  each option and make a decision based on the best \nto the gym. The decision is difficult because       |  course of action.   In this case, the decision of \nworking at a job can lead to financial              |  whether to tell a lie or not is a moral dilemma   \ninstability, stress, and lack of time for personal  |  because it involves making a choice between two   \nand family time. On the other hand, going to the    |  actions that have different consequences. It is   \ngym can lead to physical and mental health          |  important to consider the ethical implications of \nbenefits, but it also requires time and effort to   |  each option and make a decision based on the best \nmaintain a healthy lifestyle. Therefore, it is      |  course of action.   Therefore, it is difficult to \ndifficult to make a decision between going to work  |  make a decision between telling a lie or not, as  \nor going to the gym because it depends on           |  it depends on the context and the situation. It is\nindividual values and priorities. It is important   |  important to consider the ethical implications of \nto consider the consequences of each decision and   |  each option and make a decision based on the best \nmake a decision that aligns with one's values and   |  course of action.   In this case, the decision of \ngoals.   ### Response: I can provide an example of  |  whether to tell a lie or not is a moral dilemma   \na moral dilemma. One example is the decision of     |  because it involves making a choice between two   \nwhether to go to work or to go to the gym. The      |  actions that have different consequences. It is   \ndecision is difficult because working at a job can  |  important to consider the ethical implications of \nlead to financial instability, stress, and lack of  |  each option and make a decision based on the best \ntime for personal and family time. On the other     |  course of action.   Therefore, it is difficult to \nhand, going to the gym can lead to physical and     |  make a decision between telling a lie or not, as  \nmental health benefits, but it also requires time   |  it depends on the context and the situation. It is\nand effort to maintain a healthy lifestyle.         |  important to consider the ethical implications of \nTherefore, it is difficult to make a decision       |  each option and make a decision based on the best \nbetween going to work or going to the gym because   |  course of action.   In this case, the decision of \nit depends on individual values and priorities. It  |  whether to tell a lie or not is a moral dilemma   \nis important to consider the consequences of each   |  because it involves making a choice between two   \ndecision and make a decision that aligns with       |  actions that have different consequences. It is   \none's values and goals.   ### Response: I can       |  important to consider the ethical implications of \nprovide an example of a moral dilemma. One example  |  each option and make a decision based on the best \nis the decision of whether to go to work or to go   |  course of action.   Therefore, it is difficult to \nto the gym. The decision is difficult because       |  make a decision between telling a lie or not, as  \nworking at a job can lead to financial              |  it depends on the context and the situation. It is\ninstability, stress, and lack of time for personal  |  important to consider the ethical implications of \nand family time. On the other hand, going to the    |  each option and make a decision based on the best \ngym can lead to physical and mental health          |  course of action.   In this case, the decision of \nbenefits, but it also requires time and effort to   |  whether to tell a lie or not is a moral dilemma   \nmaintain a healthy lifestyle. Therefore, it is      |  because it involves making a choice between two   \ndifficult to make a decision between going to work  |  actions that have different consequences. It is   \nor going to the gym because it depends on           |  important to consider the ethical implications of \nindividual values and priorities. It is important   |  each option and make a decision based on the best \nto consider the consequences of each decision and   |  course of action.   Therefore, it is difficult to \nmake a decision that aligns with one's values and   |  make a decision between telling a lie or not, as  \ngoals.   ### Response: I can provide an example of  |  it depends on the context and the situation. It is\na moral dilemma. One example is the decision of     |  important to consider the ethical implications of \nwhether to go to work or to go to the gym. The      |  each option and make a decision based on the best \ndecision is difficult because working at a job can  |  course of action.   In this case, the decision of \nlead to financial instability, stress, and lack of  |  whether to tell a lie or not is a moral dilemma   \ntime for personal and family time. On the other     |  because it involves making a choice between two   \nhand, going to the gym can lead to physical and     |  actions that have different consequences. It is   \nmental health benefits, but it also requires time   |  important to consider the ethical implications of \nand effort to maintain a healthy lifestyle.         |  each option and make a decision based on the best \nTherefore, it is difficult to make a decision       |  course of action.   Therefore, it is difficult to \nbetween going to work or going to the gym because   |  make a decision between telling a lie or not, as  \nit depends on individual values and priorities. It  |  it depends on the context and the situation. It is\nis important to consider the consequences of each   |  important to consider the ethical implications of \ndecision and make a decision that aligns with       |  each option and make a decision based on the best \none's values and goals.   ### Response: I can       |  course of action.   In this case, the decision of \nprovide an example of a moral dilemma. One example  |  whether to tell a lie or not is a moral dilemma   \nis the decision of whether to go to work or to go   |  because it involves making a choice between two   \nto the gym. The decision is difficult because       |  actions that have different consequences. It is   \nworking at                                          |  important to consider the ethical implications of \n                                                    |  each option and make a decision                   \n","output_type":"stream"}],"execution_count":97},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:13:46.461213Z","iopub.execute_input":"2024-11-22T08:13:46.461587Z","iopub.status.idle":"2024-11-22T08:16:08.750111Z","shell.execute_reply.started":"2024-11-22T08:13:46.461557Z","shell.execute_reply":"2024-11-22T08:16:08.749240Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Summarize  |  completes the request.  ### Instruction: Summarize\nthe importance of sleep  ### Input:   ###           |  the importance of sleep  ### Input:   ###         \nResponse: The importance of sleep is vital for      |  Response: The importance of sleep is vital for    \nmaintaining overall health and well-being. It       |  maintaining overall health and well-being. It     \nplays a crucial role in the body's ability to       |  plays a crucial role in the body's ability to     \nregulate and maintain normal physiological          |  regulate and maintain normal physiological        \nfunctions, including the production of hormones,    |  functions, including metabolism, growth, and      \nthe production of blood, and the production of      |  repair of tissues. Sleep also helps to regulate   \nneurotransmitters. Sleep also helps to regulate     |  the body's internal clock, known as the circadian \nthe body's stress response, which can lead to       |  rhythm, which regulates the body's internal clock,\nimproved mood, reduced risk of developing mental    |  known as the circadian rhythm, which regulates the\nhealth disorders, and enhanced cognitive function.  |  body's internal clock, known as the circadian     \nAdequate sleep is also essential for the            |  rhythm, which regulates the body's internal clock,\nmaintenance of physical health, including the       |  known as the circadian rhythm, which regulates the\nproduction of blood, the production of hormones,    |  body's internal clock, known as the circadian     \nand the production of neurotransmitters, which are  |  rhythm, which regulates the body's internal clock,\nvital for maintaining normal bodily functions. In   |  known as the circadian rhythm, which regulates the\nsummary, sleep is an essential component of         |  body's internal clock, known as the circadian     \noverall health and well-being.   ### Response:      |  rhythm, which regulates the body's internal clock,\nSleep is a vital component of overall health and    |  known as the circadian rhythm, which regulates the\nwell-being. It plays a crucial role in the body's   |  body's internal clock, known as the circadian     \nability to regulate and maintain normal             |  rhythm, which regulates the body's internal clock,\nphysiological functions, including the production   |  known as the circadian rhythm, which regulates the\nof hormones, the production of blood, and the       |  body's internal clock, known as the circadian     \nproduction of neurotransmitters. Sleep also helps   |  rhythm, which regulates the body's internal clock,\nto regulate the body's stress response, which can   |  known as the circadian rhythm, which regulates the\nlead to improved mood, reduced risk of developing   |  body's internal clock, known as the circadian     \nmental health disorders, and enhanced cognitive     |  rhythm, which regulates the body's internal clock,\nfunction. Adequate sleep is also essential for the  |  known as the circadian rhythm, which regulates the\nmaintenance of physical health, including the       |  body's internal clock, known as the circadian     \nproduction of blood, the production of hormones,    |  rhythm, which regulates the body's internal clock,\nand the production of neurotransmitters, which are  |  known as the circadian rhythm, which regulates the\nvital for maintaining normal bodily functions. In   |  body's internal clock, known as the circadian     \nsummary, sleep is an essential component of         |  rhythm, which regulates the body's internal clock,\noverall health and well-being.   ### Response:      |  known as the circadian rhythm, which regulates the\nSleep is an essential component of overall health   |  body's internal clock, known as the circadian     \nand well-being. It plays a crucial role in the      |  rhythm, which regulates the body's internal clock,\nbody's ability to regulate and maintain normal      |  known as the circadian rhythm, which regulates the\nphysiological functions, including the production   |  body's internal clock, known as the circadian     \nof hormones, the production of blood, and the       |  rhythm, which regulates the body's internal clock,\nproduction of neurotransmitters. Sleep also helps   |  known as the circadian rhythm, which regulates the\nto regulate the body's stress response, which can   |  body's internal clock, known as the circadian     \nlead to improved mood, reduced risk of developing   |  rhythm, which regulates the body's internal clock,\nmental health disorders, and enhanced cognitive     |  known as the circadian rhythm, which regulates the\nfunction. Adequate sleep is also essential for the  |  body's internal clock, known as the circadian     \nmaintenance of physical health, including the       |  rhythm, which regulates the body's internal clock,\nproduction of blood, the production of hormones,    |  known as the circadian rhythm, which regulates the\nand the production of neurotransmitters, which are  |  body's internal clock, known as the circadian     \nvital for maintaining normal bodily functions. In   |  rhythm, which regulates the body's internal clock,\nsummary, sleep is an essential component of         |  known as the circadian rhythm, which regulates the\noverall health and well-being.   ### Response:      |  body's internal clock, known as the circadian     \nSleep is an essential component of overall health   |  rhythm, which regulates the body's internal clock,\nand well-being. It plays a crucial role in the      |  known as the circadian rhythm, which regulates the\nbody's ability to regulate and maintain normal      |  body's internal clock, known as the circadian     \nphysiological functions, including the production   |  rhythm, which regulates the body's internal clock,\nof hormones, the production of blood, and the       |  known as the circadian rhythm, which regulates the\nproduction of neurotransmitters. Sleep also helps   |  body's internal clock, known as the circadian     \nto regulate the body's stress response, which can   |  rhythm, which regulates the body's internal clock,\nlead to improved mood, reduced risk of developing   |  known as the circadian rhythm, which regulates the\nmental health disorders, and enhanced cognitive     |  body's internal clock, known as the circadian     \nfunction. Adequate sleep is also essential for the  |  rhythm, which regulates the body's internal clock,\nmaintenance of physical health, including the       |  known as the circadian rhythm, which regulates the\nproduction of blood, the production of hormones,    |  body's internal clock, known as the circadian     \nand the production of neurotransmitters, which are  |  rhythm, which regulates the body's internal clock,\nvital for maintaining normal bodily functions. In   |  known as the circadian rhythm, which regulates the\nsummary, sleep is an essential component of         |  body's internal clock, known as the circadian     \noverall health and well-being.   ### Response:      |  rhythm, which regulates the body's internal clock,\nSleep is an essential component of overall health   |  known as the circadian rhythm, which regulates the\nand well-being. It plays a crucial role in the      |  body's internal clock, known as the circadian     \nbody's ability to regulate and maintain normal      |  rhythm, which regulates the body's internal clock,\nphysiological functions, including the production   |  known as the circadian rhythm, which regulates the\nof hormones, the production of blood, and the       |  body's internal clock, known as the circadian     \nproduction of neurotransmitters. Sleep also helps   |  rhythm, which regulates the body's internal clock,\nto regulate the body's stress response, which can   |  known as the circadian rhythm, which regulates the\nlead to improved mood, reduced risk of developing   |  body's internal clock, known as the circadian     \nmental health disorders, and enhanced cognitive     |  rhythm, which regulates the body's internal clock,\nfunction. Adequate sleep is also essential for the  |  known as the circadian rhythm, which regulates the\nmaintenance of physical health, including the       |  body's internal clock, known as the circadian     \nproduction of blood, the production of hormones,    |  rhythm, which regulates the body's internal clock,\nand the production of neurotransmitters, which are  |  known as the circadian rhythm, which regulates the\nvital for maintaining normal bodily functions. In   |  body's internal clock, known as the circadian     \nsummary, sleep is an essential component of         |  rhythm, which regulates the body's internal clock,\noverall health and well-being.   ### Response:      |  known as the circadian rhythm, which regulates the\nSleep is an essential component of overall health   |  body's internal clock, known as the circadian     \nand well-being. It plays a crucial role in the      |  rhythm, which regulates the body's internal clock,\nbody's ability to regulate and maintain normal      |  known as the circadian rhythm, which regulates the\nphysiological functions, including the production   |  body's internal clock, known as the circadian     \nof hormones, the production of blood, and the       |  rhythm, which regulates the body's internal clock,\nproduction of neurotransmitters. Sleep also helps   |  known as the circadian rhythm, which regulates the\nto regulate the body's stress response, which can   |  body's internal clock, known as the circadian     \nlead to improved mood, reduced risk of developing   |  rhythm, which regulates the body's internal clock,\nmental health disorders, and enhanced cognitive     |  known as the circadian rhythm, which regulates the\nfunction. Adequate sleep is also essential for the  |  body's internal clock, known as the circadian     \nmaintenance of physical health, including the       |  rhythm, which regulates the body's internal clock,\nproduction of blood, the production of hormones,    |  known as the circadian rhythm, which regulates the\nand the production of neurotransmitters, which are  |  body's internal clock, known as the circadian     \nvital for maintaining normal bodily functions. In   |  rhythm, which regulates the body's internal clock,\nsummary, sleep is an essential component of         |  known as the circadian rhythm, which regulates the\noverall health and well-being.   ### Response:      |  body's internal clock, known as the circadian     \nSleep is an essential component of overall health   |  rhythm, which regulates the body's internal clock,\nand well-being. It plays a crucial role in the      |  known as the circadian rhythm, which regulates the\nbody's ability to regulate and maintain normal      |  body's internal clock, known as the circadian     \nphysiological functions, including the production   |  rhythm, which regulates the body's internal clock,\nof hormones, the production of blood, and the       |  known as the circadian rhythm, which regulates the\nproduction of neurotransmitters. Sleep also helps   |  body's internal clock, known as the circadian     \nto regulate the body's stress response, which can   |  rhythm, which regulates the body                  \nlead to improved mood, reduced risk of developing   |                                                    \nmental health disorders, and enhanced cognitive     |                                                    \nfunction. Adequate sleep is also essential for the  |                                                    \nmaintenance of physical health, including the       |                                                    \nproduction of blood, the production of hormones,    |                                                    \nand the production of neurotransmitters, which are  |                                                    \nvital for maintaining normal bodily functions. In   |                                                    \nsummary, sleep is an essential component of         |                                                    \noverall health and well-being.   ### Response:      |                                                    \nSleep is an essential component of overall health   |                                                    \nand well-being. It plays a crucial role in the      |                                                    \nbody's ability to regulate and maintain normal      |                                                    \nphysiological functions, including the production   |                                                    \nof hormones, the production of blood, and the       |                                                    \nproduction of neurotransmitters. Sleep also helps   |                                                    \nto regulate the body's                              |                                                    \n","output_type":"stream"}],"execution_count":99},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:40:28.859702Z","iopub.execute_input":"2024-11-22T08:40:28.860158Z","iopub.status.idle":"2024-11-22T08:42:50.659935Z","shell.execute_reply.started":"2024-11-22T08:40:28.860110Z","shell.execute_reply":"2024-11-22T08:42:50.659110Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Explain    |  completes the request.  ### Instruction: Explain  \nthe concept of a fully connected network.  ###      |  the concept of a fully connected network.  ###    \nInput:   ### Response: A fully connected network    |  Input:   ### Response: A fully connected network  \nis a type of network where every node (or node in   |  is a type of network where every node (or node in \na network) is connected to every other node. This   |  a network) is connected to every other node. This \nmeans that there is no separation of any nodes,     |  means that there is no separation of any nodes,   \nand all nodes are interconnected with each other.   |  and all nodes are interconnected with each other. \nThis type of network is commonly used in computer   |  This type of network is often used in computer    \nnetworks, where data is sent from one node to       |  networks, where it is used to transmit data       \nanother through a series of connections. The        |  between different devices.  ### Response: A fully \nconcept of a fully connected network is essential   |  connected network is a type of network where every\nfor the functioning of computer networks, as it     |  node is connected to every other node. This means \nallows for efficient data transmission and          |  that there is no separation of any nodes, and all \ncommunication. In a fully connected network, all    |  nodes are interconnected with each other. This    \nnodes are connected to each other, and no nodes     |  type of network is often used in computer         \nare isolated from each other. This type of network  |  networks, where it is used to transmit data       \nis also used in other applications, such as in the  |  between different devices. The concept of a fully \ninternet, where data is sent from one node to       |  connected network is important in computer science\nanother through a series of connections. The        |  and networking, as it allows for efficient data   \nconcept of a fully connected network is             |  transmission and communication. However, it is    \nfundamental to the functioning of computer          |  also important to note that a fully connected     \nnetworks and other types of networks.   ###         |  network can be a complex and complex system, and  \nResponse: A fully connected network is a type of    |  it is not always possible to achieve a fully      \nnetwork where every node is connected to every      |  connected network in a practical setting. It is   \nother node, and no nodes are isolated from each     |  important to consider the trade-offs between      \nother. This type of network is commonly used in     |  connectivity and complexity when designing        \ncomputer networks, where data is sent from one      |  networks.   ### Response: A fully connected       \nnode to another through a series of connections.    |  network is a type of network where every node is  \nThe concept of a fully connected network is         |  connected to every other node. This means that    \nessential for the functioning of computer           |  there is no separation of any nodes, and all nodes\nnetworks, as it allows for efficient data           |  are interconnected with each other. This type of  \ntransmission and communication. In a fully          |  network is often used in computer networks, where \nconnected network, all nodes are connected to each  |  it is used to transmit data between different     \nother, and no nodes are isolated from each other.   |  devices. The concept of a fully connected network \nThis type of network is also used in other          |  is important in computer science and networking,  \napplications, such as in the internet, where data   |  as it allows for efficient data transmission and  \nis sent from one node to another through a series   |  communication. However, it is also important to   \nof connections. The concept of a fully connected    |  note that a fully connected network can be a      \nnetwork is fundamental to the functioning of        |  complex and complex system, and it is not always  \ncomputer networks and other types of networks.      |  possible to achieve a fully connected network in a\n### Response: A fully connected network is a type   |  practical setting. It is important to consider the\nof network where every node is connected to every   |  trade-offs between connectivity and complexity    \nother node, and no nodes are isolated from each     |  when designing networks.   ### Response: A fully  \nother. This type of network is commonly used in     |  connected network is a type of network where every\ncomputer networks, where data is sent from one      |  node is connected to every other node. This means \nnode to another through a series of connections.    |  that there is no separation of any nodes, and all \nThe concept of a fully connected network is         |  nodes are interconnected with each other. This    \nessential for the functioning of computer           |  type of network is often used in computer         \nnetworks, as it allows for efficient data           |  networks, where it is used to transmit data       \ntransmission and communication. In a fully          |  between different devices. The concept of a fully \nconnected network, all nodes are connected to each  |  connected network is important in computer science\nother, and no nodes are isolated from each other.   |  and networking, as it allows for efficient data   \nThis type of network is also used in other          |  transmission and communication. However, it is    \napplications, such as in the internet, where data   |  also important to note that a fully connected     \nis sent from one node to another through a series   |  network can be a complex and complex system, and  \nof connections. The concept of a fully connected    |  it is not always possible to achieve a fully      \nnetwork is fundamental to the functioning of        |  connected network in a practical setting. It is   \ncomputer networks and other types of networks.      |  important to consider the trade-offs between      \n### Response: A fully connected network is a type   |  connectivity and complexity when designing        \nof network where every node is connected to every   |  networks.   ### Response: A fully connected       \nother node, and no nodes are isolated from each     |  network is a type of network where every node is  \nother. This type of network is commonly used in     |  connected to every other node. This means that    \ncomputer networks, where data is sent from one      |  there is no separation of any nodes, and all nodes\nnode to another through a series of connections.    |  are interconnected with each other. This type of  \nThe concept of a fully connected network is         |  network is often used in computer networks, where \nessential for the functioning of computer           |  it is used to transmit data between different     \nnetworks, as it allows for efficient data           |  devices. The concept of a fully connected network \ntransmission and communication. In a fully          |  is important in computer science and networking,  \nconnected network, all nodes are connected to each  |  as it allows for efficient data transmission and  \nother, and no nodes are isolated from each other.   |  communication. However, it is also important to   \nThis type of network is also used in other          |  note that a fully connected network can be a      \napplications, such as in the internet, where data   |  complex and complex system, and it is not always  \nis sent from one node to another through a series   |  possible to achieve a fully connected network in a\nof connections. The concept of a fully connected    |  practical setting. It is important to consider the\nnetwork is fundamental to the functioning of        |  trade-offs between connectivity and complexity    \ncomputer networks and other types of networks.      |  when designing networks.   ### Response: A fully  \n### Response: A fully connected network is a type   |  connected network is a type of network where every\nof network where every node is connected to every   |  node is connected to every other node. This means \nother node, and no nodes are isolated from each     |  that there is no separation of any nodes, and all \nother. This type of network is commonly used in     |  nodes are interconnected with each other. This    \ncomputer networks, where data is sent from one      |  type of network is often used in computer         \nnode to another through a series of connections.    |  networks, where it is used to transmit data       \nThe concept of a fully connected network is         |  between different devices. The concept of a fully \nessential for the functioning of computer           |  connected network is important in computer science\nnetworks, as it allows for efficient data           |  and networking, as it allows for efficient data   \ntransmission and communication. In a fully          |  transmission and communication. However, it is    \nconnected network, all nodes are connected to each  |  also important to note that a fully connected     \nother, and no nodes are isolated from each other.   |  network can be a complex and complex system, and  \nThis type of network is also used in other          |  it is not always possible to achieve a fully      \napplications, such as in the internet, where data   |  connected network in a practical setting. It is   \nis sent from one node to another through a series   |  important to consider the trade-offs between      \nof connections. The concept of a fully connected    |  connectivity and complexity when designing        \nnetwork is fundamental to the functioning of        |  networks.   ### Response: A fully connected       \ncomputer networks and other types of networks.      |  network is a type of network where every node is  \n### Response: A fully connected network is a type   |  connected to every other node. This means that    \nof network where every node is connected to every   |  there is no separation of any nodes, and all nodes\nother node, and no nodes are isolated from each     |  are interconnected with each other. This type of  \nother. This type of network is commonly used in     |  network is often used in computer networks, where \ncomputer networks, where data is sent from one      |  it is used to transmit data between different     \nnode to another through a series of connections.    |  devices. The concept of a fully connected network \nThe concept of a fully connected network is         |  is important in computer science and networking,  \nessential for the functioning of computer           |  as it allows for efficient data transmission and  \nnetworks, as it allows for efficient data           |  communication. However, it is also important to   \ntransmission and communication. In a fully          |  note that a fully connected network can be a      \nconnected network, all nodes are connected to each  |  complex and complex system, and it is not always  \nother, and no nodes are isolated from each other.   |  possible to achieve a fully connected network in a\nThis type of network is also used in other          |  practical setting. It is important to consider the\napplications, such as in the internet, where data   |  trade-offs between connectivity and complexity    \nis sent from one node to another through a series   |  when designing networks.   ### Response: A fully  \nof connections. The concept of a fully connected    |  connected network is a type of network where every\nnetwork is fundamental to the functioning of        |  node is connected to every other node. This means \ncomputer networks and other types of networks.      |  that there is no separation of any nodes, and all \n### Response: A fully connected network is a type   |  nodes are interconnected with each other. This    \nof network where every node is connected to every   |  type of network is often used in computer         \nother node, and no nodes are isolated from each     |  networks, where it is used to transmit data       \nother. This type of network is commonly used in     |  between different devices. The concept of a fully \ncomputer networks, where data is sent from one      |  connected network is important in computer science\nnode                                                |  and networking, as it allows for efficient data   \n                                                    |  transmission and communication. However, it       \n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:42:50.661581Z","iopub.execute_input":"2024-11-22T08:42:50.662249Z","iopub.status.idle":"2024-11-22T08:45:12.592527Z","shell.execute_reply.started":"2024-11-22T08:42:50.662206Z","shell.execute_reply":"2024-11-22T08:45:12.591643Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Add 10%    |  completes the request.  ### Instruction: Add 10%  \ntax to the following amount: $100  ### Input:       |  tax to the following amount: $100  ### Input:     \n### Response: To add 10% tax to the amount $100,    |  ### Response: To add 10% tax to the amount $100,  \nfollow these steps:  1. First, add 10% to the       |  follow these steps:  1. First, add 10% to the     \namount: $100 + ($100 * 0.10) = $100 + $10 = $110    |  amount: $100 + ($100 * 0.10) = $100 + $10 = $110  \n2. Next, add the tax amount to the total: $110 +    |  2. Next, add the tax amount to the total: $110 +  \n$10 = $120  Therefore, the final amount after       |  $10 = $120  Therefore, the final amount after     \nadding 10% tax to $100 is $120.   If you would      |  adding 10% tax to $100 is $120.   If you would    \nlike to see the tax amount added to the amount,     |  like to see the tax amount added to the amount,   \nyou can do that as well: $100 + ($100 * 0.10) =     |  you can do that as well: $100 + ($100 * 0.10) =   \n$100 + $10 = $110.   If you would like to see the   |  $100 + $10 = $110.   If you would like to see the \ntax amount added to the total, you can do that as   |  tax amount added to the total, you can do that as \nwell: $110 + $10 = $120.   If you would like to     |  well: $110 + $10 = $120.   If you would like to   \nsee the tax amount added to the amount, you can do  |  see the tax amount added to the amount, you can do\nthat as well: $100 + ($100 * 0.10) = $100 + $10 =   |  that as well: $100 + ($100 * 0.10) = $100 + $10 = \n$110.   If you would like to see the tax amount     |  $110.   If you would like to see the tax amount   \nadded to the amount, you can do that as well: $100  |  added to the amount, you can do that as well: $100\n+ ($100 * 0.10) = $100 + $10 = $110.   If you       |  + ($100 * 0.10) = $100 + $10 = $110.   If you     \nwould like to see the tax amount added to the       |  would like to see the tax amount added to the     \namount, you can do that as well: $100 + ($100 *     |  amount, you can do that as well: $100 + ($100 *   \n0.10) = $100 + $10 = $110.   If you would like to   |  0.10) = $100 + $10 = $110.   If you would like to \nsee the tax amount added to the amount, you can do  |  see the tax amount added to the amount, you can do\nthat as well: $100 + ($100 * 0.10) = $100 + $10 =   |  that as well: $100 + ($100 * 0.10) = $100 + $10 = \n$110.   If you would like to see the tax amount     |  $110.   If you would like to see the tax amount   \nadded to the amount, you can do that as well: $100  |  added to the amount, you can do that as well: $100\n+ ($100 * 0.10) = $100 + $10 = $110.   If you       |  + ($100 * 0.10) = $100 + $10 = $110.   If you     \nwould like to see the tax amount added to the       |  would like to see the tax amount added to the     \namount, you can do that as well: $100 + ($100 *     |  amount, you can do that as well: $100 + ($100 *   \n0.10) = $100 + $10 = $110.   If you would like to   |  0.10) = $100 + $10 = $110.   If you would like to \nsee the tax amount added to the amount, you can do  |  see the tax amount added to the amount, you can do\nthat as well: $100 + ($100 * 0.10) = $100 + $10 =   |  that as well: $100 + ($100 * 0.10) = $100 + $10 = \n$110.   If you would like to see the tax amount     |  $110.   If you would like to see the tax amount   \nadded to the amount, you can do that as well: $100  |  added to the amount, you can do that as well: $100\n+ ($100 * 0.10) = $100 + $10 = $110.   If you       |  + ($100 * 0.10) = $100 + $10 = $110.   If you     \nwould like to see the tax amount added to the       |  would like to see the tax amount added to the     \namount, you can do that as well: $100 + ($100 *     |  amount, you can do that as well: $100 + ($100 *   \n0.10) = $100 + $10 = $110.   If you would like to   |  0.10) = $100 + $10 = $110.   If you would like to \nsee the tax amount added to the amount, you can do  |  see the tax amount added to the amount, you can do\nthat as well: $100 + ($100 * 0.10) = $100 + $10 =   |  that as well: $100 + ($100 * 0.10) = $100 + $10 = \n$110.   If you would like to see the tax amount     |  $110.   If you would like to see the tax amount   \nadded to the amount, you can do that as well: $100  |  added to the amount, you can do that as well: $100\n+ ($100 * 0.10) = $100 + $10 = $110.   If you       |  + ($100 * 0.10) = $100 + $10 = $110.   If you     \nwould like to see the tax amount added to the       |  would like to see the tax amount added to the     \namount, you can do that as well: $100 + ($100 *     |  amount, you can do that as well: $100 + ($100 *   \n0.10) = $100 + $10 = $110.   If you would like to   |  0.10) = $100 + $10 = $110.   If you would like to \nsee the tax amount added to the amount, you can do  |  see the tax amount added to the amount, you can do\nthat as well: $100 + ($100 * 0.10) = $100 + $10 =   |  that as well: $100 + ($100 * 0.10) = $100 + $10 = \n$110.   If you would like to see the tax amount     |  $110.   If you would like to see the tax amount   \nadded to the amount, you can do that as well: $100  |  added to the amount, you can do that as well: $100\n+ ($100 * 0.10) = $100 + $10 = $110.   If you       |  + ($100 * 0.10) = $100 + $10 = $110.   If you     \nwould like to see the tax amount added to the       |  would like to see the tax amount added to the     \namount, you can do that as well: $100 + ($100 *     |  amount, you can do that as well: $100 + ($100 *   \n0.10) = $100 + $10 = $110.   If you would like to   |  0.10) = $100 + $10 = $110.   If you would like to \nsee the tax amount added to the amount, you can do  |  see the tax amount added to the amount, you can do\nthat as well: $100 + ($                             |  that as well: $100 + ($                           \n","output_type":"stream"}],"execution_count":107},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T08:28:47.197964Z","iopub.execute_input":"2024-11-22T08:28:47.198787Z","iopub.status.idle":"2024-11-22T08:31:09.710573Z","shell.execute_reply.started":"2024-11-22T08:28:47.198742Z","shell.execute_reply":"2024-11-22T08:31:09.709546Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Describe   |  completes the request.  ### Instruction: Describe \nthe personality traits of an introvert  ### Input:  |  the personality traits of an introvert  ### Input:\n### Response: The personality traits of an          |  ### Response: The personality traits of an        \nintrovert are: - They are shy and reserved - They   |  introvert are: - They are shy and reserved - They \nare introverted - They are sensitive to social      |  are introverted - They are sensitive to social    \ninteraction - They are comfortable in solitude -    |  interaction - They are self-controlled - They are \nThey are self-sufficient - They are independent -   |  detail-oriented - They are focused on their own   \nThey are calm and composed - They are focused on    |  needs and desires - They are independent - They   \ntheir own needs and desires - They are self-        |  are calm and composed - They are comfortable in   \nmotivated - They are self-assured - They are self-  |  solitude - They are comfortable in their own      \nreliant - They are self-controlled - They are       |  company - They are comfortable in their own space \nself-aware - They are self-reflective - They are    |  - They are comfortable in their own environment - \nself-reflective - They are self-reflective - They   |  They are comfortable in their own way of thinking \nare self-reflective - They are self-reflective -    |  - They are comfortable in their own way of working\nThey are self-reflective - They are self-           |  - They are comfortable in their own way of living \nreflective - They are self-reflective - They are    |  - They are comfortable in their own way of        \nself-reflective - They are self-reflective - They   |  expressing themselves - They are comfortable in   \nare self-reflective - They are self-reflective -    |  their own way of interacting with others - They   \nThey are self-reflective - They are self-           |  are comfortable in their own way of managing their\nreflective - They are self-reflective - They are    |  time - They are comfortable in their own way of   \nself-reflective - They are self-reflective - They   |  managing their emotions - They are comfortable in \nare self-reflective - They are self-reflective -    |  their own way of managing their relationships -   \nThey are self-reflective - They are self-           |  They are comfortable in their own way of managing \nreflective - They are self-reflective - They are    |  their goals - They are comfortable in their own   \nself-reflective - They are self-reflective - They   |  way of managing their life - They are comfortable \nare self-reflective - They are self-reflective -    |  in their own way of managing their work - They are\nThey are self-reflective - They are self-           |  comfortable in their own way of managing their    \nreflective - They are self-reflective - They are    |  time - They are comfortable in their own way of   \nself-reflective - They are self-reflective - They   |  managing their emotions - They are comfortable in \nare self-reflective - They are self-reflective -    |  their own way of managing their relationships -   \nThey are self-reflective - They are self-           |  They are comfortable in their own way of managing \nreflective - They are self-reflective - They are    |  their goals - They are comfortable in their own   \nself-reflective - They are self-reflective - They   |  way of managing their life - They are comfortable \nare self-reflective - They are self-reflective -    |  in their own way of managing their work - They are\nThey are self-reflective - They are self-           |  comfortable in their own way of managing their    \nreflective - They are self-reflective - They are    |  time - They are comfortable in their own way of   \nself-reflective - They are self-reflective - They   |  managing their emotions - They are comfortable in \nare self-reflective - They are self-reflective -    |  their own way of managing their relationships -   \nThey are self-reflective - They are self-           |  They are comfortable in their own way of managing \nreflective - They are self-reflective - They are    |  their goals - They are comfortable in their own   \nself-reflective - They are self-reflective - They   |  way of managing their life - They are comfortable \nare self-reflective - They are self-reflective -    |  in their own way of managing their work - They are\nThey are self-reflective - They are self-           |  comfortable in their own way of managing their    \nreflective - They are self-reflective - They are    |  time - They are comfortable in their own way of   \nself-reflective - They are self-reflective - They   |  managing their emotions - They are comfortable in \nare self-reflective - They are self-reflective -    |  their own way of managing their relationships -   \nThey are self-reflective - They are self-           |  They are comfortable in their own way of managing \nreflective - They are self-reflective - They are    |  their goals - They are comfortable in their own   \nself-reflective - They are self-reflective - They   |  way of managing their life - They are comfortable \nare self-reflective - They are self-reflective -    |  in their own way of managing their work - They are\nThey are self-reflective - They are self-           |  comfortable in their own way of managing their    \nreflective - They are self-reflective - They are    |  time - They are comfortable in their own way of   \nself-reflective - They are self-reflective - They   |  managing their emotions - They are comfortable in \nare self-reflective - They are self-reflective -    |  their own way of managing their relationships -   \nThey are self-reflective - They are self-           |  They are comfortable in their own way of managing \nreflective - They are self-reflective - They are    |  their goals - They are comfortable in their own   \nself-reflective - They are self-reflective - They   |  way of managing their life - They are comfortable \nare self-reflective - They are self-reflective -    |  in their own way of managing their work - They are\nThey are self-reflective - They are self-           |  comfortable in their own way of managing their    \nreflective - They are self-reflective - They are    |  time - They are comfortable in their own way of   \nself-reflective - They are self-reflective - They   |  managing their emotions - They are comfortable in \nare self-reflective - They are self-reflective -    |  their own way of managing their relationships -   \nThey are self-reflective - They are self-           |  They are comfortable in their own way of managing \nreflective - They are self-reflective - They are    |  their goals - They are comfortable in their own   \nself-reflective - They are self-reflective - They   |  way of managing their life - They are comfortable \nare self-reflective - They are self-reflective -    |  in their own way of managing their work - They are\nThey are self-reflective - They are self-           |  comfortable in their own way of managing their    \nreflective - They are self-reflective - They are    |  time - They are comfortable in their own way of   \nself-reflective - They are self-reflective - They   |  managing their emotions - They are comfortable in \nare self-reflective - They are self-reflective -    |  their own way of managing their relationships -   \nThey are self-reflective - They are self-           |  They are comfortable in their own way of managing \nreflective - They are self-reflective - They are    |  their goals - They are comfortable in their own   \nself-reflective - They are self-reflective - They   |  way of managing their life - They are comfortable \nare self-reflective - They are self-reflective -    |  in their own way of managing their work - They are\nThey are self-reflective - They are self-           |  comfortable in their own way of managing their    \nreflective - They are self-reflective - They are    |  time - They are comfortable in their own way of   \nself-reflective - They are self-reflective - They   |  managing their emotions - They are comfortable in \n                                                    |  their own way of managing their relationships -   \n                                                    |  They are comfortable in their own way of managing \n                                                    |  their goals - They are comfortable in their own   \n                                                    |  way of managing their life - They are comfortable \n                                                    |  in their own way of managing their work - They are\n                                                    |  comfortable in their own way of managing their    \n                                                    |  time - They are comfortable in their own way of   \n                                                    |  managing their emotions - They are comfortable in \n                                                    |  their own way of managing their relationships -   \n                                                    |  They are comfortable in their own way of managing \n                                                    |  their goals - They are comfortable in their own   \n                                                    |  way of managing their life - They are comfortable \n                                                    |  in their own way of managing their work - They are\n                                                    |  comfortable in their own way of managing their    \n                                                    |  time - They are comfortable in their own way of   \n                                                    |  managing their emotions - They are comfortable in \n                                                    |  their own way of managing their relationships -   \n                                                    |  They are comfortable in their own way of managing \n                                                    |  their goals - They are comfortable in their own   \n                                                    |  way of managing their life - They are comfortable \n                                                    |  in their own way of managing their work - They are\n                                                    |  comfortable in their own way of managing their    \n                                                    |  time - They are comfortable in their own way of   \n                                                    |  managing their emotions - They are comfortable in \n                                                    |  their own way of managing their relationships -   \n                                                    |  They are comfortable in their own way of managing \n                                                    |  their goals - They are comfortable in their own   \n                                                    |  way of managing their life - They are comfortable \n                                                    |  in their own way of managing their work - They are\n                                                    |  comfortable in their own way of                   \n","output_type":"stream"}],"execution_count":105}]}