{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-20T05:51:37.711067Z","iopub.execute_input":"2024-11-20T05:51:37.711458Z","iopub.status.idle":"2024-11-20T05:52:27.257873Z","shell.execute_reply.started":"2024-11-20T05:51:37.711417Z","shell.execute_reply":"2024-11-20T05:52:27.256766Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-11-20T05:52:27.259604Z","iopub.execute_input":"2024-11-20T05:52:27.259887Z","iopub.status.idle":"2024-11-20T05:52:46.342301Z","shell.execute_reply.started":"2024-11-20T05:52:27.259860Z","shell.execute_reply":"2024-11-20T05:52:46.341477Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-11-20T05:52:46.343513Z","iopub.execute_input":"2024-11-20T05:52:46.343758Z","iopub.status.idle":"2024-11-20T05:52:46.351734Z","shell.execute_reply.started":"2024-11-20T05:52:46.343734Z","shell.execute_reply":"2024-11-20T05:52:46.349735Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'microsoft/Phi-3-mini-4k-instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-20T05:52:46.354241Z","iopub.execute_input":"2024-11-20T05:52:46.354517Z","iopub.status.idle":"2024-11-20T05:52:46.378629Z","shell.execute_reply.started":"2024-11-20T05:52:46.354492Z","shell.execute_reply":"2024-11-20T05:52:46.377821Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-11-20T05:52:46.379496Z","iopub.execute_input":"2024-11-20T05:52:46.379743Z","iopub.status.idle":"2024-11-20T05:52:46.390590Z","shell.execute_reply.started":"2024-11-20T05:52:46.379710Z","shell.execute_reply":"2024-11-20T05:52:46.389977Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:52:46.391523Z","iopub.execute_input":"2024-11-20T05:52:46.391772Z","iopub.status.idle":"2024-11-20T05:55:59.165192Z","shell.execute_reply.started":"2024-11-20T05:52:46.391749Z","shell.execute_reply":"2024-11-20T05:55:59.164478Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f434f92b63d340c6ad300fad792347b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efb8769740de4c6080b6fe8750fe2509"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7167632b29f74bb19c93f77a052b47f7"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97ee445c940e43e681ccc7228ee2fb17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d65e4755bc6444938997366632b9d798"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fac29f3cfd54e368bd1295e9b1c504e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9eafe31d2c04e5daa57c4438596e618"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c163828707b4e5a99048905cb1a8a9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c6d3833cba846c6a3e75af198390cdf"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3RotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm()\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm()\n      )\n    )\n    (norm): Phi3RMSNorm()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:55:59.166090Z","iopub.execute_input":"2024-11-20T05:55:59.166322Z","iopub.status.idle":"2024-11-20T05:55:59.173606Z","shell.execute_reply.started":"2024-11-20T05:55:59.166284Z","shell.execute_reply":"2024-11-20T05:55:59.172724Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 2009140224\nTrainable parameters : 197200896\nTrainable percentage: 9.82%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:55:59.174791Z","iopub.execute_input":"2024-11-20T05:55:59.175484Z","iopub.status.idle":"2024-11-20T05:56:00.890723Z","shell.execute_reply.started":"2024-11-20T05:55:59.175446Z","shell.execute_reply":"2024-11-20T05:56:00.889801Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbcb3965acb04c5bb1b170072027fda8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08cff323bf584340863c181993e8df37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f86382f197d40e184049e964cccab37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ce9f2eec71a48a0a8f947f1e2908763"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cff50caf7904eb5999f234311b591e0"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'mlabonne/FineTome-100k'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:00.891900Z","iopub.execute_input":"2024-11-20T05:56:00.892170Z","iopub.status.idle":"2024-11-20T05:56:00.896060Z","shell.execute_reply.started":"2024-11-20T05:56:00.892144Z","shell.execute_reply":"2024-11-20T05:56:00.895212Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 768","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:00.898950Z","iopub.execute_input":"2024-11-20T05:56:00.899199Z","iopub.status.idle":"2024-11-20T05:56:00.908950Z","shell.execute_reply.started":"2024-11-20T05:56:00.899176Z","shell.execute_reply":"2024-11-20T05:56:00.908155Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:00.909974Z","iopub.execute_input":"2024-11-20T05:56:00.910293Z","iopub.status.idle":"2024-11-20T05:56:06.921555Z","shell.execute_reply.started":"2024-11-20T05:56:00.910257Z","shell.execute_reply":"2024-11-20T05:56:06.920781Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/982 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eee2758d31fb44b0a5921b9527d922ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/117M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec6e0f1b3b644646a2543c57618a5205"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c13769f6acef47ab83a5511a8b7ec4e3"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations', 'source', 'score'],\n    num_rows: 100000\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:06.922618Z","iopub.execute_input":"2024-11-20T05:56:06.922887Z","iopub.status.idle":"2024-11-20T05:56:06.929030Z","shell.execute_reply.started":"2024-11-20T05:56:06.922861Z","shell.execute_reply":"2024-11-20T05:56:06.928228Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:06.930107Z","iopub.execute_input":"2024-11-20T05:56:06.930387Z","iopub.status.idle":"2024-11-20T05:56:08.016626Z","shell.execute_reply.started":"2024-11-20T05:56:06.930360Z","shell.execute_reply":"2024-11-20T05:56:08.015722Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                       conversations  \\\n0  [{'from': 'human', 'value': 'Explain what bool...   \n1  [{'from': 'human', 'value': 'Explain how recur...   \n2  [{'from': 'human', 'value': 'Explain what bool...   \n3  [{'from': 'human', 'value': 'Explain the conce...   \n4  [{'from': 'human', 'value': 'Print the reverse...   \n\n                     source     score  \n0  infini-instruct-top-500k  5.212621  \n1  infini-instruct-top-500k  5.157649  \n2  infini-instruct-top-500k  5.147540  \n3  infini-instruct-top-500k  5.053656  \n4  infini-instruct-top-500k  5.045648  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversations</th>\n      <th>source</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.212621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[{'from': 'human', 'value': 'Explain how recur...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.157649</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.147540</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[{'from': 'human', 'value': 'Explain the conce...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.053656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[{'from': 'human', 'value': 'Print the reverse...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.045648</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:08.017904Z","iopub.execute_input":"2024-11-20T05:56:08.018536Z","iopub.status.idle":"2024-11-20T05:56:08.027356Z","shell.execute_reply.started":"2024-11-20T05:56:08.018494Z","shell.execute_reply":"2024-11-20T05:56:08.026489Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'from': 'human',\n   'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'},\n  {'from': 'gpt',\n   'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}],\n 'source': 'infini-instruct-top-500k',\n 'score': 5.212620735168457}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:08.028476Z","iopub.execute_input":"2024-11-20T05:56:08.029269Z","iopub.status.idle":"2024-11-20T05:56:08.037490Z","shell.execute_reply.started":"2024-11-20T05:56:08.029227Z","shell.execute_reply":"2024-11-20T05:56:08.036664Z"}},"outputs":[{"name":"stdout","text":"['conversations', 'source', 'score']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"def transform_conversations(example):\n  role_map = {\n    'human' : 'user',\n    'gpt' : 'assistant'\n  }\n\n  transformed_conversations = [\n    {\n      'role' : role_map.get(turn['from'], turn['from']),\n      'content' : turn['value']\n    }\n    for turn in example['conversations']\n  ]\n  return {'conversations': transformed_conversations}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:08.038479Z","iopub.execute_input":"2024-11-20T05:56:08.038779Z","iopub.status.idle":"2024-11-20T05:56:08.048929Z","shell.execute_reply.started":"2024-11-20T05:56:08.038754Z","shell.execute_reply":"2024-11-20T05:56:08.048057Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"formatted_dataset = dataset.map(transform_conversations, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:08.049941Z","iopub.execute_input":"2024-11-20T05:56:08.050186Z","iopub.status.idle":"2024-11-20T05:56:08.813248Z","shell.execute_reply.started":"2024-11-20T05:56:08.050163Z","shell.execute_reply":"2024-11-20T05:56:08.812441Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdb65a3c8b0945f5bc15c66f9ee148c5"}},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(formatted_dataset[0]['conversations'])","metadata":{"id":"cZya4tPEWUc9","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:08.814395Z","iopub.execute_input":"2024-11-20T05:56:08.814668Z","iopub.status.idle":"2024-11-20T05:56:08.819213Z","shell.execute_reply.started":"2024-11-20T05:56:08.814643Z","shell.execute_reply":"2024-11-20T05:56:08.818255Z"}},"outputs":[{"name":"stdout","text":"[{'content': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.', 'role': 'user'}, {'content': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.', 'role': 'assistant'}]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def format_conversation(example):\n  for entry in example['conversations']:\n    role = entry['role']\n    content = entry['content']\n\n    if role == 'user':\n      formatted_text = f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n    elif role == 'assistant':\n      formatted_text += f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n\n  return {'prompt': formatted_text}","metadata":{"id":"3bmXGueQWWzt","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:08.820378Z","iopub.execute_input":"2024-11-20T05:56:08.820714Z","iopub.status.idle":"2024-11-20T05:56:08.851357Z","shell.execute_reply.started":"2024-11-20T05:56:08.820676Z","shell.execute_reply":"2024-11-20T05:56:08.850658Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"formatted_dataset = formatted_dataset.map(\n  format_conversation,\n  remove_columns = list(formatted_dataset.features.keys())\n)\nformatted_dataset","metadata":{"id":"Z6sSaCr5eaL7","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:08.852234Z","iopub.execute_input":"2024-11-20T05:56:08.852525Z","iopub.status.idle":"2024-11-20T05:56:09.464332Z","shell.execute_reply.started":"2024-11-20T05:56:08.852500Z","shell.execute_reply":"2024-11-20T05:56:09.463507Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0102cee835dc46a5b1903c47ec36963a"}},"metadata":{}},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:09.465541Z","iopub.execute_input":"2024-11-20T05:56:09.466171Z","iopub.status.idle":"2024-11-20T05:56:09.471260Z","shell.execute_reply.started":"2024-11-20T05:56:09.466130Z","shell.execute_reply":"2024-11-20T05:56:09.470243Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:09.472495Z","iopub.execute_input":"2024-11-20T05:56:09.472980Z","iopub.status.idle":"2024-11-20T05:56:09.500417Z","shell.execute_reply.started":"2024-11-20T05:56:09.472943Z","shell.execute_reply":"2024-11-20T05:56:09.499608Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:09.501330Z","iopub.execute_input":"2024-11-20T05:56:09.501615Z","iopub.status.idle":"2024-11-20T05:56:16.437955Z","shell.execute_reply.started":"2024-11-20T05:56:09.501591Z","shell.execute_reply":"2024-11-20T05:56:16.437100Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35424875b85547dbbe74c6849dc49bba"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.439200Z","iopub.execute_input":"2024-11-20T05:56:16.439574Z","iopub.status.idle":"2024-11-20T05:56:16.445170Z","shell.execute_reply.started":"2024-11-20T05:56:16.439537Z","shell.execute_reply":"2024-11-20T05:56:16.444366Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.446167Z","iopub.execute_input":"2024-11-20T05:56:16.446433Z","iopub.status.idle":"2024-11-20T05:56:16.622420Z","shell.execute_reply.started":"2024-11-20T05:56:16.446409Z","shell.execute_reply":"2024-11-20T05:56:16.621472Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.623383Z","iopub.execute_input":"2024-11-20T05:56:16.623712Z","iopub.status.idle":"2024-11-20T05:56:16.631380Z","shell.execute_reply.started":"2024-11-20T05:56:16.623683Z","shell.execute_reply":"2024-11-20T05:56:16.630592Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.632376Z","iopub.execute_input":"2024-11-20T05:56:16.632675Z","iopub.status.idle":"2024-11-20T05:56:16.660075Z","shell.execute_reply.started":"2024-11-20T05:56:16.632641Z","shell.execute_reply":"2024-11-20T05:56:16.659201Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n1  <|start_header_id|>user<|end_header_id|>\\n\\nWr...   \n2  <|start_header_id|>user<|end_header_id|>\\n\\nWh...   \n3  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n4  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n\n                                           input_ids  \\\n0  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n1  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n2  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n3  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n4  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n\n                                      attention_mask  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWr...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWh...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.665453Z","iopub.execute_input":"2024-11-20T05:56:16.665673Z","iopub.status.idle":"2024-11-20T05:56:16.670723Z","shell.execute_reply.started":"2024-11-20T05:56:16.665652Z","shell.execute_reply":"2024-11-20T05:56:16.669903Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nHow do you graph the inequality #x > -4#?\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nTo graph the inequality #x > -4#, follow these steps:\n\n1. Start by plotting the boundary line: Draw a vertical line at #x = -4# on the X-axis. This line divides the X-axis into two halves.\n\n2. Identify the direction of the inequality: Since the inequality is #x > -4#, it indicates that we are looking for all values of #x# that are greater than -4.\n\n3. Shade the appropriate region: Shade the entire region to the right of the line at #x = -4#. This shaded area represents all the points whose X-coordinate is greater than -4.\n\n4. Include a dashed line: Since the inequality is \"greater than\" (#>,# not \"#≥#\"), draw the line at #x = -4# as a dashed line, indicating that the points on the line itself are not included in the solution.\n\nThe graph consists of the entire half-plane to the right of the dashed vertical line at #x = -4#, excluding the line itself.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.671864Z","iopub.execute_input":"2024-11-20T05:56:16.672216Z","iopub.status.idle":"2024-11-20T05:56:16.682444Z","shell.execute_reply.started":"2024-11-20T05:56:16.672164Z","shell.execute_reply":"2024-11-20T05:56:16.681642Z"}},"outputs":[{"name":"stdout","text":"[32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 529, 29989, 2962, 29918, 6672, 29918, 333, 29989, 29958, 1792, 29966, 29989, 355, 29918, 6672, 29918, 333, 29989, 29958, 13, 13, 5328, 437, 366, 3983, 278, 14585, 396, 29916, 1405, 448, 29946, 29937, 29973, 13, 29966, 29989, 29872, 327, 29918, 333, 29989, 5299, 29989, 2962, 29918, 6672, 29918, 333, 29989, 29958, 465, 22137, 29966, 29989, 355, 29918, 6672, 29918, 333, 29989, 29958, 13, 13, 1762, 3983, 278, 14585, 396, 29916, 1405, 448, 29946, 6552, 1101, 1438, 6576, 29901, 13, 13, 29896, 29889, 7370, 491, 6492, 1259, 278, 10452, 1196, 29901, 18492, 263, 11408, 1196, 472, 396, 29916, 353, 448, 29946, 29937, 373, 278, 1060, 29899, 8990, 29889, 910, 1196, 1933, 2247, 278, 1060, 29899, 8990, 964, 1023, 8870, 1960, 29889, 13, 13, 29906, 29889, 13355, 1598, 278, 5305, 310, 278, 14585, 29901, 4001, 278, 14585, 338, 396, 29916, 1405, 448, 29946, 6552, 372, 14088, 393, 591, 526, 3063, 363, 599, 1819, 310, 396, 29916, 29937, 393, 526, 7621, 1135, 448, 29946, 29889, 13, 13, 29941, 29889, 1383, 1943, 278, 8210, 5120, 29901, 1383, 1943, 278, 4152, 5120, 304, 278, 1492, 310, 278, 1196, 472, 396, 29916, 353, 448, 29946, 29937, 29889, 910, 528, 11932, 4038, 11524, 599, 278, 3291, 5069, 1060, 29899, 29302, 338, 7621, 1135, 448, 29946, 29889, 13, 13, 29946, 29889, 512, 2325, 263, 27526, 1196, 29901, 4001, 278, 14585, 338, 376, 7979, 1008, 1135, 29908, 313, 29937, 10202, 29937, 451, 12305, 30386, 29937, 4968, 4216, 278, 1196, 472, 396, 29916, 353, 448, 29946, 29937, 408, 263, 27526, 1196, 29892, 23941, 393, 278, 3291, 373, 278, 1196, 3528, 526, 451, 5134, 297, 278, 1650, 29889, 13, 13, 1576, 3983, 11624, 310, 278, 4152, 4203, 29899, 22116, 304, 278, 1492, 310, 278, 27526, 11408, 1196, 472, 396, 29916, 353, 448, 29946, 6552, 429, 22368, 278, 1196, 3528, 29889, 13, 29966, 29989, 29872, 327, 29918, 333, 29989, 29958]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.683384Z","iopub.execute_input":"2024-11-20T05:56:16.683683Z","iopub.status.idle":"2024-11-20T05:56:16.694384Z","shell.execute_reply.started":"2024-11-20T05:56:16.683657Z","shell.execute_reply":"2024-11-20T05:56:16.693589Z"}},"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.695207Z","iopub.execute_input":"2024-11-20T05:56:16.695467Z","iopub.status.idle":"2024-11-20T05:56:16.705990Z","shell.execute_reply.started":"2024-11-20T05:56:16.695433Z","shell.execute_reply":"2024-11-20T05:56:16.705105Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.706908Z","iopub.execute_input":"2024-11-20T05:56:16.707151Z","iopub.status.idle":"2024-11-20T05:56:16.715486Z","shell.execute_reply.started":"2024-11-20T05:56:16.707129Z","shell.execute_reply":"2024-11-20T05:56:16.714759Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.716532Z","iopub.execute_input":"2024-11-20T05:56:16.716859Z","iopub.status.idle":"2024-11-20T05:56:16.726851Z","shell.execute_reply.started":"2024-11-20T05:56:16.716825Z","shell.execute_reply":"2024-11-20T05:56:16.726038Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.727831Z","iopub.execute_input":"2024-11-20T05:56:16.728089Z","iopub.status.idle":"2024-11-20T05:56:16.738784Z","shell.execute_reply.started":"2024-11-20T05:56:16.728057Z","shell.execute_reply":"2024-11-20T05:56:16.737960Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:16.739697Z","iopub.execute_input":"2024-11-20T05:56:16.739954Z","iopub.status.idle":"2024-11-20T05:56:17.246736Z","shell.execute_reply.started":"2024-11-20T05:56:16.739930Z","shell.execute_reply":"2024-11-20T05:56:17.245870Z"}},"outputs":[{"name":"stdout","text":"trainable params: 35,651,584 || all params: 3,856,731,136 || trainable%: 0.9244\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:17.247913Z","iopub.execute_input":"2024-11-20T05:56:17.248257Z","iopub.status.idle":"2024-11-20T05:56:17.257077Z","shell.execute_reply.started":"2024-11-20T05:56:17.248220Z","shell.execute_reply":"2024-11-20T05:56:17.256472Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3RotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm()\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm()\n      )\n    )\n    (norm): Phi3RMSNorm()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:17.257805Z","iopub.execute_input":"2024-11-20T05:56:17.258061Z","iopub.status.idle":"2024-11-20T05:56:17.275092Z","shell.execute_reply.started":"2024-11-20T05:56:17.258032Z","shell.execute_reply":"2024-11-20T05:56:17.274372Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 2044791808\nTrainable parameters : 35651584\nTrainable percentage: 1.74%\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:17.276026Z","iopub.execute_input":"2024-11-20T05:56:17.276330Z","iopub.status.idle":"2024-11-20T05:56:17.284455Z","shell.execute_reply.started":"2024-11-20T05:56:17.276286Z","shell.execute_reply":"2024-11-20T05:56:17.283712Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 1\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:17.285474Z","iopub.execute_input":"2024-11-20T05:56:17.285806Z","iopub.status.idle":"2024-11-20T05:56:17.325272Z","shell.execute_reply.started":"2024-11-20T05:56:17.285762Z","shell.execute_reply":"2024-11-20T05:56:17.324469Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov20_05-56-17_258896f9bd38,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:17.326257Z","iopub.execute_input":"2024-11-20T05:56:17.326547Z","iopub.status.idle":"2024-11-20T05:56:18.515397Z","shell.execute_reply.started":"2024-11-20T05:56:17.326519Z","shell.execute_reply":"2024-11-20T05:56:18.514575Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7bc9bd7b2c80>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T05:56:18.516689Z","iopub.execute_input":"2024-11-20T05:56:18.517032Z","iopub.status.idle":"2024-11-20T06:58:43.208483Z","shell.execute_reply.started":"2024-11-20T05:56:18.516995Z","shell.execute_reply":"2024-11-20T06:58:43.207634Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 1\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 35,651,584\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113718300000781, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcb2be18a80a4c9d99bb71c7bf92109d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241120_055641-watmdr2u</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/watmdr2u' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/watmdr2u' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/watmdr2u</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 1:01:48, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.983600</td>\n      <td>0.917131</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.857000</td>\n      <td>0.877726</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.852600</td>\n      <td>0.815067</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.805000</td>\n      <td>0.756144</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.714900</td>\n      <td>0.724724</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.712100</td>\n      <td>0.710922</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.709900</td>\n      <td>0.703051</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.714300</td>\n      <td>0.699547</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.714900</td>\n      <td>0.698235</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.671900</td>\n      <td>0.698018</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.7736047029495239, metrics={'train_runtime': 3744.31, 'train_samples_per_second': 0.214, 'train_steps_per_second': 0.053, 'total_flos': 1.39857670176768e+16, 'train_loss': 0.7736047029495239, 'epoch': 0.08888888888888889})"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T06:58:43.209662Z","iopub.execute_input":"2024-11-20T06:58:43.209957Z","iopub.status.idle":"2024-11-20T07:01:54.874226Z","shell.execute_reply.started":"2024-11-20T06:58:43.209930Z","shell.execute_reply":"2024-11-20T07:01:54.873393Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 03:07]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.6980181336402893, 'eval_runtime': 191.6508, 'eval_samples_per_second': 1.044, 'eval_steps_per_second': 0.261, 'epoch': 0.08888888888888889}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:01:54.875400Z","iopub.execute_input":"2024-11-20T07:01:54.875673Z","iopub.status.idle":"2024-11-20T07:01:55.942783Z","shell.execute_reply.started":"2024-11-20T07:01:54.875647Z","shell.execute_reply":"2024-11-20T07:01:55.941897Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\nModel config Phi3Config {\n  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n  \"architectures\": [\n    \"Phi3ForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"auto_map\": {\n    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n  },\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 32000,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 4096,\n  \"model_type\": \"phi3\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"original_max_position_embeddings\": 4096,\n  \"pad_token_id\": 32000,\n  \"resid_pdrop\": 0.0,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 2047,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32064\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\nModel config Phi3Config {\n  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n  \"architectures\": [\n    \"Phi3ForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"auto_map\": {\n    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n  },\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 32000,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 4096,\n  \"model_type\": \"phi3\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"original_max_position_embeddings\": 4096,\n  \"pad_token_id\": 32000,\n  \"resid_pdrop\": 0.0,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 2047,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32064\n}\n\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:01:55.943942Z","iopub.execute_input":"2024-11-20T07:01:55.944252Z","iopub.status.idle":"2024-11-20T07:01:56.319135Z","shell.execute_reply.started":"2024-11-20T07:01:55.944207Z","shell.execute_reply":"2024-11-20T07:01:56.318322Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:01:56.320188Z","iopub.execute_input":"2024-11-20T07:01:56.320474Z","iopub.status.idle":"2024-11-20T07:01:56.333396Z","shell.execute_reply.started":"2024-11-20T07:01:56.320446Z","shell.execute_reply":"2024-11-20T07:01:56.332646Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:01:56.334477Z","iopub.execute_input":"2024-11-20T07:01:56.335075Z","iopub.status.idle":"2024-11-20T07:01:56.934388Z","shell.execute_reply.started":"2024-11-20T07:01:56.335037Z","shell.execute_reply":"2024-11-20T07:01:56.933574Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:01:56.935527Z","iopub.execute_input":"2024-11-20T07:01:56.935856Z","iopub.status.idle":"2024-11-20T07:02:07.295141Z","shell.execute_reply.started":"2024-11-20T07:01:56.935821Z","shell.execute_reply":"2024-11-20T07:02:07.294356Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\nModel config Phi3Config {\n  \"_name_or_path\": \"microsoft/Phi-3-mini-4k-instruct\",\n  \"architectures\": [\n    \"Phi3ForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"auto_map\": {\n    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n  },\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 32000,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 4096,\n  \"model_type\": \"phi3\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"original_max_position_embeddings\": 4096,\n  \"pad_token_id\": 32000,\n  \"resid_pdrop\": 0.0,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 2047,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32064\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/model.safetensors.index.json\nInstantiating Phi3ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 32000,\n  \"pad_token_id\": 32000\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b268d77d48d845bb9c618afe15c079fd"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint weights were used when initializing Phi3ForCausalLM.\n\nAll the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-4k-instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": [\n    32000,\n    32001,\n    32007\n  ],\n  \"pad_token_id\": 32000\n}\n\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3RotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm()\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm()\n      )\n    )\n    (norm): Phi3RMSNorm()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:02:07.296108Z","iopub.execute_input":"2024-11-20T07:02:07.296385Z","iopub.status.idle":"2024-11-20T07:02:07.306046Z","shell.execute_reply.started":"2024-11-20T07:02:07.296358Z","shell.execute_reply":"2024-11-20T07:02:07.305236Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 2009140224\nTrainable parameters : 197200896\nTrainable percentage: 9.82%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:02:07.307157Z","iopub.execute_input":"2024-11-20T07:02:07.307786Z","iopub.status.idle":"2024-11-20T07:02:07.320786Z","shell.execute_reply.started":"2024-11-20T07:02:07.307745Z","shell.execute_reply":"2024-11-20T07:02:07.320057Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Phi3ForCausalLM(\n      (model): Phi3Model(\n        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n        (embed_dropout): Dropout(p=0.0, inplace=False)\n        (layers): ModuleList(\n          (0-31): 32 x Phi3DecoderLayer(\n            (self_attn): Phi3Attention(\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n              (rotary_emb): Phi3RotaryEmbedding()\n            )\n            (mlp): Phi3MLP(\n              (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n                  (default): Linear(in_features=8192, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (activation_fn): SiLU()\n            )\n            (input_layernorm): Phi3RMSNorm()\n            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n            (post_attention_layernorm): Phi3RMSNorm()\n          )\n        )\n        (norm): Phi3RMSNorm()\n      )\n      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:02:07.322034Z","iopub.execute_input":"2024-11-20T07:02:07.322639Z","iopub.status.idle":"2024-11-20T07:02:07.341511Z","shell.execute_reply.started":"2024-11-20T07:02:07.322599Z","shell.execute_reply":"2024-11-20T07:02:07.340711Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 2080443392\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"## 13 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  chat_template = f\"###Human: {prompt}\\n###Assistant:\"\n  messages = [\n    {'role': 'human', 'content': prompt},\n  ]\n  inputs = tokenizer.apply_chat_template(\n    messages,\n    chat_template = chat_template,\n    tokenize = True,\n    add_generation_prompt = True,\n    return_tensors = 'pt',\n    truncation = True,\n    padding = True,\n  ).to('cuda')\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    input_ids = inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:02:07.342757Z","iopub.execute_input":"2024-11-20T07:02:07.343087Z","iopub.status.idle":"2024-11-20T07:02:07.350305Z","shell.execute_reply.started":"2024-11-20T07:02:07.343050Z","shell.execute_reply":"2024-11-20T07:02:07.349730Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"def post_assistant(prompt):\n  chat_template = f\"###Human: {prompt}\\n###Assistant:\"\n  messages = [\n    {'role': 'human', 'content': prompt},\n  ]\n  inputs = tokenizer.apply_chat_template(\n    messages,\n    chat_template = chat_template,\n    tokenize = True,\n    add_generation_prompt = True,\n    return_tensors = 'pt',\n    truncation = True,\n    padding = True,\n  ).to('cuda')\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    input_ids = inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:02:07.351219Z","iopub.execute_input":"2024-11-20T07:02:07.351466Z","iopub.status.idle":"2024-11-20T07:02:07.362702Z","shell.execute_reply.started":"2024-11-20T07:02:07.351443Z","shell.execute_reply":"2024-11-20T07:02:07.361977Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:02:07.363677Z","iopub.execute_input":"2024-11-20T07:02:07.363910Z","iopub.status.idle":"2024-11-20T07:02:07.379437Z","shell.execute_reply.started":"2024-11-20T07:02:07.363886Z","shell.execute_reply":"2024-11-20T07:02:07.378713Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:51:57.521849Z","iopub.execute_input":"2024-11-20T07:51:57.522446Z","iopub.status.idle":"2024-11-20T07:53:33.668652Z","shell.execute_reply.started":"2024-11-20T07:51:57.522409Z","shell.execute_reply":"2024-11-20T07:53:33.667736Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\n###Human: Explain how the order of operations in    |  ###Human: Explain how the order of operations in  \nBIDMAS ensures consistency in mathematical          |  BIDMAS ensures consistency in mathematical        \ncalculations. ###Assistant:BIDMAS, which stands     |  calculations. ###Assistant:BIDMAS, which stands   \nfor Brackets, Indices, Division and                 |  for Brackets, Indices, Division and               \nMultiplication, Addition and Subtraction, is a      |  Multiplication, Addition and Subtraction, is a    \nmnemonic device used to remember the order of       |  mnemonic device used to remember the order of     \noperations in mathematics. This order is crucial    |  operations in mathematics. This order is crucial  \nfor ensieving consistency in mathematical           |  for ensieving consistency in mathematical         \ncalculations because it provides a standardized     |  calculations because it provides a standardized   \nway to interpret and solve mathematical             |  way to solve expressions, ensuring that everyone  \nexpressions.  Here's how BIDMAS ensures             |  arrives at the same result when performing the    \nconsistency:  1. Brackets: Operations enclosed in   |  same calculation.  Here's how BIDMAS ensures      \nbrackets (parentheses) are performed first. This    |  consistency:  1. Brackets: Operations within      \nis because brackets are used to indicate that the   |  brackets (parentheses) are performed first. This  \noperations within them should be completed before   |  allows for the grouping of certain parts of an    \nany other operations. By always performing these    |  expression, which can change the overall result if\noperations first, we ensure that the expression is  |  not done correctly. By always solving the         \nsimplified as much as possible before moving on to  |  innermost brackets first, we ensure that the      \nthe next step.  2. Indices (or Exponents): After    |  grouped parts are dealt with before moving on to  \nbrackets, indices (or exponents) are calculated.    |  other operations.  2. Indices (Exponents): After  \nThis includes operations like squaring, square      |  brackets, indices (or exponents) are calculated.  \nroots, and other exponentiation. By always          |  This step is crucial because it determines the    \ncalculating indices after brackets, we ensure that  |  power or root of a number, which can significantly\nany powers or roots are resolved before moving on   |  affect the outcome of the expression.  3. Division\nto the next step.  3. Division and Multiplication:  |  and Multiplication: These operations are performed\nThese operations are performed next, from left to   |  next, from left to right. Division and            \nright. Division and multiplication are inverse      |  multiplication are inverse operations, and        \noperations, and performing them in this order       |  performing them in a specific order ensures that  \nensures that the expression is simplified           |  the result is consistent. For example, if we have \ncorrectly. For example, if we have an expression    |  an expression like 4 ÷ 2 × 3, we must first divide\nlike 4 ÷ 2 × 3, we would first divide 4 by 2 to     |  4 by 2 to get 2, and then multiply the result by 3\nget 2, and then multiply 2 by 3 to get the final    |  to get 6. If we were to perform multiplication    \nresult of 6.  4. Addition and Subtraction:          |  first, we would get a different result (4 × 3 =   \nFinally, addition and subtraction are performed,    |  12, then divide by 2 = 6), which would lead to    \nalso from left to right. This ensures that any      |  inconsistency.  4. Addition and Subtraction:      \nremaining additions or subtractions are resolved    |  Finally, addition and subtraction are performed,  \nin the correct order. For example, if we have an    |  also from left to right. This step ensures that   \nexpression like 5 + 3 - 2, we would first add 5     |  the sum or difference of numbers is calculated in \nand 3 to get 8, and then subtract 2 to get the      |  a consistent manner. For example, in the          \nfinal result of 6.  By following the BIDMAS order   |  expression 5 + 3 - 2, we must first add 5 and 3 to\nof operations, mathematicians and students can      |  get 8, and then subtract 2 to get 6. If we were to\nensure that they are interpreting and solving       |  perform subtraction first, we would get a         \nmathematical expressions consistently. This         |  different result (5 - 2 = 3, then add 3 = 6),     \nconsistency is crucial for accurate calculations    |  which would again lead to inconsistency.  By      \nand for communicating mathematical ideas            |  following the BIDMAS order of operations,         \neffectively.  ###Human: Can you provide an example  |  mathematicians and students can ensure that they  \nof a complex mathematical expression that           |  are solving expressions in a consistent and       \ndemonstrates the importance of BIDMAS in ensuring   |  standardized manner, which is essential for       \nconsistency in calculations? ###Assistant:          |  accurate and reliable results.   <|endoftext|>    \nCertainly! Let's consider the following complex     |                                                    \nmathematical expression:  (3 + 2) × 4^2 - 5 ÷ (1 +  |                                                    \n1)  Without following the BIDMAS order of           |                                                    \noperations, we might incorrectly solve this         |                                                    \nexpression as follows:  1. Add 3 and 2: 5 2. Raise  |                                                    \n4 to the power of 2: 16 3. Multiply 5 by 16: 80 4.  |                                                    \nAdd 1 and 1: 2 5. Divide 5 by 2: 2.5 6. Subtract    |                                                    \n2.5 from 80: 77.5  This incorrect solution would    |                                                    \nyield a final result of 77.5.  Now, let's solve     |                                                    \nthe expression correctly using the BIDMAS order of  |                                                    \noperations:  1. Brackets: Perform the operations    |                                                    \nwithin the brackets first.    (3 + 2) = 5  2.       |                                                    \nIndices (or Exponents): Calculate the exponent      |                                                    \nnext.    4^2 = 16  3. Division and Multiplication:  |                                                    \nPerform these operations from left to right.    5   |                                                    \n× 16 = 80  4. Addition and Subtraction: Finally,    |                                                    \nperform the remaining addition and subtraction.     |                                                    \n80 - (1 + 1) = 80 - 2 = 78  By following the        |                                                    \nBIDMAS order of operations, we arrive at the        |                                                    \ncorrect final result of 78. This example            |                                                    \ndemonstrates the importance of BIDMAS in ensuring   |                                                    \nconsistency in mathematical calculations, as it     |                                                    \nallows us to interpret and solve complex            |                                                    \nexpressions accurately.  <|endoftext|>              |                                                    \n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:02:59.000924Z","iopub.execute_input":"2024-11-20T07:02:59.001261Z","iopub.status.idle":"2024-11-20T07:05:23.448458Z","shell.execute_reply.started":"2024-11-20T07:02:59.001225Z","shell.execute_reply":"2024-11-20T07:05:23.447555Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\n###Human: What is the function of the three tiny    |  ###Human: What is the function of the three tiny  \nbones in the middle ear and how do they contribute  |  bones in the middle ear and how do they contribute\nto the process of hearing? ###Assistant:The three   |  to the process of hearing? ###Assistant:The three \ntiny bones in the middle ear, also known as the     |  tiny bones in the middle ear, also known as the   \nauditory ossicles, play a crucial role in the       |  auditory ossicles, play a crucial role in the     \nprocess of hearing. These bones are the malleus     |  process of hearing. These bones are the malleus   \n(hammer), incus (anvil), and stapes (stirrup), and  |  (hammer), incus (anvil), and stapes (stirrup), and\nthey are the smallest bones in the human body.      |  they are the smallest bones in the human body.    \nTheir primary function is to transmit and amplify   |  Their primary function is to transmit and amplify \nsound vibrations from the outer ear to the inner    |  sound vibrations from the outer ear to the inner  \near. Here's how they contribute to the process of   |  ear. Here's how they contribute to the process of \nhearing:  1. Sound transmission: When sound waves   |  hearing:  1. Sound transmission: When sound waves \nenter the ear, they first encounter the outer ear   |  enter the ear, they first encounter the outer ear \n(pinna) and travel through the ear canal until      |  (pinna) and travel through the ear canal until    \nthey reach the eardrum (tympanic membrane). The     |  they reach the eardrum (tympanic membrane). The   \nsound vibrations cause the eardrum to vibrate as    |  sound vibrations cause the eardrum to vibrate as  \nwell.  2. Malleus (hammer): The malleus is the      |  well.  2. Malleus (hammer): The malleus is the    \nfirst of the three tiny bones and is directly       |  first of the three tiny bones and is directly     \nattached to the eardrum. When the eardrum           |  attached to the eardrum. When the eardrum         \nvibrates, the malleus picks up these vibrations     |  vibrates, the malleus picks up these vibrations   \nand transfers them to the incus.  3. Incus          |  and transfers them to the incus.  3. Incus        \n(anvil): The incus is the middle bone in the chain  |  (anvil): The incus is the middle bone in the chain\nand is connected to the malleus on one side and     |  and is connected to the malleus on one side and   \nthe stapes on the other. The incus receives the     |  the stapes on the other. The incus receives the   \nvibrations from the malleus and passes them on to   |  vibrations from the malleus and passes them on to \nthe stapes.  4. Stapes (stirrup): The stapes is     |  the stapes.  4. Stapes (stirrup): The stapes is   \nthe last bone in the chain and is connected to the  |  the last bone in the chain and is connected to the\nincus on one side and the oval window (a membrane-  |  incus on one side and the oval window (a membrane-\ncovered opening) on the other. The stapes receives  |  covered opening) on the other. The stapes receives\nthe vibrations from the incus and transfers them    |  the vibrations from the incus and transfers them  \nto the oval window.  5. Amplification and           |  to the oval window.  5. Amplification and         \ntransmission: The three tiny bones work together    |  transmission: The three tiny bones work together  \nto amplify the sound vibrations as they pass from   |  to amplify the sound vibrations as they pass from \nthe eardrum to the inner ear. This amplification    |  the eardrum to the inner ear. This amplification  \nis necessary because the inner ear is filled with   |  is necessary because the inner ear is filled with \nfluid, and the sound must be strong enough to       |  fluid, and the sound must be strong enough to     \ncreate pressure waves in the fluid for the sensory  |  create pressure waves in the fluid for the sensory\ncells (hair cells) to detect and convert the        |  cells (hair cells) to detect and convert the      \nvibrations into electrical signals. These signals   |  vibrations into electrical signals. These signals \nare then sent to the brain via the auditory nerve,  |  are then sent to the brain via the auditory nerve,\nwhere they are interpreted as sound.  In summary,   |  where they are interpreted as sound.  In summary, \nthe three tiny bones in the middle ear (malleus,    |  the three tiny bones in the middle ear (malleus,  \nincus, and stapes) play a vital role in the         |  incus, and stapes) play a vital role in the       \nprocess of hearing by transmitting and amplifying   |  process of hearing by transmitting and amplifying \nsound vibrations from the outer ear to the inner    |  sound vibrations from the outer ear to the inner  \near, allowing us to perceive and interpret sounds.  |  ear, allowing us to perceive and interpret sounds.\n###Human: Can you explain the role of the           |  ###Human: Can you explain the role of the         \nEustachian tube in maintaining the function of the  |  Eustachian tube in maintaining the function of the\nmiddle ear bones and how it contributes to the      |  middle ear bones and how it contributes to the    \noverall process of hearing?  ###Ass01: The          |  overall process of hearing?  ###Ass01: The        \nEustachian tube, also known as the auditory tube    |  Eustachian tube, also known as the auditory tube  \nor pharyngotympanic tube, is a narrow tube that     |  or pharyngotympanic tube, is a narrow tube that   \nconnects the middle ear to the back of the throat   |  connects the middle ear to the back of the throat \n(nasopharynx). Its primary function is to equalize  |  (nasopharynx). Its primary function is to equalize\nthe air pressure on both sides of the eardrum,      |  the air pressure on both sides of the eardrum,    \nwhich is essential for the proper functioning of    |  which is essential for the proper functioning of  \nthe middle ear bones and the overall process of     |  the middle ear bones and the overall process of   \nhearing. Here's how the Eustachian tube             |  hearing. Here's how the Eustachian tube           \ncontributes to the process:  1. Pressure            |  contributes to the process:  1. Pressure          \nequalization: The Eustachian tube helps maintain    |  equalization: The Eustachian tube helps maintain  \nequal air pressure on both sides of the eardrum.    |  equal air pressure on both sides of the eardrum.  \nWhen the air pressure outside the ear is different  |  When the air pressure outside the ear is different\nfrom the pressure inside the middle ear, the        |  from the pressure inside the middle ear, the      \neardrum can become distorted, which may affect the  |  eardrum can become distorted, which may affect the\ntransmission of sound vibrations through the        |  transmission of sound vibrations through the      \nmiddle ear bones. By equalizing the pressure, the   |  middle ear bones. By equalizing the pressure, the \nEustachian tube ensures that the eardrum can        |  Eustachian tube ensures that the eardrum can      \nvibrate freely and efficiently, allowing the        |  vibrate freely and efficiently, allowing the      \nmiddle ear bones to function optimally.  2.         |  middle ear bones to function optimally.  2.       \nDrainage and ventilation: The Eustachian tube also  |  Drainage and ventilation: The Eustachian tube also\nserves as a drainage and ventilation system for     |  serves as a drainage and ventilation system for   \nthe middle ear. It allows air to enter the middle   |  the middle ear. It allows air to enter the middle \near when the pressure in the external environment   |  ear when the pressure in the external environment \nis higher than the pressure in the middle ear, and  |  is higher than the pressure in the middle ear, and\nit allows air to leave the middle ear when the      |  it allows air to leave the middle ear when the    \npressure in the external environment is lower.      |  pressure in the external environment is lower.    \nThis helps prevent the accumulation of fluids in    |  This helps prevent the accumulation of fluids in  \nthe middle ear, which can lead to infections and    |  the middle ear, which can lead to infections and  \nnegatively impact the function of the middle ear    |  negatively impact the function of the middle ear  \nbones.  3. Protection against infections: The       |  bones.  3. Protection against infections: The     \nEustachian tube plays a crucial role in protecting  |  Eustachian tube plays a crucial role in protecting\nthe middle ear from infections. It acts as a        |  the middle ear from infections. It acts as a      \nbarrier, preventing bacteria and other pathogens    |  barrier, preventing bacteria and other pathogens  \nfrom entering the middle ear from the nasopharynx.  |  from entering the middle ear from the nasopharynx.\nThis is particularly important for the function of  |  This is particularly important for the function of\nthe middle ear bones, as infections can cause       |  the middle ear bones, as infections can cause     \ninflammation and swelling, which may interf01:      |  inflammation and swelling, which may interf01:    \naffect the transmission of sound vibrations         |  affect the transmission of sound vibrations       \n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:05:23.449515Z","iopub.execute_input":"2024-11-20T07:05:23.449775Z","iopub.status.idle":"2024-11-20T07:06:25.477653Z","shell.execute_reply.started":"2024-11-20T07:05:23.449749Z","shell.execute_reply":"2024-11-20T07:06:25.476860Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\n###Human: Solve the following math problem step-    |  ###Human: Solve the following math problem step-  \nby-step. Simplify your answer as much as possible.  |  by-step. Simplify your answer as much as possible.\nPresent your final answer as \\boxed{Your Answer}.   |  Present your final answer as \\boxed{Your Answer}. \nif the height of a cone is increased by 160 % then  |  if the height of a cone is increased by 160 % then\nits volume is increased by ? ###Assistant: Step 1:  |  its volume is increased by ? ###Assistant: Step 1:\nUnderstand the problem We are given that the        |  Understand the problem We are given that the      \nheight of a cone is increased by 160%. We need to   |  height of a cone is increased by 160%. We need to \nfind out by what percentage the volume of the cone  |  find out by what percentage the volume of the cone\nis increased.  Step 2: Use the formula for the      |  is increased.  Step 2: Use the formula for the    \nvolume of a cone The volume (V) of a cone is given  |  volume of a cone The volume (V) of a cone is given\nby the formula: V = (1/3)πr²h where r is the        |  by the formula: V = (1/3)πr²h where r is the      \nradius of the base and h is the height of the       |  radius of the base and h is the height of the     \ncone.  Step 3: Calculate the new height Let's       |  cone.  Step 3: Calculate the new height Let's     \nassume the original height of the cone is h. After  |  assume the original height of the cone is h. After\nincreasing the height by 160%, the new height (H)   |  increasing the height by 160%, the new height (h')\nwill be: H = h + 1.6h = 2.6h  Step 4: Calculate     |  will be: h' = h + 1.6h = 2.6h  Step 4: Calculate  \nthe new volume The new volume (V') of the cone      |  the new volume The new volume (V') of the cone    \nwith the increased height will be: V' = (1/3)πr²H   |  with the increased height will be: V' =           \n= (1/3)πr²(2.6h)  Step 5: Calculate the percentage  |  (1/3)πr²(2.6h)  Step 5: Calculate the percentage  \nincrease in volume Now, we need to find the         |  increase in volume To find the percentage increase\npercentage increase in volume. To do this, we will  |  in volume, we need to compare the new volume (V') \ncompare the new volume (V') with the original       |  with the original volume (V).  Percentage increase\nvolume (V).  Percentage increase = [(V' - V) / V]   |  = [(V' - V) / V] * 100  Substitute the volume     \n* 100  Step 6: Simplify the expression Substitute   |  formulas: Percentage increase = [((1/3)πr²(2.6h) -\nthe expressions for V and V' in the percentage      |  (1/3)πr²h) / (1/3)πr²h] * 100  Step 6: Simplify   \nincrease formula:  Percentage increase =            |  the expression Percentage increase = [(2.6 - 1) * \n[((1/3)πr²(2.6h) - (1/3)πr²h) / (1/3)πr²h] * 100    |  100] Percentage increase = 1.6 * 100 Percentage   \nStep 7: Cancel out common terms Cancel out the      |  increase = 160%  So, the volume of the cone is    \ncommon terms (1/3)πr²h:  Percentage increase =      |  increased by 160%.  Final Answer: \\boxed{160\\%}   \n[(2.6 - 1) * 100]  Step 8: Calculate the final      |  <|endoftext|>                                     \nanswer Percentage increase = (1.6 * 100) = 160%     |                                                    \nSo, the volume of the cone is increased by 160%.    |                                                    \nFinal Answer: \\boxed{160\\%}<|endoftext|>            |                                                    \n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:06:25.478906Z","iopub.execute_input":"2024-11-20T07:06:25.479523Z","iopub.status.idle":"2024-11-20T07:07:51.245223Z","shell.execute_reply.started":"2024-11-20T07:06:25.479478Z","shell.execute_reply":"2024-11-20T07:07:51.244366Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\n###Human: What were the social and economic         |  ###Human: What were the social and economic       \nimpacts of the Industrial Revolution in 19th        |  impacts of the Industrial Revolution in 19th      \ncentury England? ###Assistant:The Industrial        |  century England? ###Assistant:The Industrial      \nRevolution, which began in 18th century England,    |  Revolution, which began in 18th century England   \nhad profound social and economic impacts that       |  and continued into the 19th century, had profound \ntransformed the country and laid the groundwork     |  social and economic impacts that transformed the  \nfor modern industrial society. Here are some of     |  country and set the stage for modern industrial   \nthe key changes:  1. Urbanization: The Industrial   |  society. Here are some of the key changes:  1.    \nRevolution led to a massive shift from rural to     |  Urbanization: The Industrial Revolution led to a  \nurban living. People moved to cities in search of   |  massive shift from rural to urban living. People  \nwork in factories, leading to the rapid growth of   |  moved to cities in search of work in factories,   \ncities. This urbanization process brought about     |  leading to the rapid growth of cities. This       \nsignificant changes in living conditions, with      |  urbanization process brought about significant    \novercrowded and often unsanitary housing becoming   |  changes in living conditions, with overcrowded and\ncommon.  2. Changes in the workforce: The           |  often unsanitary housing becoming common.  2.     \nIndustrial Revolution saw a shift from an agrarian  |  Changes in the workforce: The Industrial          \neconomy to an industrial one. The workforce         |  Revolution saw a shift from agrarian work to      \nchanged from being primarily agricultural to being  |  factory-based work. The demand for labor in       \ndominated by factory work. This led to the rise of  |  factories led to the growth of a new working      \na new working class, the proletariat, who worked    |  class, which often faced long hours, low wages,   \nlong hours in often dangerous conditions for low    |  and dangerous working conditions. This led to the \nwages.  3. Economic growth: The Industrial          |  rise of labor movements and the eventual          \nRevolution led to significant economic growth. The  |  establishment of labor laws and unions.  3.       \nincreased productivity and efficiency of            |  Economic growth: The Industrial Revolution led to \nindustrial production led to an increase in the     |  significant economic growth, with the rise of new \noverall wealth of the nation. This wealth was not   |  industries such as textiles, coal mining, and iron\nevenly distributed, however, and led to the         |  production. This growth was fueled by             \nemergence of a wealthy industrial capitalist        |  technological innovations, such as the steam      \nclass, the bourgeoisie.  4. Rise of capitalism:     |  engine and the power loom, which increased        \nThe Industrial Revolution was a key driver in the   |  productivity and efficiency.  4. Wealth disparity:\nrise of capitalism. The increased productivity and  |  The Industrial Revolution also led to a widening  \nwealth generated by industrialization led to the    |  gap between the rich and the poor. While the      \naccumulation of capital, which could be invested    |  owners of factories and businesses accumulated    \nin new ventures, leading to further economic        |  vast wealth, the working class often lived in     \ngrowth.  5. Social changes: The Industrial          |  poverty. This disparity led to social unrest and  \nRevolution brought about significant social         |  calls for reform.  5. Changes in family structure:\nchanges. The rise of the middle class, the          |  The Industrial Revolution also brought changes to \nbourgeoisie, led to changes in social structures    |  family structure, with more women and children    \nand norms. The increased wealth of the bourgeoisie  |  entering the workforce. This led to changes in    \nled to a demand for better education, arts, and     |  gender roles and family dynamics, as well as      \nculture, which contributed to the development of a  |  concerns about child labor and the exploitation of\nmore educated and cultured society.  6. Labor       |  women.  6. Education and literacy: The need for a \nrights: The harsh working conditions and low wages  |  skilled workforce led to an increased emphasis on \nof the working class led to the emergence of labor  |  education and literacy. The government and private\nunions and the fight for workers' rights. This      |  organizations established schools and universities\neventually led to the establishment of labor laws,  |  to train workers in new skills and technologies.  \nminimum wage, and better working conditions.  7.    |  7. Social reform: The social and economic changes \nTechnological advancements: The Industrial          |  brought about by the Industrial Revolution led to \nRevolution was marked by significant technological  |  calls for social reform. This included the        \nadvancements, such as the steam engine, the power   |  establishment of public health and sanitation     \nloom, and the spinning jenny. These innovations     |  systems, the creation of labor laws, and the      \nincreased productivity and efficiency, leading to   |  expansion of the welf0rkforce.  In summary, the   \nfurther economic growth.  8. Environmental impact:  |  Industrial Revolution had a profound impact on    \nThe Industrial Revolution had a significant         |  19th century England, transforming its social and \nenvironmental impact. The increased use of coal     |  economic landscape. While it brought about        \nand other fossil fuels led to air and water         |  significant economic growth and technological     \npollution, which had long-term consequences for     |  innovation, it also led to social unrest, wealth  \nthe environment and public health.  In summary,     |  disparity, and changes in family structure and    \nthe Industrial Revolution had a profound impact on  |  gender roles. The changes brought about by the    \nthe social and economic landscape of 19th century   |  Industrial Revolution laid the foundation for     \nEngland. It led to urbanization, changes in the     |  modern industrial society.<|endoftext|>           \nworkforce, economic growth, the rise of             |                                                    \ncapitalism, social changes, labor rights,           |                                                    \ntechnological advancements, and environmental       |                                                    \nimpact. These changes laid the foundation for       |                                                    \nmodern industrial society and continue to shape     |                                                    \nthe world we live in today.<|endoftext|>            |                                                    \n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-11-20T07:07:51.246419Z","iopub.execute_input":"2024-11-20T07:07:51.246682Z","iopub.status.idle":"2024-11-20T07:08:21.818723Z","shell.execute_reply.started":"2024-11-20T07:07:51.246656Z","shell.execute_reply":"2024-11-20T07:08:21.817895Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\n###Human: How do you determine the amplitude and    |  ###Human: How do you determine the amplitude and  \nperiod for the function #y=-2\\sin(x)#?              |  period for the function #y=-2\\sin(x)#?            \n###Assistant: The amplitude of a sinusoidal         |  ###Assistant: The amplitude of a trigonometric    \nfunction like y = A*sin(Bx + C) + D is the          |  function like y = A * sin(Bx + C) + D is the      \nabsolute value of the coefficient A. In the given   |  absolute value of the coefficient A, which        \nfunction y = -2*sin(x), the coefficient A is -2.    |  determines the maximum value the function reaches \nTherefore, the amplitude is |-2| = 2.  The period   |  above or below its midline (the D value). In the  \nof a sinusoidal function is determined by the       |  given function y = -2 * sin(x), the coefficient A \ncoefficient B in the function y = A*sin(Bx + C) +   |  is -2. Therefore, the amplitude is |-2| = 2.  The \nD. The period is calculated as (2π)/|B|. In the     |  period of a sine function is the length of one    \ngiven function y = -2*sin(x), the coefficient B is  |  complete cycle of the wave. For the basic sine    \n1 (since it'ieves no multiplication). Therefore,    |  function y = sin(x), the period is 2π because the \nthe period is (2π)/|1| = 2π.  So, the amplitude of  |  sine function repeats every 2π radians. When the  \nthe function y = -2*sin(x) is 2, and the period is  |  function is in the form y = sin(Bx), the period is\n2π.   <|endoftext|>                                 |  given by the formula 2π/B. In the given function y\n                                                    |  = -2 * sin(x), B is 1 (since there is no          \n                                                    |  coefficient multiplying x). Therefore, the period \n                                                    |  is 2π/1 = 2π.  So, for the function y = -2 *      \n                                                    |  sin(x), the amplitude is 2, and the period is 2π. \n                                                    |  <|endoftext|>                                     \n","output_type":"stream"}],"execution_count":58}]}