{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1ab4948106a4ebba90f015abaf30d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b40250409b044e9938490a726ed5aa7",
              "IPY_MODEL_8f451079dd8549d49c4e87de530afd3b",
              "IPY_MODEL_1159abf2ce3b45c08989ca6f0c88e640"
            ],
            "layout": "IPY_MODEL_a8f11790ca6e415781bc822614949785"
          }
        },
        "9b40250409b044e9938490a726ed5aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3e40536a61145ce892c6fe9ddc28b45",
            "placeholder": "​",
            "style": "IPY_MODEL_7d44c088c7a34f3988d3fac637e810f3",
            "value": "config.json: 100%"
          }
        },
        "8f451079dd8549d49c4e87de530afd3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88b6ca8709fe4b98a8cecf0a96727c88",
            "max": 681,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64ece78c86464283af8eb1fe20a43d5a",
            "value": 681
          }
        },
        "1159abf2ce3b45c08989ca6f0c88e640": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c8f1b2af49e44cbad1e166c4a72ed28",
            "placeholder": "​",
            "style": "IPY_MODEL_8fbf0a07822b4b9cbd3e53baa17f0490",
            "value": " 681/681 [00:00&lt;00:00, 41.2kB/s]"
          }
        },
        "a8f11790ca6e415781bc822614949785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3e40536a61145ce892c6fe9ddc28b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d44c088c7a34f3988d3fac637e810f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88b6ca8709fe4b98a8cecf0a96727c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ece78c86464283af8eb1fe20a43d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c8f1b2af49e44cbad1e166c4a72ed28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fbf0a07822b4b9cbd3e53baa17f0490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a284f6250dd4466689c236c13f2decca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0f367b835e74f6f8fd0cdf41b647f66",
              "IPY_MODEL_e12495545dc4416a8545292f5fc3bdc4",
              "IPY_MODEL_e6e6da0179ff465bb66271e0cebc5eca"
            ],
            "layout": "IPY_MODEL_39f81e723833405fbf6b9510dfb68580"
          }
        },
        "a0f367b835e74f6f8fd0cdf41b647f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0962ac7ee5d1447eaa3896a57f7a6de9",
            "placeholder": "​",
            "style": "IPY_MODEL_f55a7c7086514686829fa3a9daf020f1",
            "value": "model.safetensors: 100%"
          }
        },
        "e12495545dc4416a8545292f5fc3bdc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afda474253fd4fa899064d796c9dd803",
            "max": 988097824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f83ebe9ca4f404ab77d6eb52bc5f55a",
            "value": 988097824
          }
        },
        "e6e6da0179ff465bb66271e0cebc5eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed68e529c5cc4421b357e6e26179785c",
            "placeholder": "​",
            "style": "IPY_MODEL_0464e1daa5d54cb487a72ac57f5957ec",
            "value": " 988M/988M [00:23&lt;00:00, 42.5MB/s]"
          }
        },
        "39f81e723833405fbf6b9510dfb68580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0962ac7ee5d1447eaa3896a57f7a6de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55a7c7086514686829fa3a9daf020f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afda474253fd4fa899064d796c9dd803": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f83ebe9ca4f404ab77d6eb52bc5f55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed68e529c5cc4421b357e6e26179785c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0464e1daa5d54cb487a72ac57f5957ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1d3867366364d3ab303696dde3e7569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b79f61968ab54b40bec386049f1bc66b",
              "IPY_MODEL_0f1e503a4fe64fffba08c17c65dcb3ed",
              "IPY_MODEL_82d4a89288134993bfb05c7fb59ba9aa"
            ],
            "layout": "IPY_MODEL_2dcfa3515c1c4048b7ae9aff29f71ed7"
          }
        },
        "b79f61968ab54b40bec386049f1bc66b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a425ee563c942589aa57b658cd9b632",
            "placeholder": "​",
            "style": "IPY_MODEL_15941cf350be4ef286a23e3ed3d712ea",
            "value": "generation_config.json: 100%"
          }
        },
        "0f1e503a4fe64fffba08c17c65dcb3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61b97ec2b94447979dd92373b4d81f31",
            "max": 138,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b60dda2b481941cb931d38f612f56a07",
            "value": 138
          }
        },
        "82d4a89288134993bfb05c7fb59ba9aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b8a1075280a48aea68973099c15f9ea",
            "placeholder": "​",
            "style": "IPY_MODEL_c88facc80e92404783b322062c97f4b0",
            "value": " 138/138 [00:00&lt;00:00, 3.98kB/s]"
          }
        },
        "2dcfa3515c1c4048b7ae9aff29f71ed7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a425ee563c942589aa57b658cd9b632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15941cf350be4ef286a23e3ed3d712ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61b97ec2b94447979dd92373b4d81f31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b60dda2b481941cb931d38f612f56a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b8a1075280a48aea68973099c15f9ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88facc80e92404783b322062c97f4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95538c204c3a44ac973bca07c32f0c08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28ce12f067d643f285b9984b6129ac88",
              "IPY_MODEL_4b23d1e748cf4bf4a2a1a9f0bd1d41c8",
              "IPY_MODEL_f74de4a2f74c420da299c6fc7045a03d"
            ],
            "layout": "IPY_MODEL_9f0bbad5945f4e5db4392de678a80d8d"
          }
        },
        "28ce12f067d643f285b9984b6129ac88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_288dba86545c4e29828505d1089b251e",
            "placeholder": "​",
            "style": "IPY_MODEL_98fe6905b09e46a99e843e47b382d611",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4b23d1e748cf4bf4a2a1a9f0bd1d41c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_623cddec82f74236989c584b51d66e9b",
            "max": 7228,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31331b5881014de9a120ff7b9b9feec4",
            "value": 7228
          }
        },
        "f74de4a2f74c420da299c6fc7045a03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5749b81cbbcd4667b623472674ce7fc2",
            "placeholder": "​",
            "style": "IPY_MODEL_a130662d9fbc47f1aa15158cfe784251",
            "value": " 7.23k/7.23k [00:00&lt;00:00, 211kB/s]"
          }
        },
        "9f0bbad5945f4e5db4392de678a80d8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "288dba86545c4e29828505d1089b251e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98fe6905b09e46a99e843e47b382d611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "623cddec82f74236989c584b51d66e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31331b5881014de9a120ff7b9b9feec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5749b81cbbcd4667b623472674ce7fc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a130662d9fbc47f1aa15158cfe784251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d50e375442944dbeb24075fe05189d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dcab4c3bddc4948b6ae9256dec91e17",
              "IPY_MODEL_d6fcdbcb5c314f0a88dd5e2f693b1694",
              "IPY_MODEL_0f37c02f72c441a0ab759098754a0cd7"
            ],
            "layout": "IPY_MODEL_896139d0fad64f998bdefaf8be72c673"
          }
        },
        "8dcab4c3bddc4948b6ae9256dec91e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61418d9284ec4491bad7a11f85e10d39",
            "placeholder": "​",
            "style": "IPY_MODEL_0132ee8ff07b4d62b2869b2c19d965bc",
            "value": "vocab.json: 100%"
          }
        },
        "d6fcdbcb5c314f0a88dd5e2f693b1694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d4dd8f007c4b53ad2db953d2760935",
            "max": 2776833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac40d75ab78f48c39ea21678b88c10b3",
            "value": 2776833
          }
        },
        "0f37c02f72c441a0ab759098754a0cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ac64bd2f8384a9884bc3495ce232263",
            "placeholder": "​",
            "style": "IPY_MODEL_8a850ef06e5e4aaab16a8a5c41e3b924",
            "value": " 2.78M/2.78M [00:00&lt;00:00, 25.3MB/s]"
          }
        },
        "896139d0fad64f998bdefaf8be72c673": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61418d9284ec4491bad7a11f85e10d39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0132ee8ff07b4d62b2869b2c19d965bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6d4dd8f007c4b53ad2db953d2760935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac40d75ab78f48c39ea21678b88c10b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ac64bd2f8384a9884bc3495ce232263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a850ef06e5e4aaab16a8a5c41e3b924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a4a46e4dd4d469c9e6ffe27bab50fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e408bbf44554cc89997a7520f4514cc",
              "IPY_MODEL_42bd3ed503d04c8592d70b2f9a498c95",
              "IPY_MODEL_83cf0e7ea5e14ff5a4871a2ce69d2794"
            ],
            "layout": "IPY_MODEL_3bb53deabbbf4a488508284994b72e96"
          }
        },
        "4e408bbf44554cc89997a7520f4514cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e2b712e299f46c2a8da4788a120c305",
            "placeholder": "​",
            "style": "IPY_MODEL_ce12737a054241559f68450ee29cef19",
            "value": "merges.txt: 100%"
          }
        },
        "42bd3ed503d04c8592d70b2f9a498c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b7b84520cde4b64be80c30a0955d99c",
            "max": 1671839,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31b58bfb0a9b4f388c3f78e0828522bb",
            "value": 1671839
          }
        },
        "83cf0e7ea5e14ff5a4871a2ce69d2794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6a4fce383a4c21bc6c36106e5d95f4",
            "placeholder": "​",
            "style": "IPY_MODEL_3947341da0134fb28cf37f0548901bf2",
            "value": " 1.67M/1.67M [00:00&lt;00:00, 20.5MB/s]"
          }
        },
        "3bb53deabbbf4a488508284994b72e96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e2b712e299f46c2a8da4788a120c305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce12737a054241559f68450ee29cef19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b7b84520cde4b64be80c30a0955d99c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31b58bfb0a9b4f388c3f78e0828522bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc6a4fce383a4c21bc6c36106e5d95f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3947341da0134fb28cf37f0548901bf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98fb601ecf6043548c08e69bc3fddb7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df5ec7a92eb04929a9d08e28b866d29a",
              "IPY_MODEL_022aea7306eb46258ab76672121aeaa9",
              "IPY_MODEL_4f865d8fd85f4fdc96a6ebee891e0bb0"
            ],
            "layout": "IPY_MODEL_77a169c8f452426293ebee6dfc9b1f6c"
          }
        },
        "df5ec7a92eb04929a9d08e28b866d29a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9428656627464aa5abe3356deeabf016",
            "placeholder": "​",
            "style": "IPY_MODEL_8eea5807134c4d89909ce4388e05a51d",
            "value": "tokenizer.json: 100%"
          }
        },
        "022aea7306eb46258ab76672121aeaa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8841ff9001c44c3c8d0daf22056c447c",
            "max": 7031645,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9b983c1c25e4281b0ce045fd94e4e02",
            "value": 7031645
          }
        },
        "4f865d8fd85f4fdc96a6ebee891e0bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e53ebcf6ec406786c3121f1a449956",
            "placeholder": "​",
            "style": "IPY_MODEL_122dbb53c1c444f6979a8f0df74b279d",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 20.6MB/s]"
          }
        },
        "77a169c8f452426293ebee6dfc9b1f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9428656627464aa5abe3356deeabf016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eea5807134c4d89909ce4388e05a51d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8841ff9001c44c3c8d0daf22056c447c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b983c1c25e4281b0ce045fd94e4e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84e53ebcf6ec406786c3121f1a449956": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122dbb53c1c444f6979a8f0df74b279d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f0cf8acc89a47bfa9d822f74440ad62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24e478ca0d654ab381714f3a5d455d58",
              "IPY_MODEL_c8249afeb6e2414a8c046d4ff88f9909",
              "IPY_MODEL_629e47a6add24daa98cdc4a2fd65984a"
            ],
            "layout": "IPY_MODEL_8052936711ca4ca18bb2b35f61f71c51"
          }
        },
        "24e478ca0d654ab381714f3a5d455d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a440d0b510c44a14a1e10362ab66d54f",
            "placeholder": "​",
            "style": "IPY_MODEL_35b83e4970ad4d43b2528c39d24f5fdd",
            "value": "Map: 100%"
          }
        },
        "c8249afeb6e2414a8c046d4ff88f9909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9519444aabc4a0a82b9076e38f4f2ef",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e508e2470101493e8c5119a28ef18c70",
            "value": 100000
          }
        },
        "629e47a6add24daa98cdc4a2fd65984a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f348446ca6204264bdb1b27e75d54dc2",
            "placeholder": "​",
            "style": "IPY_MODEL_e4d49024563c4fa794bc6c00554ebd2c",
            "value": " 100000/100000 [02:35&lt;00:00, 722.48 examples/s]"
          }
        },
        "8052936711ca4ca18bb2b35f61f71c51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a440d0b510c44a14a1e10362ab66d54f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b83e4970ad4d43b2528c39d24f5fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9519444aabc4a0a82b9076e38f4f2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e508e2470101493e8c5119a28ef18c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f348446ca6204264bdb1b27e75d54dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d49024563c4fa794bc6c00554ebd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azzindani/03_LLM/blob/main/00_Qwen2_5_0_5B_Fine_Tune_PEFT_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00 Import Modules"
      ],
      "metadata": {
        "id": "iNW_MCROx_hX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade transformers\n",
        "!pip install -q peft\n",
        "!pip install -U -q bitsandbytes\n",
        "!pip install -q datasets\n",
        "!pip install -q trl"
      ],
      "metadata": {
        "id": "0-QxfiDVyT74",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:42:59.156295Z",
          "iopub.execute_input": "2024-11-01T01:42:59.1566Z",
          "iopub.status.idle": "2024-11-01T01:43:53.503216Z",
          "shell.execute_reply.started": "2024-11-01T01:42:59.156564Z",
          "shell.execute_reply": "2024-11-01T01:43:53.5021Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from datetime import datetime\n",
        "from datasets import load_dataset\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import (\n",
        "  AutoTokenizer,\n",
        "  AutoModelForCausalLM,\n",
        "  AutoModelForSeq2SeqLM,\n",
        "  AutoModel,\n",
        "  AutoModelForSequenceClassification,\n",
        "  DataCollatorForLanguageModeling,\n",
        "  Trainer,\n",
        "  TrainingArguments,\n",
        "  pipeline,\n",
        "  TextDataset,\n",
        "  EvalPrediction,\n",
        "  DataCollatorWithPadding,\n",
        "  GenerationConfig,\n",
        "  BitsAndBytesConfig,\n",
        "  DataCollatorForSeq2Seq,\n",
        "  TextStreamer\n",
        ")\n",
        "\n",
        "from peft import (\n",
        "  LoraConfig,\n",
        "  PeftModelForSequenceClassification,\n",
        "  PeftModel,\n",
        "  TaskType,\n",
        "  AutoPeftModelForSequenceClassification,\n",
        "  get_peft_model,\n",
        "  prepare_model_for_kbit_training\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"GPU is available!\")\n",
        "else:\n",
        "  print(\"GPU is not available.\")"
      ],
      "metadata": {
        "id": "TIgNx9Orx0It",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:43:53.505163Z",
          "iopub.execute_input": "2024-11-01T01:43:53.505501Z",
          "iopub.status.idle": "2024-11-01T01:44:17.352554Z",
          "shell.execute_reply.started": "2024-11-01T01:43:53.505467Z",
          "shell.execute_reply": "2024-11-01T01:44:17.351546Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd96a27-69ce-400a-c67a-39cfb1068b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "i-nwkyTDybqY",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:44:17.353859Z",
          "iopub.execute_input": "2024-11-01T01:44:17.354499Z",
          "iopub.status.idle": "2024-11-01T01:44:17.36203Z",
          "shell.execute_reply.started": "2024-11-01T01:44:17.354463Z",
          "shell.execute_reply": "2024-11-01T01:44:17.361056Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f4626c-babd-45cd-c0fc-4e6abaad4fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01 Import Model"
      ],
      "metadata": {
        "id": "grIeJpUdyX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n",
        "#model_name = url.split('.co/')[-1]\n",
        "\n",
        "model_name = 'Qwen/Qwen2.5-0.5B'"
      ],
      "metadata": {
        "id": "14Lkvw4cyZkY",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:44:17.364541Z",
          "iopub.execute_input": "2024-11-01T01:44:17.365575Z",
          "iopub.status.idle": "2024-11-01T01:44:17.382787Z",
          "shell.execute_reply.started": "2024-11-01T01:44:17.365427Z",
          "shell.execute_reply": "2024-11-01T01:44:17.381833Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "  load_in_4bit = True,\n",
        "  bnb_4bit_quant_type = 'nf4',\n",
        "  bnb_4bit_compute_dtype = torch.float16,\n",
        "  bnb_4bit_use_double_quant = True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  model_name,\n",
        "  quantization_config = bnb_config,\n",
        "  trust_remote_code = True\n",
        ").to(device) #'''"
      ],
      "metadata": {
        "id": "GlskFscYyeco",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:44:17.383843Z",
          "iopub.execute_input": "2024-11-01T01:44:17.384185Z",
          "iopub.status.idle": "2024-11-01T01:44:17.395491Z",
          "shell.execute_reply.started": "2024-11-01T01:44:17.384155Z",
          "shell.execute_reply": "2024-11-01T01:44:17.394541Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "c1ab4948106a4ebba90f015abaf30d97",
            "9b40250409b044e9938490a726ed5aa7",
            "8f451079dd8549d49c4e87de530afd3b",
            "1159abf2ce3b45c08989ca6f0c88e640",
            "a8f11790ca6e415781bc822614949785",
            "b3e40536a61145ce892c6fe9ddc28b45",
            "7d44c088c7a34f3988d3fac637e810f3",
            "88b6ca8709fe4b98a8cecf0a96727c88",
            "64ece78c86464283af8eb1fe20a43d5a",
            "8c8f1b2af49e44cbad1e166c4a72ed28",
            "8fbf0a07822b4b9cbd3e53baa17f0490",
            "a284f6250dd4466689c236c13f2decca",
            "a0f367b835e74f6f8fd0cdf41b647f66",
            "e12495545dc4416a8545292f5fc3bdc4",
            "e6e6da0179ff465bb66271e0cebc5eca",
            "39f81e723833405fbf6b9510dfb68580",
            "0962ac7ee5d1447eaa3896a57f7a6de9",
            "f55a7c7086514686829fa3a9daf020f1",
            "afda474253fd4fa899064d796c9dd803",
            "3f83ebe9ca4f404ab77d6eb52bc5f55a",
            "ed68e529c5cc4421b357e6e26179785c",
            "0464e1daa5d54cb487a72ac57f5957ec",
            "a1d3867366364d3ab303696dde3e7569",
            "b79f61968ab54b40bec386049f1bc66b",
            "0f1e503a4fe64fffba08c17c65dcb3ed",
            "82d4a89288134993bfb05c7fb59ba9aa",
            "2dcfa3515c1c4048b7ae9aff29f71ed7",
            "1a425ee563c942589aa57b658cd9b632",
            "15941cf350be4ef286a23e3ed3d712ea",
            "61b97ec2b94447979dd92373b4d81f31",
            "b60dda2b481941cb931d38f612f56a07",
            "9b8a1075280a48aea68973099c15f9ea",
            "c88facc80e92404783b322062c97f4b0"
          ]
        },
        "outputId": "5d7b4681-02c4-417d-aa5d-852c14f75748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1ab4948106a4ebba90f015abaf30d97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a284f6250dd4466689c236c13f2decca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1d3867366364d3ab303696dde3e7569"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''model = AutoModelForCausalLM.from_pretrained(\n",
        "  model_name,\n",
        "  torch_dtype = torch.float16,\n",
        "  trust_remote_code = True\n",
        ").to(device) #'''"
      ],
      "metadata": {
        "id": "dQ3WZpjeyfGg",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:44:17.396561Z",
          "iopub.execute_input": "2024-11-01T01:44:17.39684Z",
          "iopub.status.idle": "2024-11-01T01:45:31.000914Z",
          "shell.execute_reply.started": "2024-11-01T01:44:17.396811Z",
          "shell.execute_reply": "2024-11-01T01:45:31.000103Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "936e1fca-1dd9-4dc4-e7bc-681e17356648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model = AutoModelForCausalLM.from_pretrained(\\n  model_name,\\n  torch_dtype = torch.float16,\\n  trust_remote_code = True\\n).to(device) #'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "HIYgZ1xF1qsl",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:45:31.00206Z",
          "iopub.execute_input": "2024-11-01T01:45:31.002362Z",
          "iopub.status.idle": "2024-11-01T01:45:31.011096Z",
          "shell.execute_reply.started": "2024-11-01T01:45:31.002331Z",
          "shell.execute_reply": "2024-11-01T01:45:31.010163Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664e4a41-e7cb-4386-d100-67179a840f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2SdpaAttention(\n",
              "          (q_proj): Linear4bit(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear4bit(in_features=896, out_features=896, bias=False)\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear4bit(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "j6d6uYBfzCC4",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:45:31.012291Z",
          "iopub.execute_input": "2024-11-01T01:45:31.012623Z",
          "iopub.status.idle": "2024-11-01T01:45:31.026988Z",
          "shell.execute_reply.started": "2024-11-01T01:45:31.012584Z",
          "shell.execute_reply": "2024-11-01T01:45:31.026119Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94da8403-889d-4394-d526-8e41a33094f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters : 315119488\n",
            "Trainable parameters : 136178560\n",
            "Trainable percentage: 43.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 Import Tokenizer"
      ],
      "metadata": {
        "id": "MU_19rT5zEIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "#tokenizer"
      ],
      "metadata": {
        "id": "lpB5JUjSzGtJ",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:45:31.027984Z",
          "iopub.execute_input": "2024-11-01T01:45:31.028281Z",
          "iopub.status.idle": "2024-11-01T01:45:32.375326Z",
          "shell.execute_reply.started": "2024-11-01T01:45:31.028251Z",
          "shell.execute_reply": "2024-11-01T01:45:32.374518Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "95538c204c3a44ac973bca07c32f0c08",
            "28ce12f067d643f285b9984b6129ac88",
            "4b23d1e748cf4bf4a2a1a9f0bd1d41c8",
            "f74de4a2f74c420da299c6fc7045a03d",
            "9f0bbad5945f4e5db4392de678a80d8d",
            "288dba86545c4e29828505d1089b251e",
            "98fe6905b09e46a99e843e47b382d611",
            "623cddec82f74236989c584b51d66e9b",
            "31331b5881014de9a120ff7b9b9feec4",
            "5749b81cbbcd4667b623472674ce7fc2",
            "a130662d9fbc47f1aa15158cfe784251",
            "d50e375442944dbeb24075fe05189d46",
            "8dcab4c3bddc4948b6ae9256dec91e17",
            "d6fcdbcb5c314f0a88dd5e2f693b1694",
            "0f37c02f72c441a0ab759098754a0cd7",
            "896139d0fad64f998bdefaf8be72c673",
            "61418d9284ec4491bad7a11f85e10d39",
            "0132ee8ff07b4d62b2869b2c19d965bc",
            "a6d4dd8f007c4b53ad2db953d2760935",
            "ac40d75ab78f48c39ea21678b88c10b3",
            "5ac64bd2f8384a9884bc3495ce232263",
            "8a850ef06e5e4aaab16a8a5c41e3b924",
            "9a4a46e4dd4d469c9e6ffe27bab50fa7",
            "4e408bbf44554cc89997a7520f4514cc",
            "42bd3ed503d04c8592d70b2f9a498c95",
            "83cf0e7ea5e14ff5a4871a2ce69d2794",
            "3bb53deabbbf4a488508284994b72e96",
            "8e2b712e299f46c2a8da4788a120c305",
            "ce12737a054241559f68450ee29cef19",
            "1b7b84520cde4b64be80c30a0955d99c",
            "31b58bfb0a9b4f388c3f78e0828522bb",
            "bc6a4fce383a4c21bc6c36106e5d95f4",
            "3947341da0134fb28cf37f0548901bf2",
            "98fb601ecf6043548c08e69bc3fddb7e",
            "df5ec7a92eb04929a9d08e28b866d29a",
            "022aea7306eb46258ab76672121aeaa9",
            "4f865d8fd85f4fdc96a6ebee891e0bb0",
            "77a169c8f452426293ebee6dfc9b1f6c",
            "9428656627464aa5abe3356deeabf016",
            "8eea5807134c4d89909ce4388e05a51d",
            "8841ff9001c44c3c8d0daf22056c447c",
            "b9b983c1c25e4281b0ce045fd94e4e02",
            "84e53ebcf6ec406786c3121f1a449956",
            "122dbb53c1c444f6979a8f0df74b279d"
          ]
        },
        "outputId": "12ada48b-c82d-45d3-b38d-f9b7997d9a37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95538c204c3a44ac973bca07c32f0c08"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d50e375442944dbeb24075fe05189d46"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a4a46e4dd4d469c9e6ffe27bab50fa7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98fb601ecf6043548c08e69bc3fddb7e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03 Pre Test"
      ],
      "metadata": {
        "id": "ijrvU4PJVq2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assistant(prompt):\n",
        "  messages = [\n",
        "    {'role' : 'human', 'content' : prompt},\n",
        "  ]\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = 'pt',\n",
        "  ).to('cuda')\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = model.generate(\n",
        "    input_ids = inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return print(tokenizer.decode(outputs[0]))#, skip_special_tokens = True))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-01T01:45:32.388322Z",
          "iopub.execute_input": "2024-11-01T01:45:32.388713Z",
          "iopub.status.idle": "2024-11-01T01:45:32.397259Z",
          "shell.execute_reply.started": "2024-11-01T01:45:32.388672Z",
          "shell.execute_reply": "2024-11-01T01:45:32.396497Z"
        },
        "trusted": true,
        "id": "igcNHkPQVq2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "Summarize the following legal text in a few sentences:\n",
        "\n",
        "'In the case of John Doe v. XYZ Corp, the plaintiff, John Doe, entered into a formal service contract with XYZ Corp in January 2022. The agreement stipulated a one-year commitment for IT support services, with John Doe providing on-site troubleshooting, software updates, and system maintenance. XYZ Corp agreed to pay a fixed monthly retainer along with additional fees for after-hours support. However, in June 2022, XYZ Corp terminated the contract without prior notice, claiming that an unexpected downturn in business operations left them financially unable to continue. The plaintiff alleges wrongful termination, asserting that XYZ Corp failed to adhere to the 60-day notice clause outlined in the contract. Additionally, the plaintiff contends that the early termination damaged his professional reputation and resulted in significant financial losses, including missed client opportunities and incurred expenses for certifications specific to XYZ Corp’s systems. John Doe is seeking compensation for the remaining contract balance, damages for reputational harm, and reimbursement for training and certification costs required under the agreement.\n",
        "'''\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-01T01:45:32.398421Z",
          "iopub.execute_input": "2024-11-01T01:45:32.398881Z",
          "iopub.status.idle": "2024-11-01T01:45:44.57358Z",
          "shell.execute_reply.started": "2024-11-01T01:45:32.39884Z",
          "shell.execute_reply": "2024-11-01T01:45:44.572633Z"
        },
        "trusted": true,
        "id": "QxkFai4nVq2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c055c28a-e632-46ff-8c46-cbf43a24b8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What are the legal implications if a party violates a confidentiality agreement in the context of contract law? For example, consider a scenario where a contractor working with Tech Innovators Inc. shares proprietary technology information with a competitor. Explain in detail and cite relevant case law where possible.\"\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-01T01:47:56.817088Z",
          "iopub.execute_input": "2024-11-01T01:47:56.818072Z",
          "iopub.status.idle": "2024-11-01T01:48:08.063157Z",
          "shell.execute_reply.started": "2024-11-01T01:47:56.818026Z",
          "shell.execute_reply": "2024-11-01T01:48:08.06226Z"
        },
        "trusted": true,
        "id": "g3heyq_0Vq2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7978c49-cab3-4fba-9358-2cb056526093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Rephrase the following legal statement to make it more understandable for a general audience: 'Under the terms of the non-compete agreement, the defendant is barred from engaging in any business that competes with the plaintiff's business within a 50-mile radius for two years following the termination of employment.' Retain all key information while simplifying the language.\"\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-01T01:48:19.282128Z",
          "iopub.execute_input": "2024-11-01T01:48:19.283227Z",
          "iopub.status.idle": "2024-11-01T01:48:30.573799Z",
          "shell.execute_reply.started": "2024-11-01T01:48:19.283149Z",
          "shell.execute_reply": "2024-11-01T01:48:30.572821Z"
        },
        "trusted": true,
        "id": "oi2FTBj-Vq2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e5d18b2-f656-46ca-a25a-ccdfb82c8955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"In the case where a defendant claims breach of contract due to unforeseeable events, how does the principle of 'force majeure' apply? For instance, if a company was unable to deliver contracted goods due to a natural disaster, provide a detailed explanation and outline any relevant conditions under which the force majeure principle might or might not be applicable.\"\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-01T01:48:37.408731Z",
          "iopub.execute_input": "2024-11-01T01:48:37.409135Z",
          "iopub.status.idle": "2024-11-01T01:48:47.912624Z",
          "shell.execute_reply.started": "2024-11-01T01:48:37.409094Z",
          "shell.execute_reply": "2024-11-01T01:48:47.911692Z"
        },
        "trusted": true,
        "id": "Kwijg7zWVq2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cfedd34-1a1d-47d5-c50b-927c68634490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Construct an argument in defense of a client accused of breaching intellectual property laws due to sharing copyrighted material in an educational setting. For example, a teacher shares portions of a textbook with students to support classroom discussion. Focus on any legal exceptions or defenses that may apply, such as the fair use doctrine in educational contexts.\"\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-11-01T01:48:54.224175Z",
          "iopub.execute_input": "2024-11-01T01:48:54.224986Z",
          "iopub.status.idle": "2024-11-01T01:49:05.485618Z",
          "shell.execute_reply.started": "2024-11-01T01:48:54.224947Z",
          "shell.execute_reply": "2024-11-01T01:49:05.484628Z"
        },
        "trusted": true,
        "id": "k1Ex_wr9Vq2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57306415-e42b-4df5-a895-a8f33e2224d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04 Import Dataset"
      ],
      "metadata": {
        "id": "3QJUqcUVzNoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n",
        "#dataset_name = url.split('datasets/')[-1]\n",
        "\n",
        "dataset_name = 'mlabonne/FineTome-100k'"
      ],
      "metadata": {
        "id": "U01UXJdLzPXS",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:49:45.907284Z",
          "iopub.execute_input": "2024-11-01T01:49:45.908534Z",
          "iopub.status.idle": "2024-11-01T01:49:45.912881Z",
          "shell.execute_reply.started": "2024-11-01T01:49:45.908475Z",
          "shell.execute_reply": "2024-11-01T01:49:45.911876Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 1024"
      ],
      "metadata": {
        "id": "ZGIUyIDhNJC2",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:49:50.328881Z",
          "iopub.execute_input": "2024-11-01T01:49:50.329295Z",
          "iopub.status.idle": "2024-11-01T01:49:50.333666Z",
          "shell.execute_reply.started": "2024-11-01T01:49:50.329256Z",
          "shell.execute_reply": "2024-11-01T01:49:50.332615Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name, split = 'train')\n",
        "dataset"
      ],
      "metadata": {
        "id": "0ucM3l_FzUkp",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:49:55.907785Z",
          "iopub.execute_input": "2024-11-01T01:49:55.908934Z",
          "iopub.status.idle": "2024-11-01T01:49:59.327392Z",
          "shell.execute_reply.started": "2024-11-01T01:49:55.908881Z",
          "shell.execute_reply": "2024-11-01T01:49:59.32646Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "180be27b-8d7f-48da-9394-330c91231539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['conversations', 'source', 'score'],\n",
              "    num_rows: 100000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "FLRSMhJDzY5Z",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:50:04.4791Z",
          "iopub.execute_input": "2024-11-01T01:50:04.479975Z",
          "iopub.status.idle": "2024-11-01T01:50:04.512758Z",
          "shell.execute_reply.started": "2024-11-01T01:50:04.479931Z",
          "shell.execute_reply": "2024-11-01T01:50:04.511894Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "76e6e716-71d7-4b53-e58a-401f27f276df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                       conversations  \\\n",
              "0  [{'from': 'human', 'value': 'Explain what bool...   \n",
              "1  [{'from': 'human', 'value': 'Explain how recur...   \n",
              "2  [{'from': 'human', 'value': 'Explain what bool...   \n",
              "3  [{'from': 'human', 'value': 'Explain the conce...   \n",
              "4  [{'from': 'human', 'value': 'Print the reverse...   \n",
              "\n",
              "                     source     score  \n",
              "0  infini-instruct-top-500k  5.212621  \n",
              "1  infini-instruct-top-500k  5.157649  \n",
              "2  infini-instruct-top-500k  5.147540  \n",
              "3  infini-instruct-top-500k  5.053656  \n",
              "4  infini-instruct-top-500k  5.045648  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f5ac612-5f46-4b43-b6c1-e83cbccd81ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conversations</th>\n",
              "      <th>source</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n",
              "      <td>infini-instruct-top-500k</td>\n",
              "      <td>5.212621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'from': 'human', 'value': 'Explain how recur...</td>\n",
              "      <td>infini-instruct-top-500k</td>\n",
              "      <td>5.157649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n",
              "      <td>infini-instruct-top-500k</td>\n",
              "      <td>5.147540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'from': 'human', 'value': 'Explain the conce...</td>\n",
              "      <td>infini-instruct-top-500k</td>\n",
              "      <td>5.053656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{'from': 'human', 'value': 'Print the reverse...</td>\n",
              "      <td>infini-instruct-top-500k</td>\n",
              "      <td>5.045648</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f5ac612-5f46-4b43-b6c1-e83cbccd81ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f5ac612-5f46-4b43-b6c1-e83cbccd81ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f5ac612-5f46-4b43-b6c1-e83cbccd81ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2a97a940-3e93-4dc5-a709-ca4b502f8734\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2a97a940-3e93-4dc5-a709-ca4b502f8734')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2a97a940-3e93-4dc5-a709-ca4b502f8734 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"conversations\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"infini-instruct-top-500k\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07180840513295617,\n        \"min\": 5.045647621154785,\n        \"max\": 5.212620735168457,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5.157649040222168\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "3exPEy0JdLyI",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:50:14.570718Z",
          "iopub.execute_input": "2024-11-01T01:50:14.571753Z",
          "iopub.status.idle": "2024-11-01T01:50:14.580341Z",
          "shell.execute_reply.started": "2024-11-01T01:50:14.57171Z",
          "shell.execute_reply": "2024-11-01T01:50:14.579401Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52041c89-0347-44c6-ebb9-2b2aea42765b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'conversations': [{'from': 'human',\n",
              "   'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'},\n",
              "  {'from': 'gpt',\n",
              "   'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}],\n",
              " 'source': 'infini-instruct-top-500k',\n",
              " 'score': 5.212620735168457}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = list(dataset.features.keys())\n",
        "print(features)"
      ],
      "metadata": {
        "id": "xYKmTDtkAnt5",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:50:32.514931Z",
          "iopub.execute_input": "2024-11-01T01:50:32.51544Z",
          "iopub.status.idle": "2024-11-01T01:50:32.520409Z",
          "shell.execute_reply.started": "2024-11-01T01:50:32.515401Z",
          "shell.execute_reply": "2024-11-01T01:50:32.51939Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50eaa909-54a0-4414-b6e2-0753d2a714ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['conversations', 'source', 'score']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 05 Text Formatting"
      ],
      "metadata": {
        "id": "Wq59WgYJCDY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_conversations(example):\n",
        "  role_map = {\n",
        "    'human' : 'user',\n",
        "    'gpt' : 'assistant'\n",
        "  }\n",
        "  transformed_conversations = [\n",
        "    {\n",
        "      'role' : role_map.get(turn['from'], turn['from']),\n",
        "      'content' : turn['value']\n",
        "    }\n",
        "    for turn in example['conversations']\n",
        "  ]\n",
        "  return {'conversations': transformed_conversations}"
      ],
      "metadata": {
        "id": "0wXJNFBWWNYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = dataset.map(transform_conversations, remove_columns = features)\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "7TFGpGhoWS9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f85b3f5-660f-457f-8315-f69a8ea53089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['conversations'],\n",
              "    num_rows: 100000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['conversations'])"
      ],
      "metadata": {
        "id": "cZya4tPEWUc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d5e9ac-48e0-4b40-85b4-b21c39f2117e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'content': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.', 'role': 'user'}, {'content': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.', 'role': 'assistant'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_conversation(example):\n",
        "  for entry in example['conversations']:\n",
        "    role = entry['role']\n",
        "    content = entry['content']\n",
        "\n",
        "    if role == 'user':\n",
        "      formatted_text = f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n",
        "    elif role == 'assistant':\n",
        "      formatted_text += f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n",
        "\n",
        "  return {'prompt': formatted_text}"
      ],
      "metadata": {
        "id": "3bmXGueQWWzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset = formatted_dataset.map(\n",
        "  format_conversation,\n",
        "  remove_columns = list(formatted_dataset.features.keys())\n",
        ")\n",
        "formatted_dataset"
      ],
      "metadata": {
        "id": "Z6sSaCr5eaL7",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:53:47.227759Z",
          "iopub.execute_input": "2024-11-01T01:53:47.228489Z",
          "iopub.status.idle": "2024-11-01T01:53:53.2667Z",
          "shell.execute_reply.started": "2024-11-01T01:53:47.228447Z",
          "shell.execute_reply": "2024-11-01T01:53:53.26576Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "703c524a-87ac-4a5c-bb1b-ca5229b49f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt'],\n",
              "    num_rows: 100000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(formatted_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "Kidf8H5zefDC",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:53:56.818483Z",
          "iopub.execute_input": "2024-11-01T01:53:56.819387Z",
          "iopub.status.idle": "2024-11-01T01:53:56.825399Z",
          "shell.execute_reply.started": "2024-11-01T01:53:56.819341Z",
          "shell.execute_reply": "2024-11-01T01:53:56.824377Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c80d4f33-0ef5-46d5-9b1d-ab29c1270fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n",
            "\n",
            "Furthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n",
            "\n",
            "Finally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n",
            "\n",
            "The \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "y = 10\n",
            "result = (x > 0) and (y < 20)  # This expression evaluates to True\n",
            "```\n",
            "\n",
            "The \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "y = 10\n",
            "result = (x > 0) or (y < 20)  # This expression evaluates to True\n",
            "```\n",
            "\n",
            "The \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "result = not (x > 10)  # This expression evaluates to True\n",
            "```\n",
            "\n",
            "Operator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n",
            "\n",
            "```python\n",
            "result = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n",
            "```\n",
            "\n",
            "Short-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n",
            "\n",
            "In programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n",
            "\n",
            "```python\n",
            "if x != 0 and (y / x) > 10:\n",
            "    # Perform some operation\n",
            "```\n",
            "\n",
            "In languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n",
            "\n",
            "```\n",
            "if x != 0 {\n",
            "    if (y / x) > 10 {\n",
            "        // Perform some operation\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "Truthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n",
            "\n",
            "When evaluating boolean expressions, truthiness and falsiness come into play. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "result = x  # The value of x is truthy, so result is also truthy\n",
            "```\n",
            "\n",
            "To handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "result = bool(x)  # Explicitly converting x to a boolean value\n",
            "```\n",
            "\n",
            "This ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n",
            "<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 06 Tokenization"
      ],
      "metadata": {
        "id": "UMhGDyBpCHoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(example, max_length = max_length):\n",
        "  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)"
      ],
      "metadata": {
        "id": "m7bxU8fiewb7",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:54:28.834819Z",
          "iopub.execute_input": "2024-11-01T01:54:28.835588Z",
          "iopub.status.idle": "2024-11-01T01:54:28.840237Z",
          "shell.execute_reply.started": "2024-11-01T01:54:28.835548Z",
          "shell.execute_reply": "2024-11-01T01:54:28.839266Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = formatted_dataset.map(tokenize_data, batched = True)#, remove_columns = 'text')\n",
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "M3BO26k-BmdS",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:54:38.066106Z",
          "iopub.execute_input": "2024-11-01T01:54:38.066489Z",
          "iopub.status.idle": "2024-11-01T01:54:56.510893Z",
          "shell.execute_reply.started": "2024-11-01T01:54:38.066456Z",
          "shell.execute_reply": "2024-11-01T01:54:56.509995Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124,
          "referenced_widgets": [
            "0f0cf8acc89a47bfa9d822f74440ad62",
            "24e478ca0d654ab381714f3a5d455d58",
            "c8249afeb6e2414a8c046d4ff88f9909",
            "629e47a6add24daa98cdc4a2fd65984a",
            "8052936711ca4ca18bb2b35f61f71c51",
            "a440d0b510c44a14a1e10362ab66d54f",
            "35b83e4970ad4d43b2528c39d24f5fdd",
            "c9519444aabc4a0a82b9076e38f4f2ef",
            "e508e2470101493e8c5119a28ef18c70",
            "f348446ca6204264bdb1b27e75d54dc2",
            "e4d49024563c4fa794bc6c00554ebd2c"
          ]
        },
        "outputId": "ae5fa01c-ab03-42ec-f2f4-643292c3a337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f0cf8acc89a47bfa9d822f74440ad62"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 100000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "wEHhMdV4pEFH",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:55:01.827268Z",
          "iopub.execute_input": "2024-11-01T01:55:01.827982Z",
          "iopub.status.idle": "2024-11-01T01:55:01.853753Z",
          "shell.execute_reply.started": "2024-11-01T01:55:01.827942Z",
          "shell.execute_reply": "2024-11-01T01:55:01.852845Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "213aecbd-3a74-4a39-8134-d41dfdff0a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n",
            "\n",
            "Furthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n",
            "\n",
            "Finally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n",
            "\n",
            "The \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "y = 10\n",
            "result = (x > 0) and (y < 20)  # This expression evaluates to True\n",
            "```\n",
            "\n",
            "The \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "y = 10\n",
            "result = (x > 0) or (y < 20)  # This expression evaluates to True\n",
            "```\n",
            "\n",
            "The \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "result = not (x > 10)  # This expression evaluates to True\n",
            "```\n",
            "\n",
            "Operator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n",
            "\n",
            "```python\n",
            "result = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n",
            "```\n",
            "\n",
            "Short-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n",
            "\n",
            "In programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n",
            "\n",
            "```python\n",
            "if x != 0 and (y / x) > 10:\n",
            "    # Perform some operation\n",
            "```\n",
            "\n",
            "In languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n",
            "\n",
            "```\n",
            "if x != 0 {\n",
            "    if (y / x) > 10 {\n",
            "        // Perform some operation\n",
            "    }\n",
            "}\n",
            "```\n",
            "\n",
            "Truthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n",
            "\n",
            "When evaluating boolean expressions, truthiness and falsiness come into play. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "result = x  # The value of x is truthy, so result is also truthy\n",
            "```\n",
            "\n",
            "To handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n",
            "\n",
            "```python\n",
            "x = 5\n",
            "result = bool(x)  # Explicitly converting x to a boolean value\n",
            "```\n",
            "\n",
            "This ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n",
            "<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\n",
        "dataset"
      ],
      "metadata": {
        "id": "C2m-e-ivDn1A",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:55:23.107863Z",
          "iopub.execute_input": "2024-11-01T01:55:23.108293Z",
          "iopub.status.idle": "2024-11-01T01:55:23.145843Z",
          "shell.execute_reply.started": "2024-11-01T01:55:23.108254Z",
          "shell.execute_reply": "2024-11-01T01:55:23.14498Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a921aa0-0499-43d7-c6da-ccbcd16c4b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['prompt', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 90000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['prompt', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset['train']\n",
        "test_dataset = dataset['test']\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "QHs-BnR_zd9C",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:55:27.69848Z",
          "iopub.execute_input": "2024-11-01T01:55:27.698872Z",
          "iopub.status.idle": "2024-11-01T01:55:27.705059Z",
          "shell.execute_reply.started": "2024-11-01T01:55:27.698836Z",
          "shell.execute_reply": "2024-11-01T01:55:27.704163Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29706e47-ae72-4c3e-88bf-fbbe6ab7b7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'input_ids', 'attention_mask'],\n",
              "    num_rows: 90000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.select(range(5)).to_pandas().head()"
      ],
      "metadata": {
        "id": "-CUZuEENF2mW",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:55:30.162629Z",
          "iopub.execute_input": "2024-11-01T01:55:30.163298Z",
          "iopub.status.idle": "2024-11-01T01:55:30.192087Z",
          "shell.execute_reply.started": "2024-11-01T01:55:30.163257Z",
          "shell.execute_reply": "2024-11-01T01:55:30.191231Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "eeb5d28a-0a2f-4f07-921f-f63ca28daa78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              prompt  \\\n",
              "0  <|start_header_id|>user<|end_header_id|>\\n\\nWh...   \n",
              "1  <|start_header_id|>user<|end_header_id|>\\n\\nUs...   \n",
              "2  <|start_header_id|>user<|end_header_id|>\\n\\nCr...   \n",
              "3  <|start_header_id|>user<|end_header_id|>\\n\\nWr...   \n",
              "4  <|start_header_id|>user<|end_header_id|>\\n\\nTh...   \n",
              "\n",
              "                                           input_ids  \\\n",
              "0  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n",
              "1  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n",
              "2  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n",
              "3  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n",
              "4  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n",
              "\n",
              "                                      attention_mask  \n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d562daed-a116-46e1-938d-9fe3a2c1f53f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWh...</td>\n",
              "      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nUs...</td>\n",
              "      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nCr...</td>\n",
              "      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWr...</td>\n",
              "      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nTh...</td>\n",
              "      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d562daed-a116-46e1-938d-9fe3a2c1f53f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d562daed-a116-46e1-938d-9fe3a2c1f53f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d562daed-a116-46e1-938d-9fe3a2c1f53f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8cc2ff94-5371-480b-a039-bfe64541a78e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8cc2ff94-5371-480b-a039-bfe64541a78e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8cc2ff94-5371-480b-a039-bfe64541a78e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_dataset\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"prompt\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"<|start_header_id|>user<|end_header_id|>\\n\\nUse the method of cylindrical shells to find the volume of the solid generated by revolving the region bounded by y=x^2 and y=4 about the y-axis.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nTo use the method of cylindrical shells, we first need to find the radius and height of each shell. The radius will be the distance from the y-axis to the curve y=x^2, which is just x. The height of each shell will be the difference between the two curves, which in this case is 4 - x^2.\\n\\nNow we'll set up the integral for the volume using cylindrical shells:\\n\\nV = \\u222b[0, 2] 2\\u03c0 * x * (4 - x^2) dx\\n\\nTo evaluate this integral, we can distribute the x inside the parentheses and then integrate term by term:\\n\\nV = 2\\u03c0\\u222b[0, 2] (4x - x^3) dx\\nV = 2\\u03c0 [2x^2 - (1/4)x^4] evaluated from 0 to 2\\nV = 2\\u03c0 [(2(2)^2 - (1/4)(2)^4) - (2(0)^2 - (1/4)(0)^4)]\\nV = 2\\u03c0 [16 - 8]\\nV = 2\\u03c0 [8]\\n\\nSo the volume of the solid generated by revolving the region bounded by y=x^2 and y=4 about the y-axis is 16\\u03c0 cubic units.\\n<|eot_id|>\",\n          \"<|start_header_id|>user<|end_header_id|>\\n\\nThe following formula is computationally intensive and inefficient due to repeated calculation of the same factor:\\n\\n$$\\n\\\\frac{x^n}{n!}\\n$$\\n\\nDevelop a Python function `fast_formula(x, n)` that optimizes the above formula for computing $e^x$, where $n$ is an arbitrary integer. The function should compute the factorial of `n` only once and cache it for future use. The total number of computations should be equal or less than $2n$.\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nBy caching the factorial of `n`, we can reduce the number of computations from $2n$ to $n + 1$ since the factorial of `n` is computed only once.\\n\\n```python\\ndef fast_formula(x, n):\\n    factorial = 1\\n    for i in range(1, n + 1):\\n        factorial *= i\\n    return (x ** n) / factorial\\n```\\n<|eot_id|>\",\n          \"<|start_header_id|>user<|end_header_id|>\\n\\nCreate a solution in Inform 7 to the following:\\n\\nBasic Data Operation\\n\\nThis is a basic data operation. It represents a fundamental action on a basic data type.\\nYou may see other such operations in the Basic Data Operations category, or:\\n\\n\\nInteger Operations\\nArithmetic |\\nComparison\\nBoolean Operations\\nBitwise |\\nLogical\\nString Operations\\nConcatenation |\\nInterpolation |\\nComparison |\\nMatching\\nMemory Operations\\nPointers & references |\\nAddresses\\n\\n\\nTask\\n\\nGet two integers from the user, \\u00a0 and then (for those two integers), display their:\\n\\n \\u00a0 sum \\n \\u00a0 difference \\n \\u00a0 product \\n \\u00a0 integer quotient\\n \\u00a0 remainder \\n \\u00a0 exponentiation \\u00a0 (if the operator exists) \\n\\n\\nDon't include error handling.\\n\\nFor quotient, indicate how it rounds \\u00a0 (e.g. towards zero, towards negative infinity, etc.).\\n\\nFor remainder, indicate whether its sign matches the sign of the first operand or of the second operand, if they are different.\\n\\n\\n\\n\\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nEnter Two Numbers is a room.\\n\\u00a0\\nNumerically entering is an action applying to one number. Understand \\\"[number]\\\" as numerically entering.\\n\\u00a0\\nThe first number is a number that varies.\\n\\u00a0\\nAfter numerically entering for the first time:\\n\\tnow the first number is the number understood.\\n\\u00a0\\nAfter numerically entering for the second time:\\n\\tlet A be the first number;\\n\\tlet B be the number understood;\\n\\tsay \\\"[A] + [B] = [A + B].\\\"; [operator syntax]\\n\\tsay \\\"[A] - [B] = [A minus B].\\\"; [English syntax]\\n\\tlet P be given by P = A * B where P is a number; [inline equation]\\n\\tsay \\\"[A] * [B] = [P].\\\";\\n\\tlet Q be given by the Division Formula; [named equation]\\n\\tsay \\\"[A] / [B] = [Q].\\\";\\n\\tsay \\\"[A] mod [B] = [remainder after dividing A by B].\\\";\\n\\tend the story.\\n\\u00a0\\nEquation - Division Formula\\n\\tQ = A / B\\nwhere Q is a number, A is a number, and B is a number.\\n<|eot_id|>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attention_mask\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['prompt'])"
      ],
      "metadata": {
        "id": "6PxxrK5Rd4gk",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:55:38.284174Z",
          "iopub.execute_input": "2024-11-01T01:55:38.285122Z",
          "iopub.status.idle": "2024-11-01T01:55:38.309201Z",
          "shell.execute_reply.started": "2024-11-01T01:55:38.28508Z",
          "shell.execute_reply": "2024-11-01T01:55:38.308261Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb240add-8508-4fc8-9306-a0471e920790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "What is the algorithm to detect if a linked list contains a cycle, and if a cycle is present, determine the node at which the cycle begins?\n",
            "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "The algorithm to detect cycle in linked list is famously known as Floyd's Cycle-Finding Algorithm, or the Tortoise and the Hare algorithm.\n",
            "\n",
            "Here's how the algorithm works:\n",
            "\n",
            "1. Initialize two pointers, slow and fast at the head of the linked list.\n",
            "2. Move slow pointer by one and fast pointer by two. If there's a cycle in the list, the fast pointer will eventually meet the slow pointer.\n",
            "3. When they meet, reset the slow pointer to the head while leaving the fast pointer at the meeting point.\n",
            "4. Now, advance both slow and fast pointers at the same pace, one step at a time. The point at which they meet now is the start of the cycle.\n",
            "\n",
            "Here's the code in Python:\n",
            "\n",
            "```python\n",
            "def detectCycle(head):\n",
            "    slow = fast = head\n",
            "    while fast and fast.next:\n",
            "        slow = slow.next\n",
            "        fast = fast.next.next\n",
            "        # cycle detected\n",
            "        if slow == fast:\n",
            "            break\n",
            "    else:\n",
            "        # No cycle\n",
            "        return None\n",
            "\n",
            "    # Find the starting node\n",
            "    slow = head\n",
            "    while slow != fast:\n",
            "        slow = slow.next\n",
            "        fast = fast.next\n",
            "    return slow\n",
            "```\n",
            "\n",
            "This code returns the node at which the cycle begins. If there is no cycle, it returns None.\n",
            "\n",
            "Also, the time complexity of this algorithm is O(n) and the space complexity is O(1), where n is the number of elements in the linked list.\n",
            "<|eot_id|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HR79ppIiE78f",
        "outputId": "f32f26dd-2055-4dfc-d0bf-848f2fd8a5c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91, 408, 8757, 842, 91, 1339, 3838, 374, 279, 12111, 311, 11140, 421, 264, 10592, 1140, 5610, 264, 10775, 11, 323, 421, 264, 10775, 374, 3042, 11, 8253, 279, 2436, 518, 892, 279, 10775, 12033, 5267, 27, 91, 68, 354, 842, 91, 1784, 91, 2468, 8757, 842, 91, 29, 77091, 27, 91, 408, 8757, 842, 91, 1339, 785, 12111, 311, 11140, 10775, 304, 10592, 1140, 374, 50187, 3881, 438, 45799, 594, 41292, 7276, 3961, 40325, 11, 476, 279, 55827, 68189, 323, 279, 472, 546, 12111, 382, 8420, 594, 1246, 279, 12111, 4278, 1447, 16, 13, 9008, 1378, 27454, 11, 6301, 323, 4937, 518, 279, 1968, 315, 279, 10592, 1140, 624, 17, 13, 14561, 6301, 7445, 553, 825, 323, 4937, 7445, 553, 1378, 13, 1416, 1052, 594, 264, 10775, 304, 279, 1140, 11, 279, 4937, 7445, 686, 9583, 3367, 279, 6301, 7445, 624, 18, 13, 3197, 807, 3367, 11, 7585, 279, 6301, 7445, 311, 279, 1968, 1393, 9380, 279, 4937, 7445, 518, 279, 6438, 1459, 624, 19, 13, 4695, 11, 11912, 2176, 6301, 323, 4937, 27454, 518, 279, 1852, 17857, 11, 825, 3019, 518, 264, 882, 13, 576, 1459, 518, 892, 807, 3367, 1431, 374, 279, 1191, 315, 279, 10775, 382, 8420, 594, 279, 2038, 304, 13027, 1447, 73594, 12669, 198, 750, 11140, 44820, 25340, 982, 262, 6301, 284, 4937, 284, 1968, 198, 262, 1393, 4937, 323, 4937, 4529, 510, 286, 6301, 284, 6301, 4529, 198, 286, 4937, 284, 4937, 4529, 4529, 198, 286, 671, 10775, 16507, 198, 286, 421, 6301, 621, 4937, 510, 310, 1438, 198, 262, 770, 510, 286, 671, 2308, 10775, 198, 286, 470, 2240, 271, 262, 671, 7379, 279, 5916, 2436, 198, 262, 6301, 284, 1968, 198, 262, 1393, 6301, 961, 4937, 510, 286, 6301, 284, 6301, 4529, 198, 286, 4937, 284, 4937, 4529, 198, 262, 470, 6301, 198, 13874, 19324, 1986, 2038, 4675, 279, 2436, 518, 892, 279, 10775, 12033, 13, 1416, 1052, 374, 902, 10775, 11, 432, 4675, 2240, 382, 13394, 11, 279, 882, 23094, 315, 419, 12111, 374, 506, 1445, 8, 323, 279, 3550, 23094, 374, 506, 7, 16, 701, 1380, 308, 374, 279, 1372, 315, 5424, 304, 279, 10592, 1140, 624, 27, 91, 68, 354, 842, 91, 29, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset[0]['attention_mask'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGmCvvZTE82D",
        "outputId": "1d115745-73ce-44b8-ffe4-55f969e56f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 07 Data Collator Set Up"
      ],
      "metadata": {
        "id": "JFX4u0vc0UkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)"
      ],
      "metadata": {
        "id": "F-mkiTYw0cZi",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:55:55.705822Z",
          "iopub.execute_input": "2024-11-01T01:55:55.706694Z",
          "iopub.status.idle": "2024-11-01T01:55:55.710707Z",
          "shell.execute_reply.started": "2024-11-01T01:55:55.706652Z",
          "shell.execute_reply": "2024-11-01T01:55:55.709734Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 08 Evaluation Metrics Set Up"
      ],
      "metadata": {
        "id": "hP1Mu0J6CTCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p: EvalPrediction):\n",
        "  preds = np.argmax(p.predictions, axis = 1)\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    p.label_ids,\n",
        "    preds,\n",
        "    average = 'weighted'\n",
        "  )\n",
        "  matrix = {\n",
        "    'accuracy': accuracy_score(p.label_ids, preds),\n",
        "    'f1': f1, 'precision': precision,\n",
        "    'recall': recall\n",
        "  }\n",
        "  return matrix"
      ],
      "metadata": {
        "id": "wzNdWpCI0c7a",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:45:45.216052Z",
          "iopub.status.idle": "2024-11-01T01:45:45.216532Z",
          "shell.execute_reply.started": "2024-11-01T01:45:45.216283Z",
          "shell.execute_reply": "2024-11-01T01:45:45.216309Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tEkgHY4fxFIJ",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:56:07.93188Z",
          "iopub.execute_input": "2024-11-01T01:56:07.932801Z",
          "iopub.status.idle": "2024-11-01T01:56:07.940504Z",
          "shell.execute_reply.started": "2024-11-01T01:56:07.93274Z",
          "shell.execute_reply": "2024-11-01T01:56:07.93939Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 09 Set Up PEFT / LoRA / QLoRA"
      ],
      "metadata": {
        "id": "VLFCnU8-ZoUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "lora_r = 64\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n",
        "peft_config = LoraConfig(\n",
        "  lora_alpha = lora_alpha,\n",
        "  lora_dropout = lora_dropout,\n",
        "  r = lora_r,\n",
        "  bias = 'none',\n",
        "  task_type = 'CAUSAL_LM',\n",
        "  target_modules = target_modules,\n",
        ")"
      ],
      "metadata": {
        "id": "67HK09faZqQh",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:56:14.556857Z",
          "iopub.execute_input": "2024-11-01T01:56:14.557249Z",
          "iopub.status.idle": "2024-11-01T01:56:14.56268Z",
          "shell.execute_reply.started": "2024-11-01T01:56:14.557213Z",
          "shell.execute_reply": "2024-11-01T01:56:14.561555Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = get_peft_model(model, peft_config, adapter_name = 'math')\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "3ZPOifXCZuhg",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:56:17.099733Z",
          "iopub.execute_input": "2024-11-01T01:56:17.100125Z",
          "iopub.status.idle": "2024-11-01T01:56:17.304006Z",
          "shell.execute_reply.started": "2024-11-01T01:56:17.100086Z",
          "shell.execute_reply": "2024-11-01T01:56:17.302927Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f008900-71ef-4db1-ab09-6f35467fdce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 35,192,832 || all params: 529,225,600 || trainable%: 6.6499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Training Model"
      ],
      "metadata": {
        "id": "CVr-LToX1XCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "ikF6Yfkz1myd",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:56:22.602531Z",
          "iopub.execute_input": "2024-11-01T01:56:22.603401Z",
          "iopub.status.idle": "2024-11-01T01:56:22.6141Z",
          "shell.execute_reply.started": "2024-11-01T01:56:22.603357Z",
          "shell.execute_reply": "2024-11-01T01:56:22.613118Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7887f724-35f5-4845-bc2e-473f5d09b5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2SdpaAttention(\n",
              "          (q_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=896, out_features=896, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (math): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (math): Linear(in_features=64, out_features=896, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (k_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (math): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (math): Linear(in_features=64, out_features=128, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (v_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (math): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (math): Linear(in_features=64, out_features=128, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (o_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=896, out_features=896, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (math): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (math): Linear(in_features=64, out_features=896, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (math): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (math): Linear(in_features=64, out_features=4864, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (up_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (math): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (math): Linear(in_features=64, out_features=4864, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (down_proj): lora.Linear4bit(\n",
              "            (base_layer): Linear4bit(in_features=4864, out_features=896, bias=False)\n",
              "            (lora_dropout): ModuleDict(\n",
              "              (math): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (lora_A): ModuleDict(\n",
              "              (math): Linear(in_features=4864, out_features=64, bias=False)\n",
              "            )\n",
              "            (lora_B): ModuleDict(\n",
              "              (math): Linear(in_features=64, out_features=896, bias=False)\n",
              "            )\n",
              "            (lora_embedding_A): ParameterDict()\n",
              "            (lora_embedding_B): ParameterDict()\n",
              "            (lora_magnitude_vector): ModuleDict()\n",
              "          )\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "uhliEMyp1thd",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:57:28.09859Z",
          "iopub.execute_input": "2024-11-01T01:57:28.099013Z",
          "iopub.status.idle": "2024-11-01T01:57:28.11006Z",
          "shell.execute_reply.started": "2024-11-01T01:57:28.098976Z",
          "shell.execute_reply": "2024-11-01T01:57:28.109013Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83f77b0-922b-440c-fc31-f667cba8263c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters : 350312320\n",
            "Trainable parameters : 35192832\n",
            "Trainable percentage: 10.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Xn5zb6xWJtu-",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:59:28.004274Z",
          "iopub.execute_input": "2024-11-01T01:59:28.005068Z",
          "iopub.status.idle": "2024-11-01T01:59:28.436467Z",
          "shell.execute_reply.started": "2024-11-01T01:59:28.005028Z",
          "shell.execute_reply": "2024-11-01T01:59:28.435427Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = './model'\n",
        "\n",
        "batch_size = 2\n",
        "max_steps = 200\n",
        "training_args = TrainingArguments(\n",
        "  output_dir = save_path,\n",
        "  gradient_accumulation_steps = 4,\n",
        "  evaluation_strategy = 'steps',\n",
        "  do_eval = True,\n",
        "  per_device_train_batch_size = batch_size,\n",
        "  per_device_eval_batch_size = 4,\n",
        "  log_level = 'debug',\n",
        "  save_strategy = 'no',\n",
        "  save_total_limit = 2,\n",
        "  save_safetensors = False,\n",
        "  fp16 = False,\n",
        "  logging_steps = 20,\n",
        "  learning_rate = 2e-5,\n",
        "  eval_steps = 20,\n",
        "  max_steps = max_steps,\n",
        "  warmup_steps = 30,\n",
        "  lr_scheduler_type = 'cosine',\n",
        ")\n",
        "training_args"
      ],
      "metadata": {
        "id": "93ffvb0d4cG6",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:59:33.062891Z",
          "iopub.execute_input": "2024-11-01T01:59:33.063776Z",
          "iopub.status.idle": "2024-11-01T01:59:33.107653Z",
          "shell.execute_reply.started": "2024-11-01T01:59:33.063733Z",
          "shell.execute_reply": "2024-11-01T01:59:33.106385Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51990c51-905e-49af-f59b-02622ae313bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainingArguments(\n",
              "_n_gpu=1,\n",
              "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
              "adafactor=False,\n",
              "adam_beta1=0.9,\n",
              "adam_beta2=0.999,\n",
              "adam_epsilon=1e-08,\n",
              "auto_find_batch_size=False,\n",
              "average_tokens_across_devices=False,\n",
              "batch_eval_metrics=False,\n",
              "bf16=False,\n",
              "bf16_full_eval=False,\n",
              "data_seed=None,\n",
              "dataloader_drop_last=False,\n",
              "dataloader_num_workers=0,\n",
              "dataloader_persistent_workers=False,\n",
              "dataloader_pin_memory=True,\n",
              "dataloader_prefetch_factor=None,\n",
              "ddp_backend=None,\n",
              "ddp_broadcast_buffers=None,\n",
              "ddp_bucket_cap_mb=None,\n",
              "ddp_find_unused_parameters=None,\n",
              "ddp_timeout=1800,\n",
              "debug=[],\n",
              "deepspeed=None,\n",
              "disable_tqdm=False,\n",
              "dispatch_batches=None,\n",
              "do_eval=True,\n",
              "do_predict=False,\n",
              "do_train=False,\n",
              "eval_accumulation_steps=None,\n",
              "eval_delay=0,\n",
              "eval_do_concat_batches=True,\n",
              "eval_on_start=False,\n",
              "eval_steps=20,\n",
              "eval_strategy=steps,\n",
              "eval_use_gather_object=False,\n",
              "evaluation_strategy=steps,\n",
              "fp16=False,\n",
              "fp16_backend=auto,\n",
              "fp16_full_eval=False,\n",
              "fp16_opt_level=O1,\n",
              "fsdp=[],\n",
              "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
              "fsdp_min_num_params=0,\n",
              "fsdp_transformer_layer_cls_to_wrap=None,\n",
              "full_determinism=False,\n",
              "gradient_accumulation_steps=4,\n",
              "gradient_checkpointing=False,\n",
              "gradient_checkpointing_kwargs=None,\n",
              "greater_is_better=None,\n",
              "group_by_length=False,\n",
              "half_precision_backend=auto,\n",
              "hub_always_push=False,\n",
              "hub_model_id=None,\n",
              "hub_private_repo=False,\n",
              "hub_strategy=every_save,\n",
              "hub_token=<HUB_TOKEN>,\n",
              "ignore_data_skip=False,\n",
              "include_for_metrics=[],\n",
              "include_inputs_for_metrics=False,\n",
              "include_num_input_tokens_seen=False,\n",
              "include_tokens_per_second=False,\n",
              "jit_mode_eval=False,\n",
              "label_names=None,\n",
              "label_smoothing_factor=0.0,\n",
              "learning_rate=2e-05,\n",
              "length_column_name=length,\n",
              "load_best_model_at_end=False,\n",
              "local_rank=0,\n",
              "log_level=debug,\n",
              "log_level_replica=warning,\n",
              "log_on_each_node=True,\n",
              "logging_dir=./model/runs/Nov12_08-44-24_3e8c82c0a4a2,\n",
              "logging_first_step=False,\n",
              "logging_nan_inf_filter=True,\n",
              "logging_steps=20,\n",
              "logging_strategy=steps,\n",
              "lr_scheduler_kwargs={},\n",
              "lr_scheduler_type=cosine,\n",
              "max_grad_norm=1.0,\n",
              "max_steps=200,\n",
              "metric_for_best_model=None,\n",
              "mp_parameters=,\n",
              "neftune_noise_alpha=None,\n",
              "no_cuda=False,\n",
              "num_train_epochs=3.0,\n",
              "optim=adamw_torch,\n",
              "optim_args=None,\n",
              "optim_target_modules=None,\n",
              "output_dir=./model,\n",
              "overwrite_output_dir=False,\n",
              "past_index=-1,\n",
              "per_device_eval_batch_size=4,\n",
              "per_device_train_batch_size=2,\n",
              "prediction_loss_only=False,\n",
              "push_to_hub=False,\n",
              "push_to_hub_model_id=None,\n",
              "push_to_hub_organization=None,\n",
              "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
              "ray_scope=last,\n",
              "remove_unused_columns=True,\n",
              "report_to=['tensorboard', 'wandb'],\n",
              "restore_callback_states_from_checkpoint=False,\n",
              "resume_from_checkpoint=None,\n",
              "run_name=./model,\n",
              "save_on_each_node=False,\n",
              "save_only_model=False,\n",
              "save_safetensors=False,\n",
              "save_steps=500,\n",
              "save_strategy=no,\n",
              "save_total_limit=2,\n",
              "seed=42,\n",
              "skip_memory_metrics=True,\n",
              "split_batches=None,\n",
              "tf32=None,\n",
              "torch_compile=False,\n",
              "torch_compile_backend=None,\n",
              "torch_compile_mode=None,\n",
              "torch_empty_cache_steps=None,\n",
              "torchdynamo=None,\n",
              "tpu_metrics_debug=False,\n",
              "tpu_num_cores=None,\n",
              "use_cpu=False,\n",
              "use_ipex=False,\n",
              "use_legacy_prediction_loop=False,\n",
              "use_liger_kernel=False,\n",
              "use_mps_device=False,\n",
              "warmup_ratio=0.0,\n",
              "warmup_steps=30,\n",
              "weight_decay=0.0,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "  model = model,\n",
        "  train_dataset = train_dataset,#.select(range(10000)),\n",
        "  eval_dataset = test_dataset.select(range(1000)),\n",
        "  dataset_text_field = 'prompt',\n",
        "  max_seq_length = max_length,\n",
        "  tokenizer = tokenizer,\n",
        "  args = training_args,\n",
        "  peft_config = peft_config,\n",
        ")\n",
        "trainer"
      ],
      "metadata": {
        "id": "EsKeJE3SMdk7",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:59:41.365555Z",
          "iopub.execute_input": "2024-11-01T01:59:41.366329Z",
          "iopub.status.idle": "2024-11-01T01:59:41.554118Z",
          "shell.execute_reply.started": "2024-11-01T01:59:41.366287Z",
          "shell.execute_reply": "2024-11-01T01:59:41.553243Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20af63fa-51d3-4861-bd7b-49107906a545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n",
            "\n",
            "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<trl.trainer.sft_trainer.SFTTrainer at 0x7fb0af7da110>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MZVoQX8V1cI3",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:59:44.927085Z",
          "iopub.execute_input": "2024-11-01T01:59:44.927496Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06ba4b4e-cd9a-4056-8c04-4feb5795446f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Currently training with a batch size of: 2\n",
            "The following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 90,000\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 2\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 200\n",
            "  Number of trainable parameters = 35,192,832\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241112_084428-fiiwz8j4</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/fiiwz8j4' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/fiiwz8j4' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/fiiwz8j4</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='41' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 41/200 07:53 < 32:09, 0.08 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.345500</td>\n",
              "      <td>1.312746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='93' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 93/250 01:33 < 02:39, 0.99 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n",
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 1:00:57, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.345500</td>\n",
              "      <td>1.312746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.234200</td>\n",
              "      <td>1.218575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.167200</td>\n",
              "      <td>1.095166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.096000</td>\n",
              "      <td>1.053129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.004300</td>\n",
              "      <td>1.035356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.082200</td>\n",
              "      <td>1.023565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.011600</td>\n",
              "      <td>1.014683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.025600</td>\n",
              "      <td>1.009678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.975600</td>\n",
              "      <td>1.007857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.003100</td>\n",
              "      <td>1.007593</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n",
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n",
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n",
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n",
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n",
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n",
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n",
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=1.094542646408081, metrics={'train_runtime': 3667.9152, 'train_samples_per_second': 0.436, 'train_steps_per_second': 0.055, 'total_flos': 4210200831590400.0, 'train_loss': 1.094542646408081, 'epoch': 0.017777777777777778})"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11 Model Evaluation"
      ],
      "metadata": {
        "id": "v5N6fZsU1xiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = trainer.evaluate()\n",
        "print('Evaluation Results:', evaluation_results)"
      ],
      "metadata": {
        "id": "5d6DT3o0113O",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:45:45.234814Z",
          "iopub.status.idle": "2024-11-01T01:45:45.235147Z",
          "shell.execute_reply.started": "2024-11-01T01:45:45.234981Z",
          "shell.execute_reply": "2024-11-01T01:45:45.234998Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8ae90bba-d345-4680-cf92-03f378ae045e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 04:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_loss': 1.0075932741165161, 'eval_runtime': 253.4713, 'eval_samples_per_second': 3.945, 'eval_steps_per_second': 0.986, 'epoch': 0.017777777777777778}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12 Save Model"
      ],
      "metadata": {
        "id": "PjTPWhCj4JQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "save_model.save_pretrained(save_path)"
      ],
      "metadata": {
        "id": "OKAmko8h2VeV",
        "execution": {
          "iopub.status.busy": "2024-11-01T01:45:45.236623Z",
          "iopub.status.idle": "2024-11-01T01:45:45.236959Z",
          "shell.execute_reply.started": "2024-11-01T01:45:45.236785Z",
          "shell.execute_reply": "2024-11-01T01:45:45.236802Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13 Load PEFT Model"
      ],
      "metadata": {
        "id": "3NhWAM5h9Rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "dlTaH2HoC26T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model = PeftModel.from_pretrained(model, save_path)\n",
        "peft_model"
      ],
      "metadata": {
        "id": "Nz2HT8nb9XJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be8cac5-7d04-4d1f-a6c1-d9c62e9db771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Qwen2ForCausalLM(\n",
              "      (model): Qwen2Model(\n",
              "        (embed_tokens): Embedding(151936, 896)\n",
              "        (layers): ModuleList(\n",
              "          (0-23): 24 x Qwen2DecoderLayer(\n",
              "            (self_attn): Qwen2SdpaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=896, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (math): Dropout(p=0.1, inplace=False)\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "                  (default): Linear(in_features=896, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (math): Linear(in_features=64, out_features=896, bias=False)\n",
              "                  (default): Linear(in_features=64, out_features=896, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (math): Dropout(p=0.1, inplace=False)\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "                  (default): Linear(in_features=896, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (math): Linear(in_features=64, out_features=128, bias=False)\n",
              "                  (default): Linear(in_features=64, out_features=128, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (math): Dropout(p=0.1, inplace=False)\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "                  (default): Linear(in_features=896, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (math): Linear(in_features=64, out_features=128, bias=False)\n",
              "                  (default): Linear(in_features=64, out_features=128, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=896, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (math): Dropout(p=0.1, inplace=False)\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "                  (default): Linear(in_features=896, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (math): Linear(in_features=64, out_features=896, bias=False)\n",
              "                  (default): Linear(in_features=64, out_features=896, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (rotary_emb): Qwen2RotaryEmbedding()\n",
              "            )\n",
              "            (mlp): Qwen2MLP(\n",
              "              (gate_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (math): Dropout(p=0.1, inplace=False)\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "                  (default): Linear(in_features=896, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (math): Linear(in_features=64, out_features=4864, bias=False)\n",
              "                  (default): Linear(in_features=64, out_features=4864, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (up_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (math): Dropout(p=0.1, inplace=False)\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (math): Linear(in_features=896, out_features=64, bias=False)\n",
              "                  (default): Linear(in_features=896, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (math): Linear(in_features=64, out_features=4864, bias=False)\n",
              "                  (default): Linear(in_features=64, out_features=4864, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (down_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4864, out_features=896, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (math): Dropout(p=0.1, inplace=False)\n",
              "                  (default): Dropout(p=0.1, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (math): Linear(in_features=4864, out_features=64, bias=False)\n",
              "                  (default): Linear(in_features=4864, out_features=64, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (math): Linear(in_features=64, out_features=896, bias=False)\n",
              "                  (default): Linear(in_features=64, out_features=896, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "            (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "          )\n",
              "        )\n",
              "        (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (rotary_emb): Qwen2RotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "trainable_percentage = (trainable_params / total_params) * 100\n",
        "\n",
        "print('Total parameters :', total_params)\n",
        "print('Trainable parameters :', trainable_params)\n",
        "print('Trainable percentage: {:.2f}%'.format(trainable_percentage))"
      ],
      "metadata": {
        "id": "eepaD3O-9t3H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac9b9a5-b011-4d3d-d476-d2ec66c78f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters : 385505152\n",
            "Trainable parameters : 0\n",
            "Trainable percentage: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 14 Post Test"
      ],
      "metadata": {
        "id": "GrXYkyb89UJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assistant(prompt):\n",
        "  messages = [\n",
        "    {'role' : 'human', 'content' : prompt},\n",
        "  ]\n",
        "  inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True,\n",
        "    return_tensors = 'pt',\n",
        "  ).to('cuda')\n",
        "  generation_config = GenerationConfig(\n",
        "    do_sample = True,\n",
        "    top_k = 1,\n",
        "    temperature = 0.1,\n",
        "    max_new_tokens = 1024,\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "  )\n",
        "  outputs = peft_model.generate(\n",
        "    input_ids = inputs,\n",
        "    generation_config = generation_config\n",
        "  )\n",
        "  return print(tokenizer.decode(outputs[0]))#, skip_special_tokens = True))"
      ],
      "metadata": {
        "id": "lgVU8Ci9RMu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "Summarize the following legal text in a few sentences:\n",
        "\n",
        "'In the case of John Doe v. XYZ Corp, the plaintiff, John Doe, entered into a formal service contract with XYZ Corp in January 2022. The agreement stipulated a one-year commitment for IT support services, with John Doe providing on-site troubleshooting, software updates, and system maintenance. XYZ Corp agreed to pay a fixed monthly retainer along with additional fees for after-hours support. However, in June 2022, XYZ Corp terminated the contract without prior notice, claiming that an unexpected downturn in business operations left them financially unable to continue. The plaintiff alleges wrongful termination, asserting that XYZ Corp failed to adhere to the 60-day notice clause outlined in the contract. Additionally, the plaintiff contends that the early termination damaged his professional reputation and resulted in significant financial losses, including missed client opportunities and incurred expenses for certifications specific to XYZ Corp’s systems. John Doe is seeking compensation for the remaining contract balance, damages for reputational harm, and reimbursement for training and certification costs required under the agreement.\n",
        "'''\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "id": "JlEhdEGGTN6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e555cf74-9e53-49c9-aaae-6d6cf1773be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?\n",
            "🤨\n",
            "You are a helpful assistant.🤨\n",
            "AILABLE\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What are the legal implications if a party violates a confidentiality agreement in the context of contract law? For example, consider a scenario where a contractor working with Tech Innovators Inc. shares proprietary technology information with a competitor. Explain in detail and cite relevant case law where possible.\"\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "id": "BxmnFTADTQsT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9eb1ed6-6d9d-42b7-ee96-11b2afa65c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?\n",
            "🤨\n",
            "You are a helpful assistant.🤨\n",
            "AILABLE\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Rephrase the following legal statement to make it more understandable for a general audience: 'Under the terms of the non-compete agreement, the defendant is barred from engaging in any business that competes with the plaintiff's business within a 50-mile radius for two years following the termination of employment.' Retain all key information while simplifying the language.\"\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "id": "RDONbvZKTTqs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a63d3d-0b2f-4904-ce10-54bf472b37ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?\n",
            "🤨\n",
            "You are a helpful assistant.🤨\n",
            "AILABLE\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"In the case where a defendant claims breach of contract due to unforeseeable events, how does the principle of 'force majeure' apply? For instance, if a company was unable to deliver contracted goods due to a natural disaster, provide a detailed explanation and outline any relevant conditions under which the force majeure principle might or might not be applicable.\"\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "id": "p7dBkB_7TjZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91a5c25-7fe8-470b-a6f3-68cf10d3fbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?\n",
            "🤨\n",
            "You are a helpful assistant.🤨\n",
            "AILABLE\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Construct an argument in defense of a client accused of breaching intellectual property laws due to sharing copyrighted material in an educational setting. For example, a teacher shares portions of a textbook with students to support classroom discussion. Focus on any legal exceptions or defenses that may apply, such as the fair use doctrine in educational contexts.\"\n",
        "assistant(prompt)"
      ],
      "metadata": {
        "id": "BUPoJAmnTnCq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2babe29c-f60d-4cf3-c252-3cdd4e63e7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>assistant\n",
            "Sure, I can help you with that. What would you like to know?\n",
            "🤨\n",
            "You are a helpful assistant.🤨\n",
            "AILABLE\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.🤨\n",
            "Available\n",
            "You are a helpful assistant.\n"
          ]
        }
      ]
    }
  ]
}