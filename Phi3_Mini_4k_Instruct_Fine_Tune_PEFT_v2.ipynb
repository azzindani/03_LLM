{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-24T07:39:24.808896Z","iopub.execute_input":"2024-11-24T07:39:24.809686Z","iopub.status.idle":"2024-11-24T07:39:58.715072Z","shell.execute_reply.started":"2024-11-24T07:39:24.809639Z","shell.execute_reply":"2024-11-24T07:39:58.713870Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-11-24T07:39:58.717133Z","iopub.execute_input":"2024-11-24T07:39:58.717504Z","iopub.status.idle":"2024-11-24T07:40:09.147062Z","shell.execute_reply.started":"2024-11-24T07:39:58.717473Z","shell.execute_reply":"2024-11-24T07:40:09.146157Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-11-24T07:40:09.148389Z","iopub.execute_input":"2024-11-24T07:40:09.149485Z","iopub.status.idle":"2024-11-24T07:40:09.156115Z","shell.execute_reply.started":"2024-11-24T07:40:09.149442Z","shell.execute_reply":"2024-11-24T07:40:09.155281Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'microsoft/Phi-3-mini-4k-instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-24T07:40:09.157742Z","iopub.execute_input":"2024-11-24T07:40:09.158068Z","iopub.status.idle":"2024-11-24T07:40:09.170117Z","shell.execute_reply.started":"2024-11-24T07:40:09.158042Z","shell.execute_reply":"2024-11-24T07:40:09.169380Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-11-24T07:40:09.170930Z","iopub.execute_input":"2024-11-24T07:40:09.171168Z","iopub.status.idle":"2024-11-24T07:40:09.181450Z","shell.execute_reply.started":"2024-11-24T07:40:09.171144Z","shell.execute_reply":"2024-11-24T07:40:09.180618Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:40:09.182600Z","iopub.execute_input":"2024-11-24T07:40:09.182884Z","iopub.status.idle":"2024-11-24T07:43:50.981057Z","shell.execute_reply.started":"2024-11-24T07:40:09.182857Z","shell.execute_reply":"2024-11-24T07:43:50.979978Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2e918b843424e1f901b779add910905"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6967a8c8afd4ffb8561c2e4fd8153cd"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- configuration_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac3445b2dc354aeeb1877218a9cc5ba6"}},"metadata":{}},{"name":"stderr","text":"A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n- modeling_phi3.py\n. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c857193f46e6474992c22b14f57d26f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05a7f3adcb174120aeb5f173137f3269"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"359c89c075704a1d940f50b8107cbf12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7940a38867a54e91bec40b59d121260b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e331452235ea4038ae287c7492cfadc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a21e827b9c9045678154ea6b7b8523f1"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3RotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm()\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm()\n      )\n    )\n    (norm): Phi3RMSNorm()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:50.982277Z","iopub.execute_input":"2024-11-24T07:43:50.982629Z","iopub.status.idle":"2024-11-24T07:43:50.989921Z","shell.execute_reply.started":"2024-11-24T07:43:50.982589Z","shell.execute_reply":"2024-11-24T07:43:50.989137Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 2009140224\nTrainable parameters : 197200896\nTrainable percentage: 9.82%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:50.990970Z","iopub.execute_input":"2024-11-24T07:43:50.991213Z","iopub.status.idle":"2024-11-24T07:43:51.936110Z","shell.execute_reply.started":"2024-11-24T07:43:50.991189Z","shell.execute_reply":"2024-11-24T07:43:51.935401Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"795e28327e9c43d28490cff6a6523ac2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4687060bfd0943b38548fa84147176c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f6449c37ec64b2695e2b3aa559092a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1521bdf48c864a20a179f67cf38cba96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8640989217b4c308537566ad33af187"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'yahma/alpaca-cleaned'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:51.937148Z","iopub.execute_input":"2024-11-24T07:43:51.937425Z","iopub.status.idle":"2024-11-24T07:43:51.941435Z","shell.execute_reply.started":"2024-11-24T07:43:51.937398Z","shell.execute_reply":"2024-11-24T07:43:51.940508Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 512","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:51.945083Z","iopub.execute_input":"2024-11-24T07:43:51.945531Z","iopub.status.idle":"2024-11-24T07:43:51.953271Z","shell.execute_reply.started":"2024-11-24T07:43:51.945501Z","shell.execute_reply":"2024-11-24T07:43:51.952464Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:51.954457Z","iopub.execute_input":"2024-11-24T07:43:51.955064Z","iopub.status.idle":"2024-11-24T07:43:53.372592Z","shell.execute_reply.started":"2024-11-24T07:43:51.955025Z","shell.execute_reply":"2024-11-24T07:43:53.371545Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.373794Z","iopub.execute_input":"2024-11-24T07:43:53.374094Z","iopub.status.idle":"2024-11-24T07:43:53.380987Z","shell.execute_reply.started":"2024-11-24T07:43:53.374068Z","shell.execute_reply":"2024-11-24T07:43:53.380059Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.382039Z","iopub.execute_input":"2024-11-24T07:43:53.382346Z","iopub.status.idle":"2024-11-24T07:43:53.594307Z","shell.execute_reply.started":"2024-11-24T07:43:53.382319Z","shell.execute_reply":"2024-11-24T07:43:53.593514Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.595719Z","iopub.execute_input":"2024-11-24T07:43:53.596363Z","iopub.status.idle":"2024-11-24T07:43:53.602164Z","shell.execute_reply.started":"2024-11-24T07:43:53.596316Z","shell.execute_reply":"2024-11-24T07:43:53.601264Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.603321Z","iopub.execute_input":"2024-11-24T07:43:53.603620Z","iopub.status.idle":"2024-11-24T07:43:53.612023Z","shell.execute_reply.started":"2024-11-24T07:43:53.603561Z","shell.execute_reply":"2024-11-24T07:43:53.611117Z"}},"outputs":[{"name":"stdout","text":"['output', 'input', 'instruction']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.613156Z","iopub.execute_input":"2024-11-24T07:43:53.613461Z","iopub.status.idle":"2024-11-24T07:43:53.621880Z","shell.execute_reply.started":"2024-11-24T07:43:53.613437Z","shell.execute_reply":"2024-11-24T07:43:53.620900Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  instruction = examples['instruction']\n  input = examples['input']\n  output = examples['output']\n  \n  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.622848Z","iopub.execute_input":"2024-11-24T07:43:53.623104Z","iopub.status.idle":"2024-11-24T07:43:53.633817Z","shell.execute_reply.started":"2024-11-24T07:43:53.623078Z","shell.execute_reply":"2024-11-24T07:43:53.632924Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.634828Z","iopub.execute_input":"2024-11-24T07:43:53.635080Z","iopub.status.idle":"2024-11-24T07:43:53.648416Z","shell.execute_reply.started":"2024-11-24T07:43:53.635055Z","shell.execute_reply":"2024-11-24T07:43:53.647549Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.649297Z","iopub.execute_input":"2024-11-24T07:43:53.649549Z","iopub.status.idle":"2024-11-24T07:43:53.704875Z","shell.execute_reply.started":"2024-11-24T07:43:53.649519Z","shell.execute_reply":"2024-11-24T07:43:53.703961Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|endoftext|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.706080Z","iopub.execute_input":"2024-11-24T07:43:53.706485Z","iopub.status.idle":"2024-11-24T07:43:53.714808Z","shell.execute_reply.started":"2024-11-24T07:43:53.706445Z","shell.execute_reply":"2024-11-24T07:43:53.714113Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:43:53.715856Z","iopub.execute_input":"2024-11-24T07:43:53.716154Z","iopub.status.idle":"2024-11-24T07:44:03.013235Z","shell.execute_reply.started":"2024-11-24T07:43:53.716128Z","shell.execute_reply":"2024-11-24T07:44:03.012253Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25c60011932b4055a9961a8d263e9e7e"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.014413Z","iopub.execute_input":"2024-11-24T07:44:03.014706Z","iopub.status.idle":"2024-11-24T07:44:03.020062Z","shell.execute_reply.started":"2024-11-24T07:44:03.014680Z","shell.execute_reply":"2024-11-24T07:44:03.019188Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|endoftext|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.021122Z","iopub.execute_input":"2024-11-24T07:44:03.021388Z","iopub.status.idle":"2024-11-24T07:44:03.101775Z","shell.execute_reply.started":"2024-11-24T07:44:03.021363Z","shell.execute_reply":"2024-11-24T07:44:03.101007Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.102826Z","iopub.execute_input":"2024-11-24T07:44:03.103123Z","iopub.status.idle":"2024-11-24T07:44:03.114162Z","shell.execute_reply.started":"2024-11-24T07:44:03.103067Z","shell.execute_reply":"2024-11-24T07:44:03.113305Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.115057Z","iopub.execute_input":"2024-11-24T07:44:03.115317Z","iopub.status.idle":"2024-11-24T07:44:03.142245Z","shell.execute_reply.started":"2024-11-24T07:44:03.115293Z","shell.execute_reply":"2024-11-24T07:44:03.141436Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n1  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n2  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n3  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n4  [32000, 32000, 32000, 32000, 32000, 32000, 320...   \n\n                                      attention_mask  \n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[32000, 32000, 32000, 32000, 32000, 32000, 320...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.143404Z","iopub.execute_input":"2024-11-24T07:44:03.143783Z","iopub.status.idle":"2024-11-24T07:44:03.149021Z","shell.execute_reply.started":"2024-11-24T07:44:03.143744Z","shell.execute_reply":"2024-11-24T07:44:03.148212Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|endoftext|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.150080Z","iopub.execute_input":"2024-11-24T07:44:03.150415Z","iopub.status.idle":"2024-11-24T07:44:03.159844Z","shell.execute_reply.started":"2024-11-24T07:44:03.150372Z","shell.execute_reply":"2024-11-24T07:44:03.159070Z"}},"outputs":[{"name":"stdout","text":"[32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2744, 14997, 911, 278, 2183, 26576, 322, 12439, 967, 1667, 10929, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 13985, 25320, 17089, 3192, 297, 263, 13328, 8112, 2053, 29876, 2855, 7423, 306, 1033, 451, 9850, 1716, 29905, 29876, 2855, 367, 697, 9850, 261, 29892, 1472, 306, 8389, 29905, 29876, 2855, 5148, 1623, 697, 408, 2215, 408, 306, 1033, 29905, 29876, 1762, 988, 372, 26148, 297, 278, 1090, 29887, 798, 386, 10436, 29876, 29905, 29876, 11760, 3614, 278, 916, 29892, 408, 925, 408, 6534, 2053, 29876, 2855, 2534, 6060, 278, 2253, 5995, 2053, 29876, 29933, 5658, 372, 471, 17455, 29891, 322, 5131, 19531, 10436, 29876, 1349, 820, 408, 363, 393, 278, 6819, 727, 29905, 29876, 29950, 328, 28043, 963, 2289, 1048, 278, 1021, 2053, 29876, 1576, 25320, 393, 7250, 18018, 6568, 29905, 29876, 797, 11308, 694, 4331, 750, 3147, 29881, 1145, 4628, 7790, 29876, 9048, 29892, 306, 2175, 278, 937, 363, 1790, 2462, 9903, 29876, 29979, 300, 13797, 920, 982, 11981, 373, 304, 982, 2053, 29876, 29902, 7404, 287, 565, 306, 881, 3926, 2041, 1250, 7790, 29876, 29905, 29876, 29902, 4091, 367, 14509, 445, 411, 263, 269, 1141, 29905, 29876, 9526, 3062, 24646, 322, 24646, 8151, 3583, 29876, 13985, 25320, 17089, 3192, 297, 263, 8112, 29892, 322, 306, 30003, 29905, 29876, 29902, 3614, 278, 697, 3109, 1020, 345, 839, 491, 2053, 29876, 2855, 393, 756, 1754, 599, 278, 4328, 29889, 13, 13, 2277, 29937, 13291, 29901, 13, 1576, 1667, 10929, 310, 278, 26576, 338, 278, 13500, 310, 3907, 19995, 322, 278, 10879, 310, 1906, 19995, 373, 697, 29915, 29879, 2834, 29889, 450, 25657, 338, 20050, 411, 263, 10608, 1546, 1023, 10898, 322, 18973, 3060, 15806, 278, 697, 3109, 1020, 345, 839, 29892, 607, 18973, 25834, 1009, 2834, 7271, 29889, 32000]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.165217Z","iopub.execute_input":"2024-11-24T07:44:03.165517Z","iopub.status.idle":"2024-11-24T07:44:03.172258Z","shell.execute_reply.started":"2024-11-24T07:44:03.165470Z","shell.execute_reply":"2024-11-24T07:44:03.171383Z"}},"outputs":[{"name":"stdout","text":"[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.173123Z","iopub.execute_input":"2024-11-24T07:44:03.173952Z","iopub.status.idle":"2024-11-24T07:44:03.183588Z","shell.execute_reply.started":"2024-11-24T07:44:03.173923Z","shell.execute_reply":"2024-11-24T07:44:03.182790Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.184722Z","iopub.execute_input":"2024-11-24T07:44:03.185079Z","iopub.status.idle":"2024-11-24T07:44:03.193410Z","shell.execute_reply.started":"2024-11-24T07:44:03.185042Z","shell.execute_reply":"2024-11-24T07:44:03.192608Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.194352Z","iopub.execute_input":"2024-11-24T07:44:03.194631Z","iopub.status.idle":"2024-11-24T07:44:03.205017Z","shell.execute_reply.started":"2024-11-24T07:44:03.194601Z","shell.execute_reply":"2024-11-24T07:44:03.204199Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.206053Z","iopub.execute_input":"2024-11-24T07:44:03.206342Z","iopub.status.idle":"2024-11-24T07:44:03.215920Z","shell.execute_reply.started":"2024-11-24T07:44:03.206315Z","shell.execute_reply":"2024-11-24T07:44:03.215157Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.216858Z","iopub.execute_input":"2024-11-24T07:44:03.217175Z","iopub.status.idle":"2024-11-24T07:44:03.715966Z","shell.execute_reply.started":"2024-11-24T07:44:03.217149Z","shell.execute_reply":"2024-11-24T07:44:03.715032Z"}},"outputs":[{"name":"stdout","text":"trainable params: 35,651,584 || all params: 3,856,731,136 || trainable%: 0.9244\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.717085Z","iopub.execute_input":"2024-11-24T07:44:03.717368Z","iopub.status.idle":"2024-11-24T07:44:03.727579Z","shell.execute_reply.started":"2024-11-24T07:44:03.717341Z","shell.execute_reply":"2024-11-24T07:44:03.726559Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3RotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm()\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm()\n      )\n    )\n    (norm): Phi3RMSNorm()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.728643Z","iopub.execute_input":"2024-11-24T07:44:03.728920Z","iopub.status.idle":"2024-11-24T07:44:03.745371Z","shell.execute_reply.started":"2024-11-24T07:44:03.728891Z","shell.execute_reply":"2024-11-24T07:44:03.744520Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 2044791808\nTrainable parameters : 35651584\nTrainable percentage: 1.74%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.746254Z","iopub.execute_input":"2024-11-24T07:44:03.746520Z","iopub.status.idle":"2024-11-24T07:44:03.755654Z","shell.execute_reply.started":"2024-11-24T07:44:03.746487Z","shell.execute_reply":"2024-11-24T07:44:03.754851Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 2\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.756594Z","iopub.execute_input":"2024-11-24T07:44:03.756870Z","iopub.status.idle":"2024-11-24T07:44:03.808259Z","shell.execute_reply.started":"2024-11-24T07:44:03.756842Z","shell.execute_reply":"2024-11-24T07:44:03.807586Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov24_07-44-03_e085d4847dbc,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:03.809044Z","iopub.execute_input":"2024-11-24T07:44:03.809310Z","iopub.status.idle":"2024-11-24T07:44:05.008309Z","shell.execute_reply.started":"2024-11-24T07:44:03.809281Z","shell.execute_reply":"2024-11-24T07:44:05.007558Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:403: UserWarning: You passed a processing_class with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `processing_class.padding_side = 'right'` to your code.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x78287658ada0>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T07:44:05.009514Z","iopub.execute_input":"2024-11-24T07:44:05.009893Z","iopub.status.idle":"2024-11-24T08:44:24.017417Z","shell.execute_reply.started":"2024-11-24T07:44:05.009854Z","shell.execute_reply":"2024-11-24T08:44:24.016641Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 2\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 35,651,584\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113166455551335, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66b1551248364431866ffca9c5f57836"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241124_074406-tcuk59wr</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/tcuk59wr' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/tcuk59wr' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/tcuk59wr</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 1:00:02, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>1.297600</td>\n      <td>1.173430</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.148900</td>\n      <td>1.008226</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.968200</td>\n      <td>0.929136</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.888900</td>\n      <td>0.886840</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.850100</td>\n      <td>0.854672</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.806600</td>\n      <td>0.831586</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.797900</td>\n      <td>0.817220</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.759600</td>\n      <td>0.809999</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.765600</td>\n      <td>0.807451</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.728400</td>\n      <td>0.807061</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.901170916557312, metrics={'train_runtime': 3618.623, 'train_samples_per_second': 0.442, 'train_steps_per_second': 0.055, 'total_flos': 1.86476893569024e+16, 'train_loss': 0.901170916557312, 'epoch': 0.17777777777777778})"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:44:24.018817Z","iopub.execute_input":"2024-11-24T08:44:24.019212Z","iopub.status.idle":"2024-11-24T08:46:40.512771Z","shell.execute_reply.started":"2024-11-24T08:44:24.019168Z","shell.execute_reply":"2024-11-24T08:46:40.511871Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 02:13]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.8070605397224426, 'eval_runtime': 136.4805, 'eval_samples_per_second': 1.465, 'eval_steps_per_second': 0.366, 'epoch': 0.17777777777777778}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:40.514091Z","iopub.execute_input":"2024-11-24T08:46:40.515035Z","iopub.status.idle":"2024-11-24T08:46:41.775690Z","shell.execute_reply.started":"2024-11-24T08:46:40.514992Z","shell.execute_reply":"2024-11-24T08:46:41.774725Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\nModel config Phi3Config {\n  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n  \"architectures\": [\n    \"Phi3ForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"auto_map\": {\n    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n  },\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 32000,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 4096,\n  \"model_type\": \"phi3\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"original_max_position_embeddings\": 4096,\n  \"pad_token_id\": 32000,\n  \"resid_pdrop\": 0.0,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 2047,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32064\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\nModel config Phi3Config {\n  \"_name_or_path\": \"Phi-3-mini-4k-instruct\",\n  \"architectures\": [\n    \"Phi3ForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"auto_map\": {\n    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n  },\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 32000,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 4096,\n  \"model_type\": \"phi3\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"original_max_position_embeddings\": 4096,\n  \"pad_token_id\": 32000,\n  \"resid_pdrop\": 0.0,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 2047,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32064\n}\n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:41.776957Z","iopub.execute_input":"2024-11-24T08:46:41.777231Z","iopub.status.idle":"2024-11-24T08:46:42.175886Z","shell.execute_reply.started":"2024-11-24T08:46:41.777204Z","shell.execute_reply":"2024-11-24T08:46:42.174947Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:42.177033Z","iopub.execute_input":"2024-11-24T08:46:42.177346Z","iopub.status.idle":"2024-11-24T08:46:42.186850Z","shell.execute_reply.started":"2024-11-24T08:46:42.177319Z","shell.execute_reply":"2024-11-24T08:46:42.186122Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:42.187924Z","iopub.execute_input":"2024-11-24T08:46:42.188172Z","iopub.status.idle":"2024-11-24T08:46:42.837900Z","shell.execute_reply.started":"2024-11-24T08:46:42.188149Z","shell.execute_reply":"2024-11-24T08:46:42.836945Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:42.839071Z","iopub.execute_input":"2024-11-24T08:46:42.839355Z","iopub.status.idle":"2024-11-24T08:46:52.242544Z","shell.execute_reply.started":"2024-11-24T08:46:42.839327Z","shell.execute_reply":"2024-11-24T08:46:52.241651Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/config.json\nModel config Phi3Config {\n  \"_name_or_path\": \"microsoft/Phi-3-mini-4k-instruct\",\n  \"architectures\": [\n    \"Phi3ForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"auto_map\": {\n    \"AutoConfig\": \"microsoft/Phi-3-mini-4k-instruct--configuration_phi3.Phi3Config\",\n    \"AutoModelForCausalLM\": \"microsoft/Phi-3-mini-4k-instruct--modeling_phi3.Phi3ForCausalLM\"\n  },\n  \"bos_token_id\": 1,\n  \"embd_pdrop\": 0.0,\n  \"eos_token_id\": 32000,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3072,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8192,\n  \"max_position_embeddings\": 4096,\n  \"model_type\": \"phi3\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"original_max_position_embeddings\": 4096,\n  \"pad_token_id\": 32000,\n  \"resid_pdrop\": 0.0,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 2047,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 32064\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/model.safetensors.index.json\nInstantiating Phi3ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 32000,\n  \"pad_token_id\": 32000\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d52a5af533754b87a089ac16349ae992"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint weights were used when initializing Phi3ForCausalLM.\n\nAll the weights of Phi3ForCausalLM were initialized from the model checkpoint at microsoft/Phi-3-mini-4k-instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Phi3ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--Phi-3-mini-4k-instruct/snapshots/0a67737cc96d2554230f90338b163bc6380a2a85/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": [\n    32000,\n    32001,\n    32007\n  ],\n  \"pad_token_id\": 32000\n}\n\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"Phi3ForCausalLM(\n  (model): Phi3Model(\n    (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n    (embed_dropout): Dropout(p=0.0, inplace=False)\n    (layers): ModuleList(\n      (0-31): 32 x Phi3DecoderLayer(\n        (self_attn): Phi3Attention(\n          (o_proj): Linear4bit(in_features=3072, out_features=3072, bias=False)\n          (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n          (rotary_emb): Phi3RotaryEmbedding()\n        )\n        (mlp): Phi3MLP(\n          (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n          (down_proj): Linear4bit(in_features=8192, out_features=3072, bias=False)\n          (activation_fn): SiLU()\n        )\n        (input_layernorm): Phi3RMSNorm()\n        (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n        (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n        (post_attention_layernorm): Phi3RMSNorm()\n      )\n    )\n    (norm): Phi3RMSNorm()\n  )\n  (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:52.243587Z","iopub.execute_input":"2024-11-24T08:46:52.243830Z","iopub.status.idle":"2024-11-24T08:46:52.254414Z","shell.execute_reply.started":"2024-11-24T08:46:52.243806Z","shell.execute_reply":"2024-11-24T08:46:52.253512Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 2009140224\nTrainable parameters : 197200896\nTrainable percentage: 9.82%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:52.255625Z","iopub.execute_input":"2024-11-24T08:46:52.255977Z","iopub.status.idle":"2024-11-24T08:46:52.271610Z","shell.execute_reply.started":"2024-11-24T08:46:52.255938Z","shell.execute_reply":"2024-11-24T08:46:52.270646Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Phi3ForCausalLM(\n      (model): Phi3Model(\n        (embed_tokens): Embedding(32064, 3072, padding_idx=32000)\n        (embed_dropout): Dropout(p=0.0, inplace=False)\n        (layers): ModuleList(\n          (0-31): 32 x Phi3DecoderLayer(\n            (self_attn): Phi3Attention(\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3072, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3072, out_features=64, bias=False)\n                  (default): Linear(in_features=3072, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (qkv_proj): Linear4bit(in_features=3072, out_features=9216, bias=False)\n              (rotary_emb): Phi3RotaryEmbedding()\n            )\n            (mlp): Phi3MLP(\n              (gate_up_proj): Linear4bit(in_features=3072, out_features=16384, bias=False)\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8192, out_features=3072, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=8192, out_features=64, bias=False)\n                  (default): Linear(in_features=8192, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=3072, bias=False)\n                  (default): Linear(in_features=64, out_features=3072, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (activation_fn): SiLU()\n            )\n            (input_layernorm): Phi3RMSNorm()\n            (resid_attn_dropout): Dropout(p=0.0, inplace=False)\n            (resid_mlp_dropout): Dropout(p=0.0, inplace=False)\n            (post_attention_layernorm): Phi3RMSNorm()\n          )\n        )\n        (norm): Phi3RMSNorm()\n      )\n      (lm_head): Linear(in_features=3072, out_features=32064, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:52.272814Z","iopub.execute_input":"2024-11-24T08:46:52.273095Z","iopub.status.idle":"2024-11-24T08:46:52.292824Z","shell.execute_reply.started":"2024-11-24T08:46:52.273068Z","shell.execute_reply":"2024-11-24T08:46:52.291872Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 2080443392\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## 14 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt, inputs):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      inputs,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:52.293921Z","iopub.execute_input":"2024-11-24T08:46:52.294183Z","iopub.status.idle":"2024-11-24T08:46:52.307531Z","shell.execute_reply.started":"2024-11-24T08:46:52.294157Z","shell.execute_reply":"2024-11-24T08:46:52.306838Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def post_assistant(prompt, inputs):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      inputs,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:52.308657Z","iopub.execute_input":"2024-11-24T08:46:52.308936Z","iopub.status.idle":"2024-11-24T08:46:52.319197Z","shell.execute_reply.started":"2024-11-24T08:46:52.308911Z","shell.execute_reply":"2024-11-24T08:46:52.318487Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:52.320449Z","iopub.execute_input":"2024-11-24T08:46:52.320798Z","iopub.status.idle":"2024-11-24T08:46:52.331220Z","shell.execute_reply.started":"2024-11-24T08:46:52.320761Z","shell.execute_reply":"2024-11-24T08:46:52.330399Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:46:52.332218Z","iopub.execute_input":"2024-11-24T08:46:52.332520Z","iopub.status.idle":"2024-11-24T08:49:22.818623Z","shell.execute_reply.started":"2024-11-24T08:46:52.332494Z","shell.execute_reply":"2024-11-24T08:49:22.817766Z"}},"outputs":[{"name":"stderr","text":"The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n`get_max_cache()` is deprecated for all Cache classes. Use `get_max_cache_shape()` instead. Calling `get_max_cache()` will raise error from v4.48\n","output_type":"stream"},{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Classify   |  completes the request.  ### Instruction: Classify \nthe following news report into three categories:    |  the following news report into three categories:  \nPolitics, Economics and Social.  ### Input: The     |  Politics, Economics and Social.  ### Input: The   \nUnited Nations Security Council has unanimously     |  United Nations Security Council has unanimously   \nadopted resolution 2371 that establishes a tough    |  adopted resolution 2371 that establishes a tough  \nnew sanctions regime against North Korea in         |  new sanctions regime against North Korea in       \nresponse to its ongoing weapons program.  ###       |  response to its ongoing weapons program.  ###     \nResponse: This news report falls into the Politics  |  Response: This news report falls into the Politics\ncategory as it involves the United Nations          |  category as it involves the United Nations        \nSecurity Council, which is a political body, and    |  Security Council, which is a political body, and  \nthe adoption of a resolution against North Korea,   |  the adoption of a resolution against North Korea, \na political issue. It also touches on               |  a political issue. It also touches on             \ninternational relations and global politics.   ###  |  international relations and global politics.   ###\nInstruction: Classify the following news report     |  Instruction: Classify the following news report   \ninto three categories: Politics, Economics, and     |  into three categories: Politics, Economics, and   \nSocial. Additionally, identify any potential        |  Social. Additionally, identify any potential      \nimplications for international relations, and       |  implications for international relations, and     \nsuggest two possible reactions from the             |  suggest two possible reactions from the           \ninternational community.  ### Input: The European   |  international community.  ### Input: The European \nUnion has announced a new trade agreement with      |  Union has announced a new policy that will impose \nVietnam that will eliminate tariffs on over 90% of  |  tariffs on imported goods from countries that do  \ngoods traded between the two regions. The deal is   |  not meet its environmental standards.  ###        \nexpected to boost Vietnam'limpact on the global     |  Response: This news report falls into the         \neconomy, particularly in the technology and         |  Economics category due to the imposition of       \nagriculture sectors.  ### Response: This news       |  tariffs, which are economic tools. It also touches\nreport falls into the Economics category due to     |  on Politics as it involves the European Union, a  \nthe focus on a trade agreement and its impact on    |  political entity, and international relations due \ntariffs and global economy. It also has             |  to the impact on countries that do not meet the   \nimplications for international relations as it      |  EU's environmental standards.   Potential         \ncould strengthen ties between the European Union    |  implications for international relations include  \nand Vietnam, potentially influencing the balance    |  strained trade relations with countries that may  \nof trade power in the region.   Two possible        |  view the tariffs as protectionist or unfair. This \nreactions from the international community could    |  could lead to retaliatory measures or trade       \nbe:  1. Other countries in the region might seek    |  disputes.   Two possible reactions from the       \nsimilar trade agreements with Vietnam to remain     |  international community could be:  1. Countries   \ncompetitive, leading to a potential shift in trade  |  affected by the tariffs might seek to negotiate   \ndynamics.  2. There could be concerns from          |  with the EU to either improve their environmental \ncountries that feel disadvant0ged by the            |  standards or to receive exemptions or reductions  \nagreement, possibly leading to diplomatic           |  in the tariffs.  2. Affected countries could form \ndiscussions or negotiations to address these        |  a coalition to challenge the EU's policy at the   \nconcerns.   ### Instruction: Classify the           |  World Trade Organization (WTO), arguing that the  \nfollowing news report into three categories:        |  tariffs violate trade agreements or are           \nPolitics, Economics, and Social. Additionally,      |  discriminatory.   ### Instruction: Classify the   \nidentify any potential implications for             |  following news report into three categories:      \ninternational relations, suggest two possible       |  Politics, Economics, and Social. Additionally,    \nreactions from the international community, and     |  identify any potential implications for           \nanalyze the potential impact on the domestic        |  international relations, suggest two possible     \neconomies of the countries involved.  ### Input:    |  reactions from the international community, and   \nThe United States has imposed a series of           |  analyze the potential impact on global trade      \nsanctions on Russia, targeting its energy sector    |  patterns.  ### Input: The G20 summit has concluded\nand limiting access to international financial      |  with a consensus on implementing a global minimum \nmarkets. The sanctions are a response to Russia's   |  corporate tax rate to curb tax evasion and ensure \nrecent military actions in Ukraine.  ### Response:  |  fair competition among nations.  ### Response:    \nThis news report falls into the Politics category   |  This news report falls into the Economics category\ndue to the involvement of the United States and     |  due to the focus on corporate tax rates and fair  \nRussia, which are political entities, and the       |  competition. It also touches on Politics as the   \nimposition of sanctions, a political tool. It also  |  G20 summit is a political forum where such        \nhas significant implications for international      |  agreements are made. The Social aspect is         \nrelations, as sanctions are often used to exert     |  indirectly addressed as the agreement aims to     \npressure without resorting to military action.      |  ensure fair competition, which can have social    \nTwo possible reactions from the international       |  implications in terms of economic equality and    \ncommunity could be:  1. Allies of the United        |  corporate responsibility.   Potential implications\nStates might support the sanctions, reinforcing     |  for international relations include a more        \nthe message that aggressive actions will not be     |  cooperative global financial system and reduced   \ntolerated.  2. Countries that have strong economic  |  incentives for tax havens. This could lead to a   \nties with Russia might oppose the sanctions,        |  more equitable distribution of tax revenues among \nleading to diplomatic efforts to find a middle      |  nations and potentially reduce corruption and     \nground or exemptions.   The potential impact on     |  financial crimes.   Two possible reactions from   \nthe domestic economies of the countries involved    |  the international community could be:  1.         \ncould be substantial. For the United States, the    |  Countries that previously benefited from tax      \nsanctions could lead to a decrease in trade with    |  havens might resist the change, fearing a loss of \nRussia, affecting industries that export to         |  competitive advantage and revenue.  2. Developing \nRussia. For Russia, the sanctions could lead to a   |  countries might welcome the change, as it could   \ndecrease in foreign investment and a potential      |  lead to increased tax revenues and resources for  \nincrease in the cost of borrowing, which could      |  public services.   The potential impact on global \nslow down economic growth.   ### Instruction:       |  trade patterns could be significant. By leveling  \nClassify the following news report into three       |  the playing field, smaller nations might be able  \ncategories: Politics, Economics, and Social.        |  to compete more effectively with larger           \nAdditionally, identify any potential implications   |  corporations, potentially leading to a more       \nfor international relations, suggest two possible   |  diverse and competitive global market. This could \nreactions from the international community,         |  also encourage multin0national corporations to    \nanalyze the potential impact on the domestic        |  invest more in local economies, leading to        \neconomies of the countries involved, and predict    |  economic growth and development.   ###            \nthe long-term effects on the global economy.  ###   |  Instruction: Classify the following news report   \nInput: China has announced a new policy to          |  into three categories: Politics, Economics, and   \nsubsidize its domestic solar panel manufacturers,   |  Social. Additionally, identify any potential      \naiming to reduce reliance on imported solar panels  |  implications for international relations, suggest \nand promote the use of renewable energy.  ###       |  two possible reactions from the international     \nResponse: This news report falls into the           |  community, analyze the potential impact on global \nEconomics category due to the focus on subsidies,   |  trade patterns, and evaluate the effectiveness of \nwhich are economic tools used to support domestic   |  the policy in achieving its goals.  ### Input: The\nindustries. It also has implications for            |  International Monetary Fund (IMF) has released a  \ninternational relations, as it could lead to trade  |  report stating that countries with higher gender  \ndisputes with countries that export solar panels    |  equality tend to have more stable and resilient   \nto China.   Two possible reactions from the         |  economies.  ### Response: This news report falls  \ninternational community could be:  1. Countries     |  into the Economics category due to the focus on   \nthat export solar panels to China might protest     |  the relationship between gender equality and      \nthe subsidies, claiming they distort the market     |  economic stability. It also touches on Politics as\nand harm their own solar panel industries.  2.      |  the IMF is an international organization that     \nOther countries might welcome the move as a         |  influences global economic policies. The Social   \npositive step towards global efforts to combat      |  aspect is directly addressed as the report        \nclimate change, potentially leading to increased    |  discusses gender equality.   Potential            \ncooperation in renewable energy technology.   The   |  implications for international relations include  \npotential impact on the domestic economies of the   |  the promotion of gender equality as a global      \ncountries involved could be significant. For        |  economic goal, which could lead to increased      \nChina, the subsidies could lead to the growth of    |  cooperation between nations on social issues. This\nthe domestic solar panel industry, creating jobs    |  could also influence international aid and        \nand reducing energy costs. For exporting            |  development programs, with a focus on empowering  \ncountries, the subsidies could lead to a decrease   |  women.   Two possible reactions from the          \nin demand for their solar panels, potentially       |  international community could be:  1. Countries   \nharming their solar panel industries.   The long-   |  with lower gender equality might be encouraged to \nterm effects on the global economy could include a  |  adopt policies that promote women's rights and    \nshift towards more self-                            |  participation in the economy.  2. Some nations    \n                                                    |  might resist the push for gender equality,        \n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:49:22.819846Z","iopub.execute_input":"2024-11-24T08:49:22.820197Z","iopub.status.idle":"2024-11-24T08:51:53.564517Z","shell.execute_reply.started":"2024-11-24T08:49:22.820165Z","shell.execute_reply":"2024-11-24T08:51:53.563631Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Come up    |  completes the request.  ### Instruction: Come up  \nwith a riddle  ### Input:   ### Response: I fly     |  with a riddle  ### Input:   ### Response: I fly   \nwithout wings, I cry without eyes. Whenever I go,   |  without wings, I cry without eyes. Whenever I go, \ndarkness flies. What am I?   # Instruction: Create  |  darkness flies. What am I?   # Instruction: Create\na complex riddle that involves a historical         |  a complex riddle that involves a historical       \nfigure, a specific location, and a unique object.   |  figure, a specific location, and a unique object. \nThe riddle must include a metaphor, a play on       |  The riddle must include a metaphor, a play on     \nwords, and a reference to a significant event       |  words, and a reference to a significant event     \nrelated to the figure. The solution should not be   |  related to the figure. The solution should not be \nimmediately obvious and require knowledge of the    |  immediately obvious and require knowledge of the  \nhistorical figure's life and achievements.   ###    |  historical figure's life and achievements.   ###  \nInput:   ### Response: In the heart of a city       |  Input:   ### Response: In the heart of a city     \nwhere the Tiber meets the sea,  A figure of power,  |  where the Tiber meets the sea,  A figure of power,\nwith a vision so free.  He once stood, a leader, a  |  with a vision so free.  He once stood, a leader, a\nking,  With a sword in hand, his fate he'd sing.    |  king,  With a sword in hand, his fate he'd sing.  \nA metaphor for his rule, a game of chess,  His      |  A metaphor for his rule, a game of chess,  His    \npawns and knights, a nation's success.  A unique    |  pawns and knights, a nation's success.  A unique  \nobject, a symbol of his reign,  A golden eagle,     |  object, a symbol of his reign,  A golden eagle,   \nhis legacy's main.   This riddle refers to Julius   |  his legacy's main.   This riddle refers to Julius \nCaesar, who was a prominent leader in Rome. The     |  Caesar, who was a prominent leader in Rome. The   \n\"city where the Tiber meets the sea\" is Rome, and   |  \"city where the Tiber meets the sea\" is Rome, and \nthe \"unique object\" is the golden eagle, which was  |  the \"unique object\" is the golden eagle, which was\na symbol of his authority and power. The            |  a symbol of his authority and power. The          \n\"significant event\" alludes to his assassination,   |  \"significant event\" alludes to his assassination, \nwhich was a turning point in Roman history. The     |  which was a turning point in Roman history. The   \nmetaphor of chess represents the strategic and      |  metaphor of chess represents the strategic and    \npolitical maneuvers Caesar made during his rule.    |  political maneuvers Caesar made during his rule.  \n# Instruction: Formulate a riddle that              |  # Instruction: Formulate a riddle that            \nincorporates a mathematical concept, a famous       |  incorporates a mathematical concept, a famous     \npainting, and a mythical creature. The riddle must  |  painting, and a mythical creature. The riddle must\ninclude a double entendre, a historical anecdote,   |  include a double entendre, a historical anecdote, \nand a play on the mathematical concept's name. The  |  and a play on the mathematical concept's name. The\nsolution should be a single word that is not        |  solution should be a single word that is not      \nimmediately apparent and requires knowledge of the  |  immediately apparent and requires knowledge of the\npainting's artist and the mythical creature's       |  painting's artist and the mythical creature's     \norigin.   ### Input:   ### Response: In a canvas    |  origin.   ### Input:   ### Response: In a canvas  \nof night, where shadows play,  A creature of myth,  |  of night, where shadows play,  A creature of myth,\nin disguise, holds sway.  A mathematician's dream,  |  in disguise, holds sway.  A mathematician's dream,\na circle's embrace,  A painter's vision, in a       |  a circle's embrace,  A tale of a painter, with a  \nstarry space.   A double entendre for the           |  starry face.   A double entendre for the          \ncreature's \"disguise,\"  A historical anecdote, a    |  creature's \"disguise,\"  A nod to the artist, who  \nnight's surprise.  The play on \"circle's embrace,\"  |  captured the skies.  The anecdote of a night, a   \na name's twist,  Find the word, in the art, the     |  revelation,  A play on \"pi,\" a circle's           \nmyth, and the math, kissed.   This riddle refers    |  revelation.   This riddle refers to the mythical  \nto the painting \"The Starry Night\" by Vincent van   |  creature, the Phoenix, which is often depicted in \nGogh, which features a night sky with swirling      |  art and symbolizes rebirth. The famous painting is\npatterns that resemble a circle. The mythical       |  \"The Starry Night\" by Vincent van Gogh, which     \ncreature is the unicorn, often depicted in          |  features a night sky filled with stars. The       \ndisguise or as a symbol of purity and rarity. The   |  mathematical concept is pi (π), which is the ratio\nmathematical concept is the circle, which is        |  of a circle's circumference to its diameter. The  \ncentral to the painting's composition. The word to  |  solution to the riddle is \"Phoenix,\" which is a   \nbe found is \"unicorn,\" which is a single word that  |  single word that is not immediately apparent and  \nis not immediately apparent and requires knowledge  |  requires knowledge of the mythical creature's     \nof the painting's artist (Vincent van Gogh) and     |  origin and the artist's work.   # Instruction:    \nthe mythical creature's origin (mythology). The     |  Devise a riddle that intertwines a scientific     \ndouble entendre lies in the \"disguise\" of the       |  principle, a historical event, and a famous       \nunicorn, and the historical anecdote could be the   |  literary work. The riddle must include a          \nstory of van Gogh painting \"The Starry Night\"       |  palindrome, a reference to a specific invention,  \nduring his stay at the asylum in Saint-Rémy-de-     |  and a play on words related to the scientific     \nProvence. The play on the mathematical concept's    |  principle. The solution should be a single word   \nname is \"circle's embrace,\" which hints at the      |  that is not immediately apparent and requires     \ncircular patterns in the painting.   #              |  knowledge of the literary work's author and the   \nInstruction: Devise a riddle that intertwines a     |  historical event'escholarly.   ### Input:   ###   \nfamous scientist, a specific architectural          |  Response: A tale of flight, a loop that's the same\nstructure, and a rare gemstone. The riddle must     |  backward and forward,  A principle of motion,     \ninclude an anagram, a palindrome, and a reference   |  where airplanes are adored.  A historical event,  \nto the scientist's most notable theory. The         |  when the world was at war,  A literary work, with \nsolution should be a single word that is not        |  a message for all to adore.   A palindrome for the\nimmediately apparent and requires knowledge of the  |  flight, a loop that's the same,  A reference to   \nscientist's field of study, the architectural       |  the Wright brothers, who took to the fame.  A play\nstructure' compositional style, and the gemstone's  |  on words for the principle, \"lift\" in the air,  A \nproperties.   ### Input:   ### Response: A thinker  |  famous author, whose words we still share.   This \nof atoms, in a tower of light,  His name an         |  riddle refers to the scientific principle of      \nanagram, in the night.  A palindrome in his work,   |  \"lift,\" which is essential for flight and was a   \na theory so bright,  A gemstone rare, in the day    |  significant factor in the development of aviation,\nand night.   A structure's style, with symmetry so  |  particularly with the Wright brothers' invention  \ngrand,  A gemstone's facets, by nature's hand.      |  of the airplane. The historical event is World War\nThe word you seek, in science and art,  A single    |  I, during which airplanes were first used in      \nterm, a conceptual part.   This riddle refers to    |  combat. The famous literary work is \"The Great    \nthe famous scientist Albert Ein                     |  Gatsby\" by F. Scott Fitzgerald, whose words have  \n                                                    |  been widely shared and celebrated. The solution to\n                                                    |  the riddle is \"Lift,\" which is a single word that \n                                                    |  is not immediately apparent and requires knowledge\n                                                    |  of the scientific principle, the historical       \n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:51:53.565957Z","iopub.execute_input":"2024-11-24T08:51:53.566749Z","iopub.status.idle":"2024-11-24T08:54:25.066428Z","shell.execute_reply.started":"2024-11-24T08:51:53.566707Z","shell.execute_reply":"2024-11-24T08:54:25.065542Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Construct  |  completes the request.  ### Instruction: Construct\na story of love and loss.  ### Input:   ###         |  a story of love and loss.  ### Input:   ###       \nResponse:  Once upon a time in a quaint village     |  Response:  Once upon a time in a quaint village   \nnestled between rolling hills and whispering        |  nestled between rolling hills and whispering      \nwoods, there lived a young woman named Elara. Her   |  woods, there lived a young woman named Elara. Her \nheart was as vast as the sky above, and her spirit  |  heart was as vast as the sky above, and her spirit\nas free as the wind that danced through the trees.  |  as free as the wind that danced through the trees.\nElara's days were filled with the simple joys of    |  Elara's days were filled with the simple joys of  \nvillage life, but her nights were haunted by the    |  village life, but her nights were haunted by the  \nmemory of a love lost to time and fate.             |  memory of a love lost to time and fate.           \nElara'usted by the loss of her beloved, a man       |  Elara'usted by the loss of her beloved, a man     \nnamed Orion, who had ventured far beyond the        |  named Orion, who had ventured far beyond the      \nhorizon, she found solace in the beauty of the      |  horizon, she found solace in the beauty of the    \nnatural world. She would often wander the forest    |  natural world. She would often wander the forest  \npaths, her thoughts adrift with memories of         |  paths, her thoughts adrift with memories of       \nOrion's laughter and the warmth of his embrace.     |  Orion's laughter and the warmth of his embrace.   \nOne fateful evening, as the sun dipped below the    |  One fateful evening, as the sun dipped below the  \nhorizon, painting the sky in hues of fiery orange   |  horizon, painting the sky in hues of fiery orange \nand deep purple, Elara encountered a stranger. His  |  and deep purple, Elara encountered a stranger. His\neyes held the same depth as Orion's, and his smile  |  eyes held the same depth as Orion's, and his smile\nwas as enchanting as his lost love's. They spoke    |  was as enchanting as his lost love's. They spoke  \nof dreams and desires, and in that moment, Elara    |  of dreams and desires, and in that moment, Elara  \nfelt a connection that mirrored the one she had     |  felt a connection that mirrored the one she had   \nlost.   As the seasons changed, so did Elara's      |  lost.   As the seasons changed, so did Elara's    \nheart. She found herself entwined with the          |  heart. She found herself entwined with the        \nstranger, a man named Leo, who became her new       |  stranger, a man named Leo, who became her new     \nbeacon of hope. Together, they explored the world,  |  beacon of hope. Together, they explored the world,\ntheir love blossoming like the flowers that         |  their love blossoming like the flowers that       \nadorned the village in spring.   But as the wheel   |  adorned the village in spring.   But as the wheel \nof time turned, Leo's health began to wane. The     |  of time turned, Leo's health began to wane. The   \nonce vibrant man grew frail, his strength ebbing    |  once vibrant man grew frail, his strength ebbing  \naway like the tide. Elara watched helplessly as     |  away like the tide. Elara watched helplessly as   \nher love faded, the pain of loss returning with a   |  her love faded, the pain of loss returning with a \nvengeance.   In the end, Leo passed away, leaving   |  vengeance.   In the end, Leo passed away, leaving \nElara to mourn in the silence of the forest. She    |  Elara to mourn in the silence of the forest. She  \nburied him beneath the ancient oak, where Orion     |  buried him beneath the ancient oak, where Orion   \nhad once stood, and whispered a promise to keep     |  had once stood, and whispered a promise to keep   \nhis memory alive.   Elara's love for Leo was a      |  his memory alive.   Elara's love for Leo was a    \ntestament to the enduring power of love, even in    |  testament to the enduring power of love, even in  \nthe face of loss. And though her heart would never  |  the face of loss. And though her heart would never\nfully heal, she knew that the love she shared with  |  fully heal, she knew that the love she shared with\nLeo would forever be a part of her story, a story   |  Leo would forever be a part of her story, a story \nof love and loss that would be told for             |  of love and loss that would be told for           \ngenerations to come.   ### Instruction: Write a     |  generations to come.   ### Instruction: Create a  \ndetailed narrative set in a dystopian future where  |  detailed narrative set in a dystopian future,     \nthe protagonist, named Alex, disco0000000000000000  |  featuring a protagonist named Alex Mercer, who is \n00000000000000000000000000000000000000000000000000  |  a skilled hacker. The story must include a        \n00000000000000000000000000000000000000000000000000  |  rebellion against a totalitarian regime, a        \n00000000000000000000000000000000000000000000000000  |  forbidden romance, a betrayal by a close friend,  \n00000000000000000000000000000000000000000000000000  |  and a climactic showdown at the regime's          \n00000000000000000000000000000000000000000000000000  |  stronghold. The narrative should be written in the\n00000000000000000000000000000000000000000000000000  |  first-person perspective, include at least two    \n00000000000000000000000000000000000000000000000000  |  plot twists, and incorporate a symbolic object    \n00000000000000000000000000000000000000000000000000  |  that represents hope.   ### Response:  I remember \n00000000000000000000000000000000000000000000000000  |  the day the regime's grip on our lives tightened, \n0000000000000000                                    |  the day when freedom became a mere whisper in the \n                                                    |  wind. My name is Alex Mercer, and I am a hacker, a\n                                                    |  digital whisperer in a world where the iron fist  \n                                                    |  of the totalitarian regime, known as The Order,   \n                                                    |  has suffocated our spirits.   My life took a turn \n                                                    |  when I met Lila, a fiery rebel with eyes that     \n                                                    |  mirrored the defiance in my own. Our connection   \n                                                    |  was electric, a spark in the oppressive darkness. \n                                                    |  We shared a secret, a forbidden romance that could\n                                                    |  cost us everything.   As the rebellion grew, so   \n                                                    |  did our love, but it was Lila who betrayed me. She\n                                                    |  was the one who infiltrated my network, revealing \n                                                    |  my identity to The Order. The pain was unbearable,\n                                                    |  but I could not let her actions dictate my fate.  \n                                                    |  I became the face of the rebellion, a symbol of   \n                                                    |  resistance. My hacking skills were our only hope  \n                                                    |  against The Order'escheming to crush us at every  \n                                                    |  turn. But I had a secret weapon, a small,         \n                                                    |  unassuming pendant that Lila had given me before  \n                                                    |  her betrayal. It was a pendant with a single,     \n                                                    |  glowing ember, a reminder of the hope that kept us\n                                                    |  going.   The climax came when we launched our most\n                                                    |  daring attack on The Order's stronghold. As we    \n                                                    |  infiltrated their digital fortress, I encountered \n                                                    |  a shocking twist: Lila was there, not as a        \n                                                    |  traitor, but as a double agent, working to        \n                                                    |  dismantle The Order from within.   In the final   \n                                                    |  showdown, I faced off against the regime's leader,\n                                                    |  a man who had once been a                         \n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:58:59.729083Z","iopub.execute_input":"2024-11-24T08:58:59.729436Z","iopub.status.idle":"2024-11-24T09:01:32.786123Z","shell.execute_reply.started":"2024-11-24T08:58:59.729405Z","shell.execute_reply":"2024-11-24T09:01:32.785149Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Describe   |  completes the request.  ### Instruction: Describe \nthe implications of Artificial Intelligence  ###    |  the implications of Artificial Intelligence  ###  \nInput:   ### Response: Artificial Intelligence      |  Input:   ### Response: Artificial Intelligence    \n(AI) has profound implications across various       |  (AI) has profound implications across various     \nsectors, fundamentally altering how we live, work,  |  sectors, fundamentally altering how we live, work,\nand interact. Here are some key areas where AI's    |  and interact. Here are some key areas where AI's  \nimpact is particularly significant:   1.            |  impact is particularly significant:   1.          \n**Economy**: AI is driving economic growth by       |  **Economy**: AI is driving economic growth by     \nincreasing productivity and creating new markets.   |  increasing productivity and creating new markets. \nIt enables businesses to optimize operations,       |  It enables businesses to optimize operations,     \nreduce costs, and develop new products and          |  reduce costs, and develop new products and        \nservices. However, it also poses a risk of job      |  services. However, it also poses a risk of job    \ndisplacement as automation replaces certain roles.  |  displacement as automation replaces certain roles.\n2. **Healthcare**: AI is revolutionizing            |  2. **Healthcare**: AI is revolutionizing          \nhealthcare by improving diagnostic accuracy,        |  healthcare by improving diagnostic accuracy,      \npersonalizing treatment plans, and expediting drug  |  personalizing treatment plans, and expediting drug\ndiscovery. AI-powered tools can analyze medical     |  discovery. AI-powered tools can analyze medical   \nimages with high precision, predict patient         |  images with high precision, predict patient       \noutcomes, and assist in surgical procedures.   3.   |  outcomes, and assist in surgical procedures.   3. \n**Education**: AI personalizes learning by          |  **Education**: AI personalizes learning by        \nadapting to individual student needs, providing     |  adapting to individual student needs, providing   \ntailored resources, and offering instant feedback.  |  tailored resources, and offering instant feedback.\nIt can also automate administrative tasks,          |  It can also automate administrative tasks,        \nallowing educators to focus more on teaching.   4.  |  allowing educators to focus more on teaching.   4.\n**Security**: AI enhances security systems through  |  **Security**: AI enhances security systems through\nfacial recognition, anomaly detection, and          |  facial recognition, anomaly detection, and        \npredictive analytics, making it possible to         |  predictive analytics, making it possible to       \nprevent crimes and terrorist activities more        |  prevent crimes and terrorist activities more      \neffectively.   5. **Ethics and Privacy**: AI        |  effectively.   5. **Ethics and Privacy**: AI      \nraises ethical concerns regarding decision-making,  |  raises ethical concerns regarding decision-making,\nbias, and accountability. It also challenges        |  bias, and accountability. It also challenges      \nprivacy norms as AI systems often require vast      |  privacy norms as AI systems often require vast    \namounts of personal data to function effectively.   |  amounts of personal data to function effectively. \n6. **Social Interaction**: AI-powered chatbots and  |  6. **Social Interaction**: AI-powered chatbots and\nvirtual assistants are changing the way we          |  virtual assistants are changing the way we        \ncommunicate, providing instant responses and        |  communicate, providing instant responses and      \nsupport. However, there's a risk of over-reliance   |  support. However, there's a risk of over-reliance \non technology for social interaction.   7.          |  on technology for social interaction.   7.        \n**Environment**: AI can help in monitoring and      |  **Environment**: AI can help in monitoring and    \nmanaging environmental resources, predicting        |  managing environmental resources, predicting      \nclimate change impacts, and optimizing energy       |  climate change impacts, and optimizing energy     \nconsumption, contributing to sustainability         |  consumption, contributing to sustainability       \nefforts.   In conclusion, AI's implications are     |  efforts.   In conclusion, AI's implications are   \nvast and multifaceted, offering both opportunities  |  vast and multifaceted, offering both opportunities\nand challenges that society must navigate           |  and challenges that society must navigate         \ncarefully.   ### Instruction: Craft a detailed      |  carefully.   ### Instruction: Craft a detailed    \nanalysis of the impact of Quantum Computing on      |  analysis of the impact of Quantum Computing on    \ncybersecurity, considering the following            |  cybersecurity, considering the following          \nconstraints:  1. Discuss the potential of Quantum   |  constraints:  1. Discuss the potential of Quantum \nComputing to break current encryption methods.  2.  |  Computing to break current encryption methods.  2.\nExamine the development of Quantum-Resistant        |  Examine the development of Quantum-Resistant      \nalgorithms.  3. Analyze the role of Quantum         |  algorithms.  3. Analyze the role of Quantum       \nComputing in enhancing secure communications.  4.   |  Computing in enhancing secure communications.  4. \nConsider the ethical implications of Quantum        |  Consider the ethical implications of Quantum      \nComputing in cybersecurity.  5. Evaluate the        |  Computing in cybersecurity.  5. Evaluate the      \nreadiness of current infrastructure to adopt        |  readiness of the cybersecurity industry to adapt  \nQuantum Computing technologies.  6. Explore the     |  to Quantum Computing.  6. Provide historical      \npotential for Quantum Computing to create new       |  context by comparing Quantum Computing's impact to\ncybersecurity threats.  7. Provide examples of      |  that of the advent of the internet.  7. Include at\nQuantum Computing applications in cybersecurity.    |  least two case studies where Quantum Computing has\n### Input:   ### Response: Quantum Computing (QC)   |  been applied in cybersecurity.   ### Response:    \nrepresents a paradigm shift in computational        |  Quantum Computing (QC) represents a paradigm shift\npower, with significant implications for            |  in computational power, with significant          \ncybersecurity. Here's a detailed analysis           |  implications for cybersecurity. Here's a detailed \nconsidering the specified constraints:   1.         |  analysis considering the specified constraints:   \n**Breaking Encryption**: QC poses a threat to       |  1. **Breaking Encryption**: QC poses a threat to  \ncurrent encryption methods, particularly those      |  current encryption methods, particularly those    \nbased on factorization of large numbers, such as    |  based on factorization of large numbers, such as  \nRSA. Quantum algorithms like Shor's algorithm can   |  RSA. Shor's algorithm, when run on a sufficiently \ntheoretically break these systems, compromising     |  powerful quantum computer, could factor these     \nthe security of encrypted data.   2. **Quantum-     |  large numbers efficiently, rendering many of      \nResistant Algorithms**: In response, researchers    |  today's encryption systems vulnerable.   2.       \nare developing Quantum-Resistant algorithms, such   |  **Quantum-Resistant Algorithms**: In response,    \nas lattice-based, hash-based, and multivariate      |  researchers are developing quantum-resistant      \npolynomial public key cryptography, which are       |  algorithms, such as lattice-based, hash-based, and\nbelieved to be secure against quantum attacks.      |  multivariate polynomial public key cryptography.  \n3. **Secure Communications**: Quantum Key           |  These algorithms are believed to be secure against\nDistribution (QKD) uses the principles of quantum   |  both classical and quantum attacks, ensuring the  \nmechanics to enable secure communication channels.  |  confidentiality and integrity of data in a post-  \nIt ensures that any attempt at eavesdropping can    |  quantum world.   3. **Enhancing Secure            \nbe detected, as it would alter the quantum state    |  Communications**: Quantum Key Distribution (QKD)  \nof the transmitted particles.   4. **Ethical        |  uses the principles of quantum mechanics to enable\nImplications**: The advent of QC in cybersecurity   |  two parties to generate a shared random secret    \nraises ethical concerns about privacy and           |  key, which can be used to encrypt and decrypt     \nsurveillant capabilities. There's a need for a      |  messages, ensuring secure communication that is   \nbalance between national security interests and     |  theoretically immune to eavesdropping.   4.       \nindividual privacy rights.   5. **Infrastructure    |  **Ethical Implications**: The advent of QC in     \nReadiness**: Current infrastructure is not ready    |  cybersecurity raises ethical concerns, such as the\nfor widespread adoption of QC technologies. There   |  potential for a new arms race in quantum          \nare significant challenges in terms of hardware,    |  technologies and the need for equitable access to \nsoftware, and the need for a skilled workforce to   |  quantum-safe security solutions.   5. **Industry  \nmanage and maintain quantum systems.   6. **New     |  Readiness**: The cybersecurity industry is at     \nThreats**: QC could lead to new cybersecurity       |  various stages of readiness. While some           \nthreats, such as the ability to crack previously    |  organizations are proactively investing in        \nsecure systems, potentially exposing sensitive      |  quantum-safe solutions, others are lagging,       \ndata and creating vulnerabilities in critical       |  creating a potential security gap.   6.           \n                                                    |  **Historical Context**                            \n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T08:56:56.468217Z","iopub.execute_input":"2024-11-24T08:56:56.468489Z","iopub.status.idle":"2024-11-24T08:58:51.547796Z","shell.execute_reply.started":"2024-11-24T08:56:56.468462Z","shell.execute_reply":"2024-11-24T08:58:51.546914Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    2009140224                     |                     2080443392                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: In this    |  completes the request.  ### Instruction: In this  \ntask, you need to provide an example of how the     |  task, you need to provide an example of how the   \ngiven words can be used in a sentence.  ### Input:  |  given words can be used in a sentence.  ### Input:\nWords: Fantasy, Magical  ### Response: In the       |  Words: Fantasy, Magical  ### Response: In the     \nfantasy novel, the protagonist discovered a         |  fantasy novel, the protagonist discovered a       \nmagical amulet that granted her the power to        |  magical amulet that granted her the power to      \ncontrol the elements.   ### Instruction: For this   |  control the elements.   ### Instruction: For this \ntask, you are required to create a complex          |  task, you are required to create a complex        \nsentence that incorporates the given words,         |  sentence that incorporates the given words,       \nadheres to a specified grammatical structure, and   |  adheres to a specified grammatical structure, and \nincludes a metaphorical comparison. The sentence    |  includes a metaphorical comparison. The sentence  \nmust also contain a subordinate clause that         |  must also contain a subordinate clause that       \nprovides additional information about the main      |  provides additional information about the main    \nsubject.  ### Input: Words: Enigma, Labyrinthine    |  subject.  ### Input: Words: Enigma, Labyrinthine  \n### Response: The enigma of the ancient             |  ### Response: The enigma of the ancient           \nmanuscript, as intricate and labyrinthine as the    |  manuscript, as intricate and labyrinthine as the  \nplot of a Shakespearean play, remained unsolved,    |  plot of a Shakespearean play, remained unsolved,  \nmuch like a minotaur lost in its own maze, until    |  much like a minotaur lost in its own maze, until  \nthe linguist's keen insight unraveled its secrets.  |  the linguist's keen insight unraveled its secrets.\n### Instruction: In this task, you are to craft a   |  ### Instruction: In this task, you are to craft a \nsentence that not only uses the given words but     |  sentence that not only uses the given words but   \nalso follows a specific rhythmic pattern (iambic    |  also follows a specific rhythmic pattern (iambic  \npentameter), includes a historical reference, and   |  pentameter), includes a historical reference, and \ncontains a rhetorical question.  ### Input: Words:  |  contains a rhetorical question.  ### Input: Words:\nRevolution, Epoch  ### Response: Did not the        |  Revolution, Epoch  ### Response: Did not the      \nFrench Revolution mark an epoch, whereupon the      |  French Revolution mark an epoch, whereupon the    \ncommon man's plight, like a phoenix, rose from      |  common man's plight, like a phoenix, rose from    \nashes to claim the dawn?   ### Instruction: For     |  ashes to claim the dawn?   ### Instruction: For   \nthis task, you must formulate a sentence that uses  |  this task, you must construct a sentence that uses\nthe given words, follows a strict iambic            |  the given words, follows a specified rhythmic     \npentameter, includes a simile, a historical         |  pattern (iambic pentameter), includes a historical\nfigure, and a philosophical question.  ### Input:   |  reference, contains a rhetorical question, and    \nWords: Renaissance, Da Vinci  ### Response: In      |  embeds a subtle allusion to a work of art.  ###   \nRenaissance's bloom, did Da Vinci's art, like a     |  Input: Words: Revolution, Epoch  ### Response: Did\nmirror, reflect the soul's quest for truth, and     |  not the storming of the Bastille signal an epoch, \nnot just beauty's form?   ### Instruction: In this  |  as if Da Vinci's 'Last Supper' had whispered to   \ntask, you are to compose a sentence that uses the   |  the masses, urging them to paint their own        \ngiven words, follows a strict iambic pentameter,    |  destiny?   ### Instruction: In this task, you are \nincludes a simile, a historical event, and a        |  to create a sentence that uses the given words,   \nphilosophical question.  ### Input: Words:          |  follows a specified rhythmic pattern (iambic      \nEnlightenment, Voltaire  ### Response: Did          |  pentameter), includes a historical reference,     \nVoltaire's wit, sharp as a blade, cut through       |  contains a rhetorical question, embeds a subtle   \ndarkness, like the Enlightenment's light, to ask:   |  allusion to a work of art, and must also imply a  \nIs reason mankind's true guide?                     |  moral lesson.  ### Input: Words: Revolution, Epoch\n                                                    |  ### Response: Did not the fall of the Bastille    \n                                                    |  herald an epoch, as if 'Guernica's' silent screams\n                                                    |  had stirred the hearts of men, teaching us that   \n                                                    |  from the ashes of tyranny, freedom's seed may     \n                                                    |  sprout?   ### Instruction: For this task, you are \n                                                    |  to craft a sentence that uses the given words,    \n                                                    |  follows a specified rhythmic pattern (iambic      \n                                                    |  pentameter), includes a historical reference,     \n                                                    |  contains a rhetorical question, embeds a subtle   \n                                                    |  allusion to a work of art, implies a moral lesson,\n                                                    |  and must also use an archaic word.  ### Input:    \n                                                    |  Words: Revolution, Epoch  ### Response: Did not   \n                                                    |  the fall of the Bastille herald an epoch, as if   \n                                                    |  'The School of Athens' had whispered wisdoms old, \n                                                    |  teaching us that from oppression's grip, liberty's\n                                                    |  light may break?   ### Instruction: In this task, \n                                                    |  you are to create a sentence that uses the given  \n                                                    |  words, follows a specified rhythmic pattern       \n                                                    |  (iambic pentameter), includes a historical        \n                                                    |  reference, contains a rhetorical question, embeds \n                                                    |  a subtle allusion to a work of art, implies a     \n                                                    |  moral lesson, uses an archaic word, and must also \n                                                    |  incorporate a scientific concept.  ### Input:     \n                                                    |  Words: Revolution, Epoch  ### Response: Did not   \n                                                    |  the Bastille's fall, like gravity's unyielding    \n                                                    |  law, herald an epoch, as if 'The School of Athens'\n                                                    |  had whispered wisdoms old, teaching us that from  \n                                                    |  tyranny's dark abyss, freedom's light may break?  \n                                                    |  ### Instruction: For this task, you are to craft a\n                                                    |  sentence that uses the given words, follows a     \n                                                    |  specified rhythmic pattern (iambic pentameter),   \n                                                    |  includes a historical reference, contains a       \n                                                    |  rhetorical question, embeds a subtle allusion to a\n                                                    |  work of art, implies a moral lesson, uses an      \n                                                    |  archaic word, incorporates a scientific concept,  \n                                                    |  and must also reference a specific year.  ###     \n                                                    |  Input: Words: Revolution, Epoch  ### Response: Did\n                                                    |  not the Bastille's fall in seventeen eighty       \n","output_type":"stream"}],"execution_count":56}]}