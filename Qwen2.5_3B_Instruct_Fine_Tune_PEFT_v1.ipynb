{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-17T05:10:47.311982Z","iopub.execute_input":"2024-11-17T05:10:47.312395Z","iopub.status.idle":"2024-11-17T05:11:33.991963Z","shell.execute_reply.started":"2024-11-17T05:10:47.312345Z","shell.execute_reply":"2024-11-17T05:11:33.990860Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-11-17T05:11:33.994412Z","iopub.execute_input":"2024-11-17T05:11:33.995170Z","iopub.status.idle":"2024-11-17T05:11:42.373061Z","shell.execute_reply.started":"2024-11-17T05:11:33.995120Z","shell.execute_reply":"2024-11-17T05:11:42.372070Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-11-17T05:11:42.374643Z","iopub.execute_input":"2024-11-17T05:11:42.375076Z","iopub.status.idle":"2024-11-17T05:11:42.384415Z","shell.execute_reply.started":"2024-11-17T05:11:42.375031Z","shell.execute_reply":"2024-11-17T05:11:42.383328Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'Qwen/Qwen2.5-3B-Instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-17T05:11:42.387042Z","iopub.execute_input":"2024-11-17T05:11:42.387817Z","iopub.status.idle":"2024-11-17T05:11:42.395024Z","shell.execute_reply.started":"2024-11-17T05:11:42.387773Z","shell.execute_reply":"2024-11-17T05:11:42.394169Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-11-17T05:11:42.396373Z","iopub.execute_input":"2024-11-17T05:11:42.396724Z","iopub.status.idle":"2024-11-17T05:11:42.406448Z","shell.execute_reply.started":"2024-11-17T05:11:42.396682Z","shell.execute_reply":"2024-11-17T05:11:42.405572Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:42.407976Z","iopub.execute_input":"2024-11-17T05:11:42.408741Z","iopub.status.idle":"2024-11-17T05:11:50.309202Z","shell.execute_reply.started":"2024-11-17T05:11:42.408688Z","shell.execute_reply":"2024-11-17T05:11:50.308313Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd652bc78395424b876a30d146f9d917"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 2048)\n    (layers): ModuleList(\n      (0-35): 36 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n          (down_proj): Linear4bit(in_features=11008, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:50.310342Z","iopub.execute_input":"2024-11-17T05:11:50.310615Z","iopub.status.idle":"2024-11-17T05:11:50.322229Z","shell.execute_reply.started":"2024-11-17T05:11:50.310585Z","shell.execute_reply":"2024-11-17T05:11:50.321344Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1698672640\nTrainable parameters : 311314432\nTrainable percentage: 18.33%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:50.323443Z","iopub.execute_input":"2024-11-17T05:11:50.323802Z","iopub.status.idle":"2024-11-17T05:11:50.814576Z","shell.execute_reply.started":"2024-11-17T05:11:50.323749Z","shell.execute_reply":"2024-11-17T05:11:50.813761Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'mlabonne/FineTome-100k'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:50.815737Z","iopub.execute_input":"2024-11-17T05:11:50.816063Z","iopub.status.idle":"2024-11-17T05:11:50.820388Z","shell.execute_reply.started":"2024-11-17T05:11:50.816029Z","shell.execute_reply":"2024-11-17T05:11:50.819347Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 768","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:50.824197Z","iopub.execute_input":"2024-11-17T05:11:50.824501Z","iopub.status.idle":"2024-11-17T05:11:50.831657Z","shell.execute_reply.started":"2024-11-17T05:11:50.824454Z","shell.execute_reply":"2024-11-17T05:11:50.830829Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:50.832757Z","iopub.execute_input":"2024-11-17T05:11:50.833399Z","iopub.status.idle":"2024-11-17T05:11:52.402243Z","shell.execute_reply.started":"2024-11-17T05:11:50.833364Z","shell.execute_reply":"2024-11-17T05:11:52.401330Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations', 'source', 'score'],\n    num_rows: 100000\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.403317Z","iopub.execute_input":"2024-11-17T05:11:52.403591Z","iopub.status.idle":"2024-11-17T05:11:52.411020Z","shell.execute_reply.started":"2024-11-17T05:11:52.403561Z","shell.execute_reply":"2024-11-17T05:11:52.410156Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.412070Z","iopub.execute_input":"2024-11-17T05:11:52.412382Z","iopub.status.idle":"2024-11-17T05:11:52.442621Z","shell.execute_reply.started":"2024-11-17T05:11:52.412351Z","shell.execute_reply":"2024-11-17T05:11:52.441732Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                       conversations  \\\n0  [{'from': 'human', 'value': 'Explain what bool...   \n1  [{'from': 'human', 'value': 'Explain how recur...   \n2  [{'from': 'human', 'value': 'Explain what bool...   \n3  [{'from': 'human', 'value': 'Explain the conce...   \n4  [{'from': 'human', 'value': 'Print the reverse...   \n\n                     source     score  \n0  infini-instruct-top-500k  5.212621  \n1  infini-instruct-top-500k  5.157649  \n2  infini-instruct-top-500k  5.147540  \n3  infini-instruct-top-500k  5.053656  \n4  infini-instruct-top-500k  5.045648  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversations</th>\n      <th>source</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.212621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[{'from': 'human', 'value': 'Explain how recur...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.157649</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.147540</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[{'from': 'human', 'value': 'Explain the conce...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.053656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[{'from': 'human', 'value': 'Print the reverse...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.045648</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.443725Z","iopub.execute_input":"2024-11-17T05:11:52.444041Z","iopub.status.idle":"2024-11-17T05:11:52.450426Z","shell.execute_reply.started":"2024-11-17T05:11:52.443987Z","shell.execute_reply":"2024-11-17T05:11:52.449446Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'from': 'human',\n   'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'},\n  {'from': 'gpt',\n   'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}],\n 'source': 'infini-instruct-top-500k',\n 'score': 5.212620735168457}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.451812Z","iopub.execute_input":"2024-11-17T05:11:52.452379Z","iopub.status.idle":"2024-11-17T05:11:52.458152Z","shell.execute_reply.started":"2024-11-17T05:11:52.452334Z","shell.execute_reply":"2024-11-17T05:11:52.457211Z"}},"outputs":[{"name":"stdout","text":"['conversations', 'source', 'score']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"def transform_conversations(example):\n  role_map = {\n    'human' : 'user',\n    'gpt' : 'assistant'\n  }\n\n  transformed_conversations = [\n    {\n      'role' : role_map.get(turn['from'], turn['from']),\n      'content' : turn['value']\n    }\n    for turn in example['conversations']\n  ]\n  return {'conversations': transformed_conversations}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.459279Z","iopub.execute_input":"2024-11-17T05:11:52.459674Z","iopub.status.idle":"2024-11-17T05:11:52.465530Z","shell.execute_reply.started":"2024-11-17T05:11:52.459641Z","shell.execute_reply":"2024-11-17T05:11:52.464783Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"formatted_dataset = dataset.map(transform_conversations, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.466736Z","iopub.execute_input":"2024-11-17T05:11:52.467622Z","iopub.status.idle":"2024-11-17T05:11:52.480224Z","shell.execute_reply.started":"2024-11-17T05:11:52.467574Z","shell.execute_reply":"2024-11-17T05:11:52.479302Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(formatted_dataset[0]['conversations'])","metadata":{"id":"cZya4tPEWUc9","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.481427Z","iopub.execute_input":"2024-11-17T05:11:52.482184Z","iopub.status.idle":"2024-11-17T05:11:52.486809Z","shell.execute_reply.started":"2024-11-17T05:11:52.482151Z","shell.execute_reply":"2024-11-17T05:11:52.486066Z"}},"outputs":[{"name":"stdout","text":"[{'content': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.', 'role': 'user'}, {'content': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.', 'role': 'assistant'}]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def format_conversation(example):\n  for entry in example['conversations']:\n    role = entry['role']\n    content = entry['content']\n\n    if role == 'user':\n      formatted_text = f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n    elif role == 'assistant':\n      formatted_text += f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n\n  return {'prompt': formatted_text}","metadata":{"id":"3bmXGueQWWzt","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.488344Z","iopub.execute_input":"2024-11-17T05:11:52.489126Z","iopub.status.idle":"2024-11-17T05:11:52.495342Z","shell.execute_reply.started":"2024-11-17T05:11:52.489081Z","shell.execute_reply":"2024-11-17T05:11:52.494564Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"formatted_dataset = formatted_dataset.map(\n  format_conversation,\n  remove_columns = list(formatted_dataset.features.keys())\n)\nformatted_dataset","metadata":{"id":"Z6sSaCr5eaL7","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.496555Z","iopub.execute_input":"2024-11-17T05:11:52.497443Z","iopub.status.idle":"2024-11-17T05:11:52.509158Z","shell.execute_reply.started":"2024-11-17T05:11:52.497399Z","shell.execute_reply":"2024-11-17T05:11:52.508233Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.510242Z","iopub.execute_input":"2024-11-17T05:11:52.510554Z","iopub.status.idle":"2024-11-17T05:11:52.516208Z","shell.execute_reply.started":"2024-11-17T05:11:52.510522Z","shell.execute_reply":"2024-11-17T05:11:52.515256Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.517394Z","iopub.execute_input":"2024-11-17T05:11:52.517755Z","iopub.status.idle":"2024-11-17T05:11:52.525155Z","shell.execute_reply.started":"2024-11-17T05:11:52.517713Z","shell.execute_reply":"2024-11-17T05:11:52.524278Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:11:52.526439Z","iopub.execute_input":"2024-11-17T05:11:52.527107Z","iopub.status.idle":"2024-11-17T05:12:02.438986Z","shell.execute_reply.started":"2024-11-17T05:11:52.527060Z","shell.execute_reply":"2024-11-17T05:12:02.438050Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35e3115fc4384ea783b9a96c60d88902"}},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.440180Z","iopub.execute_input":"2024-11-17T05:12:02.440470Z","iopub.status.idle":"2024-11-17T05:12:02.446655Z","shell.execute_reply.started":"2024-11-17T05:12:02.440439Z","shell.execute_reply":"2024-11-17T05:12:02.445749Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.447952Z","iopub.execute_input":"2024-11-17T05:12:02.448341Z","iopub.status.idle":"2024-11-17T05:12:02.624698Z","shell.execute_reply.started":"2024-11-17T05:12:02.448300Z","shell.execute_reply":"2024-11-17T05:12:02.623793Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.625890Z","iopub.execute_input":"2024-11-17T05:12:02.626289Z","iopub.status.idle":"2024-11-17T05:12:02.632740Z","shell.execute_reply.started":"2024-11-17T05:12:02.626247Z","shell.execute_reply":"2024-11-17T05:12:02.631854Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.634088Z","iopub.execute_input":"2024-11-17T05:12:02.634477Z","iopub.status.idle":"2024-11-17T05:12:02.663577Z","shell.execute_reply.started":"2024-11-17T05:12:02.634434Z","shell.execute_reply":"2024-11-17T05:12:02.662686Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n1  <|start_header_id|>user<|end_header_id|>\\n\\nWr...   \n2  <|start_header_id|>user<|end_header_id|>\\n\\nWh...   \n3  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n4  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n\n                                           input_ids  \\\n0  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n1  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n2  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n3  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n4  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWr...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWh...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.670517Z","iopub.execute_input":"2024-11-17T05:12:02.670828Z","iopub.status.idle":"2024-11-17T05:12:02.676984Z","shell.execute_reply.started":"2024-11-17T05:12:02.670795Z","shell.execute_reply":"2024-11-17T05:12:02.676063Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nHow do you graph the inequality #x > -4#?\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nTo graph the inequality #x > -4#, follow these steps:\n\n1. Start by plotting the boundary line: Draw a vertical line at #x = -4# on the X-axis. This line divides the X-axis into two halves.\n\n2. Identify the direction of the inequality: Since the inequality is #x > -4#, it indicates that we are looking for all values of #x# that are greater than -4.\n\n3. Shade the appropriate region: Shade the entire region to the right of the line at #x = -4#. This shaded area represents all the points whose X-coordinate is greater than -4.\n\n4. Include a dashed line: Since the inequality is \"greater than\" (#>,# not \"#≥#\"), draw the line at #x = -4# as a dashed line, indicating that the points on the line itself are not included in the solution.\n\nThe graph consists of the entire half-plane to the right of the dashed vertical line at #x = -4#, excluding the line itself.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.678134Z","iopub.execute_input":"2024-11-17T05:12:02.678482Z","iopub.status.idle":"2024-11-17T05:12:02.688171Z","shell.execute_reply.started":"2024-11-17T05:12:02.678442Z","shell.execute_reply":"2024-11-17T05:12:02.687321Z"}},"outputs":[{"name":"stdout","text":"[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91, 408, 8757, 842, 91, 1339, 4340, 653, 498, 4771, 279, 31205, 671, 87, 861, 481, 19, 2, 5267, 27, 91, 68, 354, 842, 91, 1784, 91, 2468, 8757, 842, 91, 29, 77091, 27, 91, 408, 8757, 842, 91, 1339, 1249, 4771, 279, 31205, 671, 87, 861, 481, 19, 60778, 1795, 1493, 7354, 1447, 16, 13, 5145, 553, 43902, 279, 18732, 1555, 25, 11992, 264, 12140, 1555, 518, 671, 87, 284, 481, 19, 2, 389, 279, 1599, 35321, 13, 1096, 1555, 64828, 279, 1599, 35321, 1119, 1378, 74112, 382, 17, 13, 64547, 279, 5106, 315, 279, 31205, 25, 8704, 279, 31205, 374, 671, 87, 861, 481, 19, 60778, 432, 14807, 429, 582, 525, 3330, 369, 678, 2750, 315, 671, 87, 2, 429, 525, 7046, 1091, 481, 19, 382, 18, 13, 79818, 279, 8311, 5537, 25, 79818, 279, 4453, 5537, 311, 279, 1290, 315, 279, 1555, 518, 671, 87, 284, 481, 19, 87846, 1096, 91766, 3082, 10868, 678, 279, 3501, 6693, 1599, 80697, 374, 7046, 1091, 481, 19, 382, 19, 13, 29734, 264, 66722, 1555, 25, 8704, 279, 31205, 374, 330, 65235, 1091, 1, 29083, 8066, 2, 537, 5869, 144481, 2, 3975, 4038, 279, 1555, 518, 671, 87, 284, 481, 19, 2, 438, 264, 66722, 1555, 11, 18860, 429, 279, 3501, 389, 279, 1555, 5086, 525, 537, 5230, 304, 279, 6291, 382, 785, 4771, 17167, 315, 279, 4453, 4279, 89549, 311, 279, 1290, 315, 279, 66722, 12140, 1555, 518, 671, 87, 284, 481, 19, 60778, 43778, 279, 1555, 5086, 624, 27, 91, 68, 354, 842, 91, 29, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.689407Z","iopub.execute_input":"2024-11-17T05:12:02.690188Z","iopub.status.idle":"2024-11-17T05:12:02.699411Z","shell.execute_reply.started":"2024-11-17T05:12:02.690142Z","shell.execute_reply":"2024-11-17T05:12:02.698447Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.700414Z","iopub.execute_input":"2024-11-17T05:12:02.700724Z","iopub.status.idle":"2024-11-17T05:12:02.708474Z","shell.execute_reply.started":"2024-11-17T05:12:02.700691Z","shell.execute_reply":"2024-11-17T05:12:02.707653Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.709548Z","iopub.execute_input":"2024-11-17T05:12:02.709833Z","iopub.status.idle":"2024-11-17T05:12:02.718761Z","shell.execute_reply.started":"2024-11-17T05:12:02.709802Z","shell.execute_reply":"2024-11-17T05:12:02.717910Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.719758Z","iopub.execute_input":"2024-11-17T05:12:02.720085Z","iopub.status.idle":"2024-11-17T05:12:02.728262Z","shell.execute_reply.started":"2024-11-17T05:12:02.720045Z","shell.execute_reply":"2024-11-17T05:12:02.727454Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.729293Z","iopub.execute_input":"2024-11-17T05:12:02.729646Z","iopub.status.idle":"2024-11-17T05:12:02.737270Z","shell.execute_reply.started":"2024-11-17T05:12:02.729602Z","shell.execute_reply":"2024-11-17T05:12:02.736513Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:02.738336Z","iopub.execute_input":"2024-11-17T05:12:02.738629Z","iopub.status.idle":"2024-11-17T05:12:04.413037Z","shell.execute_reply.started":"2024-11-17T05:12:02.738597Z","shell.execute_reply":"2024-11-17T05:12:04.412098Z"}},"outputs":[{"name":"stdout","text":"trainable params: 119,734,272 || all params: 3,205,672,960 || trainable%: 3.7351\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:04.414508Z","iopub.execute_input":"2024-11-17T05:12:04.415420Z","iopub.status.idle":"2024-11-17T05:12:04.454699Z","shell.execute_reply.started":"2024-11-17T05:12:04.415371Z","shell.execute_reply":"2024-11-17T05:12:04.452071Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 2048)\n    (layers): ModuleList(\n      (0-35): 36 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=11008, out_features=2048, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=11008, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:04.458292Z","iopub.execute_input":"2024-11-17T05:12:04.458931Z","iopub.status.idle":"2024-11-17T05:12:04.491966Z","shell.execute_reply.started":"2024-11-17T05:12:04.458889Z","shell.execute_reply":"2024-11-17T05:12:04.490913Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1818406912\nTrainable parameters : 119734272\nTrainable percentage: 6.58%\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:04.493293Z","iopub.execute_input":"2024-11-17T05:12:04.493688Z","iopub.status.idle":"2024-11-17T05:12:04.499069Z","shell.execute_reply.started":"2024-11-17T05:12:04.493652Z","shell.execute_reply":"2024-11-17T05:12:04.497891Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 1\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:04.500501Z","iopub.execute_input":"2024-11-17T05:12:04.500859Z","iopub.status.idle":"2024-11-17T05:12:04.538927Z","shell.execute_reply.started":"2024-11-17T05:12:04.500808Z","shell.execute_reply":"2024-11-17T05:12:04.538055Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov17_05-12-04_84769eed1484,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:04.540064Z","iopub.execute_input":"2024-11-17T05:12:04.540360Z","iopub.status.idle":"2024-11-17T05:12:06.847147Z","shell.execute_reply.started":"2024-11-17T05:12:04.540330Z","shell.execute_reply":"2024-11-17T05:12:06.846286Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x786210097460>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T05:12:06.848309Z","iopub.execute_input":"2024-11-17T05:12:06.848698Z","iopub.status.idle":"2024-11-17T06:15:15.079273Z","shell.execute_reply.started":"2024-11-17T05:12:06.848652Z","shell.execute_reply":"2024-11-17T06:15:15.078356Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 1\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 119,734,272\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111371560000407, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f9874e572d145db8de8142f6da92d0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241117_051208-gbxl9pvo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/gbxl9pvo' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/gbxl9pvo' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/gbxl9pvo</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 1:02:53, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>1.175800</td>\n      <td>1.060939</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.910900</td>\n      <td>0.933555</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.882200</td>\n      <td>0.855007</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.855700</td>\n      <td>0.804848</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.778400</td>\n      <td>0.791469</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.792100</td>\n      <td>0.783412</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.759600</td>\n      <td>0.776977</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.783500</td>\n      <td>0.773864</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.807100</td>\n      <td>0.772589</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.734900</td>\n      <td>0.772384</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.8480108737945556, metrics={'train_runtime': 3787.6462, 'train_samples_per_second': 0.211, 'train_steps_per_second': 0.053, 'total_flos': 1.11117028294656e+16, 'train_loss': 0.8480108737945556, 'epoch': 0.08888888888888889})"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:15:15.080446Z","iopub.execute_input":"2024-11-17T06:15:15.080761Z","iopub.status.idle":"2024-11-17T06:18:19.854318Z","shell.execute_reply.started":"2024-11-17T06:15:15.080728Z","shell.execute_reply":"2024-11-17T06:18:19.853371Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 03:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.7723840475082397, 'eval_runtime': 184.7599, 'eval_samples_per_second': 1.082, 'eval_steps_per_second': 0.271, 'epoch': 0.08888888888888889}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:19.855694Z","iopub.execute_input":"2024-11-17T06:18:19.856412Z","iopub.status.idle":"2024-11-17T06:18:23.050278Z","shell.execute_reply.started":"2024-11-17T06:18:19.856365Z","shell.execute_reply":"2024-11-17T06:18:23.049261Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 70,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 36,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 70,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 36,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:23.051722Z","iopub.execute_input":"2024-11-17T06:18:23.052296Z","iopub.status.idle":"2024-11-17T06:18:23.362674Z","shell.execute_reply.started":"2024-11-17T06:18:23.052261Z","shell.execute_reply":"2024-11-17T06:18:23.361736Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:23.363942Z","iopub.execute_input":"2024-11-17T06:18:23.364334Z","iopub.status.idle":"2024-11-17T06:18:23.377478Z","shell.execute_reply.started":"2024-11-17T06:18:23.364292Z","shell.execute_reply":"2024-11-17T06:18:23.376346Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:23.380674Z","iopub.execute_input":"2024-11-17T06:18:23.381024Z","iopub.status.idle":"2024-11-17T06:18:25.396231Z","shell.execute_reply.started":"2024-11-17T06:18:23.380964Z","shell.execute_reply":"2024-11-17T06:18:25.395406Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:25.397415Z","iopub.execute_input":"2024-11-17T06:18:25.397701Z","iopub.status.idle":"2024-11-17T06:18:32.875669Z","shell.execute_reply.started":"2024-11-17T06:18:25.397671Z","shell.execute_reply":"2024-11-17T06:18:32.874295Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2.5-3B-Instruct\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 70,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 36,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/model.safetensors.index.json\nInstantiating Qwen2ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"809baaac21a041e394293b0a7e1f0f2f"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-3B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B-Instruct/snapshots/aa8e72537993ba99e69dfaafa59ed015b17504d1/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    151645,\n    151643\n  ],\n  \"pad_token_id\": 151643,\n  \"repetition_penalty\": 1.05,\n  \"temperature\": 0.7,\n  \"top_k\": 20,\n  \"top_p\": 0.8\n}\n\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 2048)\n    (layers): ModuleList(\n      (0-35): 36 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n          (down_proj): Linear4bit(in_features=11008, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:32.876995Z","iopub.execute_input":"2024-11-17T06:18:32.877342Z","iopub.status.idle":"2024-11-17T06:18:32.890264Z","shell.execute_reply.started":"2024-11-17T06:18:32.877307Z","shell.execute_reply":"2024-11-17T06:18:32.889349Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1698672640\nTrainable parameters : 311314432\nTrainable percentage: 18.33%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:32.891594Z","iopub.execute_input":"2024-11-17T06:18:32.891895Z","iopub.status.idle":"2024-11-17T06:18:32.929047Z","shell.execute_reply.started":"2024-11-17T06:18:32.891851Z","shell.execute_reply":"2024-11-17T06:18:32.928162Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(151936, 2048)\n        (layers): ModuleList(\n          (0-35): 36 x Qwen2DecoderLayer(\n            (self_attn): Qwen2SdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): Qwen2RotaryEmbedding()\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n                  (default): Linear(in_features=64, out_features=11008, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n                  (default): Linear(in_features=64, out_features=11008, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=11008, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=11008, out_features=64, bias=False)\n                  (default): Linear(in_features=11008, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:32.930270Z","iopub.execute_input":"2024-11-17T06:18:32.930645Z","iopub.status.idle":"2024-11-17T06:18:32.969779Z","shell.execute_reply.started":"2024-11-17T06:18:32.930600Z","shell.execute_reply":"2024-11-17T06:18:32.968682Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1938141184\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"## 13 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  messages = [\n    {'role' : 'system', 'content' : 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.'},\n    {'role' : 'user', 'content': prompt}\n  ]\n  inputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True,\n    return_tensors = 'pt',\n    truncation = True,\n    padding = True,\n  ).to('cuda')\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    input_ids = inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:32.970893Z","iopub.execute_input":"2024-11-17T06:18:32.971200Z","iopub.status.idle":"2024-11-17T06:18:32.978707Z","shell.execute_reply.started":"2024-11-17T06:18:32.971167Z","shell.execute_reply":"2024-11-17T06:18:32.977766Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"def post_assistant(prompt):\n  messages = [\n    {'role' : 'system', 'content' : 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.'},\n    {'role' : 'user', 'content': prompt}\n  ]\n  inputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True,\n    return_tensors = 'pt',\n    truncation = True,\n    padding = True,\n  ).to('cuda')\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    input_ids = inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:32.979904Z","iopub.execute_input":"2024-11-17T06:18:32.980281Z","iopub.status.idle":"2024-11-17T06:18:32.988774Z","shell.execute_reply.started":"2024-11-17T06:18:32.980248Z","shell.execute_reply":"2024-11-17T06:18:32.987914Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:18:32.989960Z","iopub.execute_input":"2024-11-17T06:18:32.990322Z","iopub.status.idle":"2024-11-17T06:18:33.001325Z","shell.execute_reply.started":"2024-11-17T06:18:32.990290Z","shell.execute_reply":"2024-11-17T06:18:33.000441Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:29:10.410526Z","iopub.execute_input":"2024-11-17T06:29:10.411346Z","iopub.status.idle":"2024-11-17T06:31:31.908802Z","shell.execute_reply.started":"2024-11-17T06:29:10.411305Z","shell.execute_reply":"2024-11-17T06:31:31.907668Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user Describe how  |  assistant.<|im_end|> <|im_start|>user Describe how\nairplanes maintain altitude.<|im_end|>              |  airplanes maintain altitude.<|im_end|>            \n<|im_start|>assistant Airplanes maintain altitude   |  <|im_start|>assistant Airplanes maintain altitude \nthrough a combination of aerodynamic design,        |  through a combination of aerodynamic design,      \nengine thrust, and the use of various systems and   |  engine thrust, and the use of various systems and \ninstruments. Here’s a detailed explanation:  1.     |  instruments. Here’s a detailed explanation:  1.   \n**Aerodynamic Design**: Modern airplanes are        |  **Aerodynamic Design**: Modern airplanes are      \ndesigned with aerodynamic surfaces such as wings,   |  designed with aerodynamic surfaces such as wings, \ntailplanes, and control surfaces (ailerons,         |  tailplanes, and control surfaces (ailerons,       \nelevators, rudder) that are optimized to generate   |  elevators, rudder) that are optimized to generate \nlift. The lift generated by the wings is            |  lift. The lift generated by the wings is          \nproportional to the square of the airplane's speed  |  proportional to the square of the airplane's speed\nand the square of the air density. As the airplane  |  and the square of the air density. As the airplane\nclimbs, the air density decreases, and the pilot    |  climbs, the air density decreases, and the pilot  \nmust increase the angle of attack (the angle        |  must increase the angle of attack (the angle      \nbetween the wing and the oncoming airflow) to       |  between the wing and the oncoming airflow) to     \nmaintain the same amount of lift, which helps in    |  maintain the same amount of lift, which helps in  \nmaintaining altitude.  2. **Engine Thrust**: The    |  maintaining altitude.  2. **Engine Thrust**: The  \nengines of the airplane provide the thrust          |  engines of the airplane provide the thrust        \nnecessary to overcome the drag and maintain         |  necessary to overcome drag and maintain altitude. \naltitude. The thrust is adjusted according to the   |  The thrust is adjusted according to the airplane's\nairplane's speed and the required altitude. As the  |  speed and the required altitude. As the airplane  \nairplane climbs, the pilot may need to reduce       |  climbs, the pilot may need to reduce engine power \nengine power to prevent the airplane from flying    |  to prevent the airplane from flying too fast and  \ntoo fast and thus too high, which would increase    |  thus too high, which would increase drag and      \ndrag and require more thrust.  3. **Trim System**:  |  require more thrust.  3. **Trim System**: Modern  \nModern airplanes have a trim system that            |  airplanes have a trim system that automatically   \nautomatically adjusts the control surfaces (like    |  adjusts the control surfaces (like ailerons,      \nailerons, elevators, and rudder) to counteract the  |  elevators, and rudder) to counteract the          \naerodynamic forces acting on the airplane. This     |  aerodynamic forces acting on the airplane. This   \nhelps the pilot to maintain a steady altitude       |  helps the pilot to maintain a steady altitude     \nwithout constantly adjusting the controls.  4.      |  without constantly adjusting the controls.  4.    \n**Auto-Pilot Systems**: Many modern airplanes are   |  **Auto-Pilot Systems**: Many modern airplanes are \nequipped with auto-pilot systems that can           |  equipped with auto-pilot systems that can         \nautomatically maintain the airplane's altitude.     |  automatically maintain the airplane's altitude.   \nThese systems use sensors to monitor the            |  These systems use sensors to monitor the          \nairplane's altitude and adjust the engines and      |  airplane's altitude and adjust the engines and    \ntrim system as needed to keep the airplane at the   |  trim system as needed to keep the airplane at the \ndesired altitude.  5. **Air Data Computer (ADC)**:  |  desired altitude.  5. **Air Data Computer (ADC)**:\nThe airplane's air data computer (ADC) is a         |  The airplane's air data computer (ADC) is a       \ncomputer system that collects and processes         |  computer system that collects and processes       \nvarious data about the airplane's environment,      |  various data about the airplane's environment,    \nincluding airspeed, altitude, and temperature.      |  including airspeed, altitude, and temperature.    \nThis data is used by the auto-pilot system to       |  This data is used by the auto-pilot system to     \nmaintain the airplane's altitude.  6. **Altitude    |  maintain the airplane's altitude.  6. **Altitude  \nSensors**: The airplane is equipped with various    |  Sensors**: The airplane is equipped with various  \nsensors, such as static ports and pitot tubes,      |  sensors, such as static ports and pitot tubes,    \nwhich measure the air pressure and speed. These     |  which measure the air pressure and speed. These   \nsensors feed data to the auto-pilot system, which   |  sensors feed data to the auto-pilot system, which \nthen adjusts the airplane's altitude.  7. **Trim    |  then adjusts the airplane's altitude.  7. **Trim  \nTabs and Trim Servo Motors**: Some airplanes have   |  Tabs and Trim Servo Motors**: Some airplanes have \ntrim tabs and trim servo motors that automatically  |  trim tabs and trim servo motors that automatically\nadjust the control surfaces to maintain the         |  adjust the control surfaces to maintain the       \nairplane's altitude. These systems are              |  airplane's altitude. These systems are            \nparticularly useful in high-altitude operations     |  particularly useful in high-altitude operations   \nwhere the pilot might not have the time or the      |  where the pilot might not have the time or the    \nability to manually adjust the controls.  8.        |  ability to manually adjust the controls.  8.      \n**Manual Control**: In some cases, the pilot may    |  **Manual Control**: In some cases, the pilot may  \nmanually adjust the controls to fine-tune the       |  manually adjust the controls to fine-tune the     \nairplane's altitude. This is typically done when    |  airplane's altitude. This is typically done when  \nthe airplane is close to the desired altitude or    |  the airplane is close to the desired altitude or  \nwhen the auto-pilot system is not functioning       |  when the auto-pilot system is not functioning     \nproperly.  By combining these systems and           |  properly.  By combining these systems and         \ninstruments, airplanes can maintain their altitude  |  instruments, airplanes can maintain their altitude\nefficiently and safely, ensuring a smooth and       |  efficiently and safely, ensuring a comfortable and\ncomfortable flight experience for                   |  safe flight experience for passengers.<|im_end|>  \npassengers.<|im_end|>                               |                                                    \n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:20:17.222185Z","iopub.execute_input":"2024-11-17T06:20:17.222713Z","iopub.status.idle":"2024-11-17T06:21:47.997196Z","shell.execute_reply.started":"2024-11-17T06:20:17.222666Z","shell.execute_reply":"2024-11-17T06:21:47.996300Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user What is the   |  assistant.<|im_end|> <|im_start|>user What is the \nfunction of the three tiny bones in the middle ear  |  function of the three tiny bones in the middle ear\nand how do they contribute to the process of        |  and how do they contribute to the process of      \nhearing?<|im_end|> <|im_start|>assistant The three  |  hearing?<|im_end|> <|im_start|>assistant The three\ntiny bones in the middle ear, collectively known    |  tiny bones in the middle ear, collectively known  \nas the ossicles, are the malleus (also called the   |  as the ossicles, play a crucial role in the       \nhammer), incus (also called the anvil), and the     |  process of hearing. These bones are the malleus   \nstapes (also called the stirrup). These bones play  |  (also called the hammer), incus (also called the  \na crucial role in the process of hearing by         |  anvil), and the stapes (also called the stirrup). \namplifying and transmitting the vibrations of the   |  Together, they amplify and transmit the vibrations\neardrum (tympanic membrane) to the inner ear.       |  of the eardrum (tympanic membrane) to the inner   \nHere's how they contribute to the process of        |  ear, where the actual hearing takes place.  Here's\nhearing:  1. **Amplification and Transmission of    |  how they contribute to the process of hearing:  1.\nSound**: When sound waves enter the ear, they       |  **Amplification and Transmission of Sound**: When \ncause the eardrum to vibrate. The malleus, which    |  sound waves enter the ear, they cause the eardrum \nis attached to the eardrum, amplifies these         |  to vibrate. The malleus, which is attached to the \nvibrations and transmits them to the incus. The     |  eardrum, amplifies these vibrations and transmits \nincus then amplifies the vibrations and transmits   |  them to the incus. The incus then amplifies the   \nthem to the stapes. The stapes, which is the        |  vibrations and transmits them to the stapes. The  \nsmallest bone in the human body, is attached to     |  stapes, in turn, amplifies the vibrations and     \nthe oval window of the inner ear. As the stapes     |  transmits them to the oval window, which is the   \nvibrates, it pushes against the oval window, which  |  membrane that separates the middle ear from the   \nis the opening to the inner ear. This movement of   |  inner ear.  2. **Vibration Transmission to the    \nthe stapes into the inner ear transmits the         |  Inner Ear**: The oval window is connected to the  \nvibrations to the fluid-filled cochlea.  2.         |  inner ear through a fluid-filled structure called \n**Conversion of Mechanical Energy to Electrical     |  the cochlea. The vibrations from the stapes cause \nEnergy**: In the inner ear, the vibrations cause    |  the fluid in the cochlea to move, which in turn   \nthe fluid in the cochlea to move. These movements   |  stimulates the hair cells in the cochlea. These   \nstimulate the hair cells in the cochlea, which are  |  hair cells convert the mechanical energy of the   \nspecialized sensory cells. The hair cells convert   |  vibrations into electrical signals.  3.           \nthe mechanical energy of the vibrations into        |  **Transmission of Electrical Signals**: The       \nelectrical signals. These electrical signals are    |  electrical signals generated by the hair cells are\nthen transmitted to the auditory nerve, which       |  transmitted to the auditory nerve, which carries  \ncarries them to the brain.  In summary, the         |  these signals to the brain. The brain interprets  \nossicles play a vital role in the process of        |  these signals as sound, allowing us to hear and   \nhearing by amplifying and transmitting the          |  understand the sounds around us.  In summary, the \nvibrations of sound waves from the outer ear to     |  ossicles work together to amplify and transmit the\nthe inner ear, where they are converted into        |  vibrations of sound from the eardrum to the inner \nelectrical signals that the brain can interpret as  |  ear, where the actual process of hearing occurs.  \nsound.<|im_end|>                                    |  This process is essential for converting the      \n                                                    |  mechanical energy of sound waves into electrical  \n                                                    |  signals that the brain can interpret as           \n                                                    |  sound.<|im_end|>                                  \n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:48:02.063981Z","iopub.execute_input":"2024-11-17T06:48:02.064397Z","iopub.status.idle":"2024-11-17T06:50:22.989916Z","shell.execute_reply.started":"2024-11-17T06:48:02.064361Z","shell.execute_reply":"2024-11-17T06:50:22.988922Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user What is the   |  assistant.<|im_end|> <|im_start|>user What is the \nobservable universe, and why does its size not      |  observable universe, and why does its size not    \ncorrespond to the age of the universe multiplied    |  correspond to the age of the universe multiplied  \nby the speed of light? How does the expansion of    |  by the speed of light? How does the expansion of  \nthe universe affect our perception of its           |  the universe affect our perception of its         \nsize?<|im_end|> <|im_start|>assistant The           |  size?<|im_end|> <|im_start|>assistant The         \nobservable universe is the part of the universe     |  observable universe is the part of the universe   \nthat we can see, given the finite speed of light    |  that we can see, given the finite speed of light  \nand the finite age of the universe. It is the       |  and the finite age of the universe. It is the     \nregion of space that we can observe because the     |  region of space that we can observe because the   \nlight from distant objects has had enough time to   |  light from distant objects has had enough time to \nreach us since the beginning of the universe.       |  reach us since the beginning of the universe.     \nHowever, the size of the observable universe does   |  However, the size of the observable universe does \nnot correspond to the age of the universe           |  not correspond to the age of the universe         \nmultiplied by the speed of light because the        |  multiplied by the speed of light because the      \nuniverse is not static and is expanding.  ### Why   |  universe is not static and is expanding.  ### Why \nthe Observable Universe Size Doesn't Correspond to  |  the Observable Universe Size Doesn't Correspond to\nAge Multiplied by Speed of Light  1. **Expansion    |  Age Multiplied by Speed of Light  1. **Expansion  \nof the Universe**: The universe is not static; it   |  of the Universe**: The universe is not static; it \nis expanding. As the universe expands, the          |  is expanding. As the universe expands, the        \ndistance between galaxies increases over time.      |  distance between galaxies increases over time.    \nThis means that the light from distant objects      |  This means that the light from distant objects    \ntakes longer to reach us as the universe expands.   |  takes longer to reach us as the universe expands. \nTherefore, the observable universe is not just a    |  Therefore, the observable universe is not just a  \nsphere with a radius equal to the age of the        |  sphere with a radius equal to the age of the      \nuniverse multiplied by the speed of light.  2.      |  universe multiplied by the speed of light.  2.    \n**Cosmic Horizon**: The light from distant objects  |  **Cosmic Horizon**: The light from distant objects\ncan only travel a certain distance before the       |  can only travel a certain distance before the     \nuniverse expands beyond that distance. This         |  universe expands beyond that distance. This       \ndistance is called the cosmic horizon. The cosmic   |  distance is called the cosmic horizon. The cosmic \nhorizon is the limit of the observable universe,    |  horizon is the limit of the observable universe,  \nbeyond which we cannot see because the light has    |  beyond which we cannot see because the light has  \nnot had enough time to reach us.  ### How the       |  not had enough time to reach us.  ### How the     \nExpansion of the Universe Affects Our Perception    |  Expansion of the Universe Affects Our Perception  \nof Its Size  1. **Hubble's Law**: The expansion of  |  of Its Size  1. **Light Travel Time**: As the     \nthe universe is described by Hubble's law, which    |  universe expands, the light from distant objects  \nstates that the velocity at which a galaxy is       |  takes longer to reach us. This means that the     \nmoving away from us is proportional to its          |  observable universe is not a static sphere but    \ndistance from us. Mathematically, this can be       |  rather a dynamic region that changes over time.   \nexpressed as \\( v = H_0 d \\), where \\( v \\) is the  |  2. **Cosmic Microwave Background (CMB)**: The CMB \nrecession velocity, \\( H_0 \\) is the Hubble         |  is the afterglow of the Big Bang and is uniformly \nconstant, and \\( d \\) is the distance to the        |  distributed across the sky. This radiation        \ngalaxy.  2. **Cosmic Microwave Background (CMB)**:  |  provides a snapshot of the universe at a very     \nThe CMB is the afterglow of the Big Bang and        |  early time, allowing us to understand the         \nprovides a snapshot of the universe when it was     |  expansion history of the universe.  3. **Hubble's \nabout 380,000 years old. The CMB radiation fills    |  Law**: The expansion of the universe is described \nthe entire observable universe, and its             |  by Hubble's Law, which states that the velocity at\ntemperature is uniform in all directions. This      |  which a galaxy is moving away from us is          \nradiation is a key piece of evidence for the Big    |  proportional to its distance from us. This        \nBang theory and helps us understand the early       |  relationship helps us understand the rate at which\nuniverse.  3. **Cosmic Microwave Background         |  the universe is expanding and how it affects the  \nRadiation (CMBR)**: The CMBR is a remnant of the    |  observable universe.  ### Summary  The observable \nearly universe, and its uniformity and temperature  |  universe is the part of the universe that we can  \nprovide insights into the expansion history of the  |  see because the light from distant objects has had\nuniverse. The CMBR is observed to be isotropic      |  enough time to reach us. The expansion of the     \n(uniform in all directions) and has a specific      |  universe means that the observable universe is not\ntemperature, which helps us understand the          |  just a sphere with a radius equal to the age of   \nexpansion rate and the age of the universe.  ###    |  the universe multiplied by the speed of light.    \nConclusion  The observable universe is not just a   |  Instead, it is a dynamic region that changes over \nsphere with a radius equal to the age of the        |  time, and its size is determined by the light     \nuniverse multiplied by the speed of light.          |  travel time and the cosmic horizon. The expansion \nInstead, it is the region of space that we can      |  of the universe affects our perception of its size\nobserve because the light from distant objects has  |  by making it a dynamic and changing region, rather\nhad enough time to reach us. The expansion of the   |  than a static one.<|im_end|>                      \nuniverse means that the distance between galaxies   |                                                    \nincreases over time, and the cosmic horizon limits  |                                                    \nthe observable universe. Understanding the          |                                                    \nexpansion of the universe and the cosmic microwave  |                                                    \nbackground radiation helps us understand the size   |                                                    \nand age of the observable universe.<|im_end|>       |                                                    \n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:22:53.769919Z","iopub.execute_input":"2024-11-17T06:22:53.770241Z","iopub.status.idle":"2024-11-17T06:26:09.522790Z","shell.execute_reply.started":"2024-11-17T06:22:53.770207Z","shell.execute_reply":"2024-11-17T06:26:09.521769Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user What were     |  assistant.<|im_end|> <|im_start|>user What were   \nthe social and economic impacts of the Industrial   |  the social and economic impacts of the Industrial \nRevolution in 19th century England?<|im_end|>       |  Revolution in 19th century England?<|im_end|>     \n<|im_start|>assistant The Industrial Revolution in  |  <|im_start|>assistant The Industrial Revolution in\n19th century England had profound social and        |  19th century England had profound social and      \neconomic impacts that reshaped the landscape of     |  economic impacts that reshaped the landscape of   \nEngland and had far-reaching effects on the world.  |  England and had far-reaching effects on the world.\nHere are some of the key impacts:  ### Economic     |  Here are some of the key impacts:  ### Economic   \nImpacts  1. **Economic Growth and                   |  Impacts  1. **Economic Growth and                 \nIndustrialization:**    - **Economic Growth:** The  |  Industrialization:**    - **Economic Growth:** The\nIndustrial Revolution led to significant economic   |  Industrial Revolution led to significant economic \ngrowth. New technologies and innovations, such as   |  growth. New technologies and innovations, such as \nthe steam engine, mechanized textile production,    |  the steam engine, mechanized textile production,  \nand the factory system, increased productivity and  |  and the factory system, increased productivity and\noutput.    - **Industrialization:** The shift from  |  output.    - **Industrialization:** The shift from\nagrarian to industrial economies led to the growth  |  agrarian to industrial economies led to the growth\nof new industries, including textiles, iron, coal,  |  of new industries, including textiles, iron, coal,\nand machinery. This industrialization transformed   |  and machinery. This industrialization transformed \nthe economy, creating new wealth and opportunities  |  the economy, creating new wealth and opportunities\nfor some.    - **Urbanization:** As industries      |  for some.    - **Urbanization:** As industries    \ngrew, people moved from rural areas to cities in    |  grew, people moved from rural areas to cities in  \nsearch of work, leading to rapid urbanization.      |  search of work, leading to rapid urbanization.    \nThis shift led to the growth of cities and the      |  This shift led to the growth of cities and the    \ndevelopment of urban infrastructure.  2.            |  development of urban infrastructure.  2.          \n**Economic Disparities:**    - **Income             |  **Economic Disparities:**    - **Income           \nInequality:** The Industrial Revolution             |  Inequality:** The Industrial Revolution           \nexacerbated income inequality. While some           |  exacerbated income inequality. While some         \nindividuals became extremely wealthy, the majority  |  individuals became very wealthy, the majority of  \nof workers, especially those in the textile         |  workers, especially those in the textile industry,\nindustry, faced harsh working conditions and low    |  faced harsh working conditions and low wages.    -\nwages.    - **Exploitation:** Workers,              |  **Exploitation:** Workers, particularly women and \nparticularly women and children, were often         |  children, were often subjected to long hours, low \nsubjected to long hours, low pay, and dangerous     |  pay, and dangerous working conditions. Child labor\nworking conditions. Child labor was common, with    |  was common, with children as young as five years  \nchildren as young as five years old working in      |  old working in factories.  3. **Economic          \nfactories.  3. **Economic Innovations:**    -       |  Innovations:**    - **New Technologies:** The     \n**New Technologies:** The Industrial Revolution     |  Industrial Revolution introduced new technologies \nintroduced new technologies that transformed        |  that transformed various industries. Innovations  \nvarious industries. Innovations like the steam      |  like the steam engine, spinning jenny, power loom,\nengine, spinning jenny, power loom, and mechanized  |  and mechanized factories were key in driving      \nfactories were key in driving economic growth.      |  economic growth.    - **Transportation:**         \n- **Transportation:** Improvements in               |  Improvements in transportation, such as the       \ntransportation, such as the development of          |  development of railways, facilitated the movement \nrailways, facilitated the movement of goods and     |  of goods and people, further boosting economic    \npeople, further boosting economic activity.  ###    |  activity.  ### Social Impacts  1. **Social        \nSocial Impacts  1. **Social Changes:**    -         |  Changes:**    - **Urbanization:** The rapid growth\n**Urbanization:** The rapid growth of cities led    |  of cities led to significant social changes.      \nto significant social changes. Urbanization         |  Cities became centers of industry and commerce,   \nbrought about the growth of slums and overcrowded   |  but they also faced challenges such as            \nliving conditions, which led to public health       |  overcrowding, poor sanitation, and public health  \nissues and social problems.    - **Family           |  issues.    - **Social Stratification:** The       \nStructure:** The Industrial Revolution disrupted    |  Industrial Revolution led to a more rigid social  \ntraditional family structures. With men working in  |  stratification. The wealthy industrialists and    \nfactories and women often working as domestic       |  landowners became the new aristocracy, while the  \nservants, family life became more fragmented.    -  |  working class faced harsh conditions and limited  \n**Social Mobility:** While some individuals became  |  opportunities.    - **Family Structure:** The     \nwealthy, others remained in poverty. This led to    |  shift to industrial work often led to the         \ndebates about social mobility and the fairness of   |  breakdown of traditional family structures. Women \nthe economic system.  2. **Labor Conditions:**      |  and children were often employed in factories, and\n- **Working Conditions:** Workers faced harsh       |  families were often separated.  2. **Labor        \nworking conditions, including long hours, low       |  Conditions:**    - **Working Conditions:** Workers\nwages, and dangerous working environments. Child    |  faced long hours, low wages, and harsh working    \nlabor was common, with children as young as five    |  conditions. Child labor was common, with children \nyears old working in factories.    - **Health and   |  as young as five years old working in factories.  \nSafety:** Poor working conditions led to high       |  These conditions often led to health problems and \nrates of illness and accidents. Workers often       |  early deaths.    - **Child Labor:** Children were \nsuffered from respiratory diseases, accidents, and  |  often employed in factories, mines, and other     \nother health issues due to the harsh conditions.    |  industries. They worked long hours in dangerous   \n3. **Social Unrest:**    - **Labor Unrest:** The    |  conditions, often without adequate safety measures\nharsh conditions and low wages led to labor unrest  |  or protection.    - **Women's Role:** Women were  \nand strikes. Workers demanded better working        |  often employed in domestic service, textile mills,\nconditions, higher wages, and shorter working       |  and other industries. They faced similar working  \nhours.    - **Social Reform:** The social and       |  conditions and were often paid less than men.  3. \neconomic impacts of the Industrial Revolution led   |  **Public Health and Welfare:**    - **Public      \nto increased calls for social reform. This led to   |  Health Issues:** The rapid growth of cities led to\nthe development of labor laws and the               |  public health issues, including poor sanitation,  \nestablishment of workers' rights.  ### Conclusion   |  disease, and overcrowding. Diseases such as       \nThe Industrial Revolution in 19th century England   |  cholera and tuberculosis were common.    -        \nwas a period of immense economic and social         |  **Public Welfare:** The government and            \nchange. While it brought about significant          |  philanthropists began to address some of these    \neconomic growth and industrialization, it also led  |  issues, leading to the development of public      \nto widespread social and economic disparities. The  |  health initiatives and welfare programs. However, \nimpacts of the Industrial Revolution continue to    |  these efforts were often slow and inadequate.  4. \ninfluence modern society, highlighting the complex  |  **Education and Social Mobility:**    -           \nand often contentious nature of                     |  **Education:** The Industrial Revolution led to a \nindustrialization.<|im_end|>                        |  growing demand for a more educated workforce. This\n                                                    |  led to the development of public education        \n                                                    |  systems, which helped to improve literacy rates   \n                                                    |  and provided opportunities for social mobility.   \n                                                    |  - **Social Mobility:** While the Industrial       \n                                                    |  Revolution created new opportunities for some, it \n                                                    |  also perpetuated social stratification. The       \n                                                    |  wealthy industrialists and landowners remained at \n                                                    |  the top, while the working class faced limited    \n                                                    |  opportunities for advancement.  In summary, the   \n                                                    |  Industrial Revolution in 19th century England had \n                                                    |  far-reaching social and economic impacts,         \n                                                    |  transforming the economy and society in           \n                                                    |  significant ways. While it led to economic growth \n                                                    |  and industrialization, it also created significant\n                                                    |  social and economic disparities and               \n                                                    |  challenges.<|im_end|>                             \n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T06:54:36.157955Z","iopub.execute_input":"2024-11-17T06:54:36.158871Z","iopub.status.idle":"2024-11-17T06:56:16.123986Z","shell.execute_reply.started":"2024-11-17T06:54:36.158824Z","shell.execute_reply":"2024-11-17T06:56:16.122993Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user How can I     |  assistant.<|im_end|> <|im_start|>user How can I   \ncalculate the hypotenuse of a right-angled          |  calculate the hypotenuse of a right-angled        \ntriangle using Python?<|im_end|>                    |  triangle using Python?<|im_end|>                  \n<|im_start|>assistant To calculate the hypotenuse   |  <|im_start|>assistant To calculate the hypotenuse \nof a right-angled triangle in Python, you can use   |  of a right-angled triangle in Python, you can use \nthe Pythagorean theorem. The theorem states that    |  the Pythagorean theorem. The theorem states that  \nin a right-angled triangle, the square of the       |  in a right-angled triangle, the square of the     \nhypotenuse (the side opposite the right angle) is   |  hypotenuse (the side opposite the right angle) is \nequal to the sum of the squares of the other two    |  equal to the sum of the squares of the other two  \nsides. The formula is:  \\[ c = \\sqrt{a^2 + b^ml^2}  |  sides. The formula is:  \\[ c = \\sqrt{a^2 + b^ml^2}\n\\]  Where: - \\( c \\) is the length of the           |  \\]  Where: - \\( c \\) is the length of the         \nhypotenuse, - \\( a \\) and \\( b \\) are the lengths   |  hypotenuse, - \\( a \\) and \\( b \\) are the lengths \nof the other two sides (the legs of the triangle).  |  of the other two sides (the legs of the triangle).\nHere's how you can implement this in Python:        |  Here's how you can implement this in Python:      \n```python import math  def calculate_hypotenuse(a,  |  ```python import math  def calculate_hypotenuse(a,\nb):     \"\"\"     Calculate the hypotenuse of a       |  b):     \"\"\"     Calculate the hypotenuse of a     \nright-angled triangle.      Parameters:     a       |  right-angled triangle.      Parameters:     a     \n(float): The length of one of the legs of the       |  (float): The length of one of the legs of the     \ntriangle.     b (float): The length of the other    |  triangle.     b (float): The length of the other  \nleg of the triangle.      Returns:     float: The   |  leg of the triangle.      Returns:     float: The \nlength of the hypotenuse.     \"\"\"     return        |  length of the hypotenuse.     \"\"\"     return      \nmath.sqrt(a**2 + b**2)  # Example usage a = 3.0 b   |  math.sqrt(a**2 + b**2)  # Example usage side_a =  \n= 4.0 hypotenuse = calculate_hypotenuse(a, b)       |  3.0 side_b = 4.0 hypotenuse =                     \nprint(f\"The hypotenuse is: {hypotenuse}\") ```  In   |  calculate_hypotenuse(side_a, side_b) print(f\"The  \nthis code: - We import the `math` module to use     |  hypotenuse is: {hypotenuse}\") ```  In this code: -\nthe `sqrt` function for calculating the square      |  We import the `math` module to use the `sqrt`     \nroot. - We define a function                        |  function for calculating the square root. - We    \n`calculate_hypotenuse` that takes two arguments,    |  define a function `calculate_hypotenuse` that     \n`a` and `b`, which are the lengths of the two legs  |  takes two arguments, `a` and `b`, which are the   \nof the triangle. - Inside the function, we use the  |  lengths of the two legs of the triangle. - Inside \nPythagorean theorem to calculate the hypotenuse. -  |  the function, we use the Pythagorean theorem to   \nWe then call this function with example values for  |  calculate the hypotenuse. - We then call this     \n`a` and `b`, and print the result.  You can         |  function with example values for `side_a` and     \nreplace `a` and `b` with any values you want to     |  `side_b`, and print the result.  You can replace  \ncalculate the hypotenuse for.<|im_end|>             |  `side_a` and `side_b` with any values you want to \n                                                    |  calculate the hypotenuse for.<|im_end|>           \n","output_type":"stream"}],"execution_count":67}]}