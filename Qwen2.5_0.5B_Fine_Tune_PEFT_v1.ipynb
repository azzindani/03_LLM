{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-17T12:34:49.736345Z","iopub.execute_input":"2024-11-17T12:34:49.736742Z","iopub.status.idle":"2024-11-17T12:35:35.976550Z","shell.execute_reply.started":"2024-11-17T12:34:49.736703Z","shell.execute_reply":"2024-11-17T12:35:35.975274Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-11-17T12:35:35.979218Z","iopub.execute_input":"2024-11-17T12:35:35.979981Z","iopub.status.idle":"2024-11-17T12:35:44.125953Z","shell.execute_reply.started":"2024-11-17T12:35:35.979931Z","shell.execute_reply":"2024-11-17T12:35:44.124943Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-11-17T12:35:44.128396Z","iopub.execute_input":"2024-11-17T12:35:44.129123Z","iopub.status.idle":"2024-11-17T12:35:44.135922Z","shell.execute_reply.started":"2024-11-17T12:35:44.129085Z","shell.execute_reply":"2024-11-17T12:35:44.134975Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'Qwen/Qwen2.5-0.5B'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-17T12:35:44.137180Z","iopub.execute_input":"2024-11-17T12:35:44.137644Z","iopub.status.idle":"2024-11-17T12:35:44.144559Z","shell.execute_reply.started":"2024-11-17T12:35:44.137601Z","shell.execute_reply":"2024-11-17T12:35:44.143503Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-11-17T12:35:44.147180Z","iopub.execute_input":"2024-11-17T12:35:44.147503Z","iopub.status.idle":"2024-11-17T12:35:44.154367Z","shell.execute_reply.started":"2024-11-17T12:35:44.147472Z","shell.execute_reply":"2024-11-17T12:35:44.153334Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:44.155458Z","iopub.execute_input":"2024-11-17T12:35:44.155777Z","iopub.status.idle":"2024-11-17T12:35:46.613617Z","shell.execute_reply.started":"2024-11-17T12:35:44.155741Z","shell.execute_reply":"2024-11-17T12:35:46.612684Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 896)\n    (layers): ModuleList(\n      (0-23): 24 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=896, out_features=896, bias=True)\n          (k_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n          (v_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n          (o_proj): Linear4bit(in_features=896, out_features=896, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n          (up_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n          (down_proj): Linear4bit(in_features=4864, out_features=896, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:46.614685Z","iopub.execute_input":"2024-11-17T12:35:46.614956Z","iopub.status.idle":"2024-11-17T12:35:46.624247Z","shell.execute_reply.started":"2024-11-17T12:35:46.614927Z","shell.execute_reply":"2024-11-17T12:35:46.623314Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 315119488\nTrainable parameters : 136178560\nTrainable percentage: 43.21%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:46.625442Z","iopub.execute_input":"2024-11-17T12:35:46.625933Z","iopub.status.idle":"2024-11-17T12:35:47.075419Z","shell.execute_reply.started":"2024-11-17T12:35:46.625889Z","shell.execute_reply":"2024-11-17T12:35:47.074398Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'mlabonne/FineTome-100k'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:47.076688Z","iopub.execute_input":"2024-11-17T12:35:47.076978Z","iopub.status.idle":"2024-11-17T12:35:47.081337Z","shell.execute_reply.started":"2024-11-17T12:35:47.076947Z","shell.execute_reply":"2024-11-17T12:35:47.080393Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 1024","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:47.082586Z","iopub.execute_input":"2024-11-17T12:35:47.082878Z","iopub.status.idle":"2024-11-17T12:35:47.090193Z","shell.execute_reply.started":"2024-11-17T12:35:47.082848Z","shell.execute_reply":"2024-11-17T12:35:47.089406Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:47.091140Z","iopub.execute_input":"2024-11-17T12:35:47.091479Z","iopub.status.idle":"2024-11-17T12:35:49.075519Z","shell.execute_reply.started":"2024-11-17T12:35:47.091448Z","shell.execute_reply":"2024-11-17T12:35:49.074658Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations', 'source', 'score'],\n    num_rows: 100000\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.076590Z","iopub.execute_input":"2024-11-17T12:35:49.076872Z","iopub.status.idle":"2024-11-17T12:35:49.084202Z","shell.execute_reply.started":"2024-11-17T12:35:49.076840Z","shell.execute_reply":"2024-11-17T12:35:49.083507Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.087384Z","iopub.execute_input":"2024-11-17T12:35:49.087695Z","iopub.status.idle":"2024-11-17T12:35:49.114027Z","shell.execute_reply.started":"2024-11-17T12:35:49.087664Z","shell.execute_reply":"2024-11-17T12:35:49.113147Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                       conversations  \\\n0  [{'from': 'human', 'value': 'Explain what bool...   \n1  [{'from': 'human', 'value': 'Explain how recur...   \n2  [{'from': 'human', 'value': 'Explain what bool...   \n3  [{'from': 'human', 'value': 'Explain the conce...   \n4  [{'from': 'human', 'value': 'Print the reverse...   \n\n                     source     score  \n0  infini-instruct-top-500k  5.212621  \n1  infini-instruct-top-500k  5.157649  \n2  infini-instruct-top-500k  5.147540  \n3  infini-instruct-top-500k  5.053656  \n4  infini-instruct-top-500k  5.045648  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>conversations</th>\n      <th>source</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.212621</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[{'from': 'human', 'value': 'Explain how recur...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.157649</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[{'from': 'human', 'value': 'Explain what bool...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.147540</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[{'from': 'human', 'value': 'Explain the conce...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.053656</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[{'from': 'human', 'value': 'Print the reverse...</td>\n      <td>infini-instruct-top-500k</td>\n      <td>5.045648</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.119111Z","iopub.execute_input":"2024-11-17T12:35:49.119397Z","iopub.status.idle":"2024-11-17T12:35:49.125577Z","shell.execute_reply.started":"2024-11-17T12:35:49.119355Z","shell.execute_reply":"2024-11-17T12:35:49.124631Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'from': 'human',\n   'value': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.'},\n  {'from': 'gpt',\n   'value': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.'}],\n 'source': 'infini-instruct-top-500k',\n 'score': 5.212620735168457}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.126952Z","iopub.execute_input":"2024-11-17T12:35:49.127409Z","iopub.status.idle":"2024-11-17T12:35:49.134876Z","shell.execute_reply.started":"2024-11-17T12:35:49.127346Z","shell.execute_reply":"2024-11-17T12:35:49.134060Z"}},"outputs":[{"name":"stdout","text":"['conversations', 'source', 'score']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"def transform_conversations(example):\n  role_map = {\n    'human' : 'user',\n    'gpt' : 'assistant'\n  }\n\n  transformed_conversations = [\n    {\n      'role' : role_map.get(turn['from'], turn['from']),\n      'content' : turn['value']\n    }\n    for turn in example['conversations']\n  ]\n  return {'conversations': transformed_conversations}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.135901Z","iopub.execute_input":"2024-11-17T12:35:49.136186Z","iopub.status.idle":"2024-11-17T12:35:49.144413Z","shell.execute_reply.started":"2024-11-17T12:35:49.136156Z","shell.execute_reply":"2024-11-17T12:35:49.143618Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"formatted_dataset = dataset.map(transform_conversations, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.145365Z","iopub.execute_input":"2024-11-17T12:35:49.145670Z","iopub.status.idle":"2024-11-17T12:35:49.158901Z","shell.execute_reply.started":"2024-11-17T12:35:49.145640Z","shell.execute_reply":"2024-11-17T12:35:49.158034Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"print(formatted_dataset[0]['conversations'])","metadata":{"id":"cZya4tPEWUc9","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.160020Z","iopub.execute_input":"2024-11-17T12:35:49.160296Z","iopub.status.idle":"2024-11-17T12:35:49.165186Z","shell.execute_reply.started":"2024-11-17T12:35:49.160266Z","shell.execute_reply":"2024-11-17T12:35:49.164322Z"}},"outputs":[{"name":"stdout","text":"[{'content': 'Explain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \\n\\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\\n\\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.', 'role': 'user'}, {'content': 'Boolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\\n\\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\\n\\n```python\\nx = 5\\ny = 10\\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\\n```\\n\\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\\n\\n```python\\nx = 5\\nresult = not (x > 10)  # This expression evaluates to True\\n```\\n\\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\\n\\n```python\\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\\n```\\n\\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\\n\\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\\n\\n```python\\nif x != 0 and (y / x) > 10:\\n    # Perform some operation\\n```\\n\\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here\\'s an example in pseudocode:\\n\\n```\\nif x != 0 {\\n    if (y / x) > 10 {\\n        // Perform some operation\\n    }\\n}\\n```\\n\\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\\n\\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\\n\\n```python\\nx = 5\\nresult = x  # The value of x is truthy, so result is also truthy\\n```\\n\\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\\n\\n```python\\nx = 5\\nresult = bool(x)  # Explicitly converting x to a boolean value\\n```\\n\\nThis ensures that the result is always a boolean value, regardless of the language\\'s truthiness and falsiness rules.', 'role': 'assistant'}]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def format_conversation(example):\n  for entry in example['conversations']:\n    role = entry['role']\n    content = entry['content']\n\n    if role == 'user':\n      formatted_text = f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n    elif role == 'assistant':\n      formatted_text += f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}\\n<|eot_id|>\"\n\n  return {'prompt': formatted_text}","metadata":{"id":"3bmXGueQWWzt","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.166283Z","iopub.execute_input":"2024-11-17T12:35:49.166613Z","iopub.status.idle":"2024-11-17T12:35:49.174780Z","shell.execute_reply.started":"2024-11-17T12:35:49.166571Z","shell.execute_reply":"2024-11-17T12:35:49.173933Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"formatted_dataset = formatted_dataset.map(\n  format_conversation,\n  remove_columns = list(formatted_dataset.features.keys())\n)\nformatted_dataset","metadata":{"id":"Z6sSaCr5eaL7","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.175783Z","iopub.execute_input":"2024-11-17T12:35:49.176092Z","iopub.status.idle":"2024-11-17T12:35:49.187664Z","shell.execute_reply.started":"2024-11-17T12:35:49.176061Z","shell.execute_reply":"2024-11-17T12:35:49.186772Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.188954Z","iopub.execute_input":"2024-11-17T12:35:49.189689Z","iopub.status.idle":"2024-11-17T12:35:49.194509Z","shell.execute_reply.started":"2024-11-17T12:35:49.189656Z","shell.execute_reply":"2024-11-17T12:35:49.193573Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.195730Z","iopub.execute_input":"2024-11-17T12:35:49.196164Z","iopub.status.idle":"2024-11-17T12:35:49.203307Z","shell.execute_reply.started":"2024-11-17T12:35:49.196122Z","shell.execute_reply":"2024-11-17T12:35:49.202520Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.204307Z","iopub.execute_input":"2024-11-17T12:35:49.204632Z","iopub.status.idle":"2024-11-17T12:35:49.335011Z","shell.execute_reply.started":"2024-11-17T12:35:49.204600Z","shell.execute_reply":"2024-11-17T12:35:49.334082Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.336297Z","iopub.execute_input":"2024-11-17T12:35:49.337095Z","iopub.status.idle":"2024-11-17T12:35:49.343202Z","shell.execute_reply.started":"2024-11-17T12:35:49.337060Z","shell.execute_reply":"2024-11-17T12:35:49.342273Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nExplain what boolean operators are, what they do, and provide examples of how they can be used in programming. Additionally, describe the concept of operator precedence and provide examples of how it affects the evaluation of boolean expressions. Discuss the difference between short-circuit evaluation and normal evaluation in boolean expressions and demonstrate their usage in code. \n\nFurthermore, add the requirement that the code must be written in a language that does not support short-circuit evaluation natively, forcing the test taker to implement their own logic for short-circuit evaluation.\n\nFinally, delve into the concept of truthiness and falsiness in programming languages, explaining how it affects the evaluation of boolean expressions. Add the constraint that the test taker must write code that handles cases where truthiness and falsiness are implemented differently across different programming languages.\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nBoolean operators are logical operators used in programming to manipulate boolean values. They operate on one or more boolean operands and return a boolean result. The three main boolean operators are \"AND\" (&&), \"OR\" (||), and \"NOT\" (!).\n\nThe \"AND\" operator returns true if both of its operands are true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) and (y < 20)  # This expression evaluates to True\n```\n\nThe \"OR\" operator returns true if at least one of its operands is true, and false otherwise. For example:\n\n```python\nx = 5\ny = 10\nresult = (x > 0) or (y < 20)  # This expression evaluates to True\n```\n\nThe \"NOT\" operator negates the boolean value of its operand. It returns true if the operand is false, and false if the operand is true. For example:\n\n```python\nx = 5\nresult = not (x > 10)  # This expression evaluates to True\n```\n\nOperator precedence refers to the order in which operators are evaluated in an expression. It ensures that expressions are evaluated correctly. In most programming languages, logical AND has higher precedence than logical OR. For example:\n\n```python\nresult = True or False and False  # This expression is evaluated as (True or (False and False)), which is True\n```\n\nShort-circuit evaluation is a behavior where the second operand of a logical operator is not evaluated if the result can be determined based on the value of the first operand. In short-circuit evaluation, if the first operand of an \"AND\" operator is false, the second operand is not evaluated because the result will always be false. Similarly, if the first operand of an \"OR\" operator is true, the second operand is not evaluated because the result will always be true.\n\nIn programming languages that support short-circuit evaluation natively, you can use it to improve performance or avoid errors. For example:\n\n```python\nif x != 0 and (y / x) > 10:\n    # Perform some operation\n```\n\nIn languages without native short-circuit evaluation, you can implement your own logic to achieve the same behavior. Here's an example in pseudocode:\n\n```\nif x != 0 {\n    if (y / x) > 10 {\n        // Perform some operation\n    }\n}\n```\n\nTruthiness and falsiness refer to how non-boolean values are evaluated in boolean contexts. In many programming languages, non-zero numbers and non-empty strings are considered truthy, while zero, empty strings, and null/None values are considered falsy.\n\nWhen evaluating boolean expressions, truthiness and falsiness come into play. For example:\n\n```python\nx = 5\nresult = x  # The value of x is truthy, so result is also truthy\n```\n\nTo handle cases where truthiness and falsiness are implemented differently across programming languages, you can explicitly check the desired condition. For example:\n\n```python\nx = 5\nresult = bool(x)  # Explicitly converting x to a boolean value\n```\n\nThis ensures that the result is always a boolean value, regardless of the language's truthiness and falsiness rules.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.345132Z","iopub.execute_input":"2024-11-17T12:35:49.345605Z","iopub.status.idle":"2024-11-17T12:35:49.358064Z","shell.execute_reply.started":"2024-11-17T12:35:49.345562Z","shell.execute_reply":"2024-11-17T12:35:49.357330Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.359235Z","iopub.execute_input":"2024-11-17T12:35:49.359599Z","iopub.status.idle":"2024-11-17T12:35:49.365745Z","shell.execute_reply.started":"2024-11-17T12:35:49.359558Z","shell.execute_reply":"2024-11-17T12:35:49.364841Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.366961Z","iopub.execute_input":"2024-11-17T12:35:49.367309Z","iopub.status.idle":"2024-11-17T12:35:49.393587Z","shell.execute_reply.started":"2024-11-17T12:35:49.367268Z","shell.execute_reply":"2024-11-17T12:35:49.392760Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n1  <|start_header_id|>user<|end_header_id|>\\n\\nWr...   \n2  <|start_header_id|>user<|end_header_id|>\\n\\nWh...   \n3  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n4  <|start_header_id|>user<|end_header_id|>\\n\\nHo...   \n\n                                           input_ids  \\\n0  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n1  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n2  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n3  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n4  [27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWr...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nWh...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHo...</td>\n      <td>[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.396045Z","iopub.execute_input":"2024-11-17T12:35:49.396533Z","iopub.status.idle":"2024-11-17T12:35:49.402138Z","shell.execute_reply.started":"2024-11-17T12:35:49.396501Z","shell.execute_reply":"2024-11-17T12:35:49.401189Z"}},"outputs":[{"name":"stdout","text":"<|start_header_id|>user<|end_header_id|>\n\nHow do you graph the inequality #x > -4#?\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\nTo graph the inequality #x > -4#, follow these steps:\n\n1. Start by plotting the boundary line: Draw a vertical line at #x = -4# on the X-axis. This line divides the X-axis into two halves.\n\n2. Identify the direction of the inequality: Since the inequality is #x > -4#, it indicates that we are looking for all values of #x# that are greater than -4.\n\n3. Shade the appropriate region: Shade the entire region to the right of the line at #x = -4#. This shaded area represents all the points whose X-coordinate is greater than -4.\n\n4. Include a dashed line: Since the inequality is \"greater than\" (#>,# not \"#≥#\"), draw the line at #x = -4# as a dashed line, indicating that the points on the line itself are not included in the solution.\n\nThe graph consists of the entire half-plane to the right of the dashed vertical line at #x = -4#, excluding the line itself.\n<|eot_id|>\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.403236Z","iopub.execute_input":"2024-11-17T12:35:49.403533Z","iopub.status.idle":"2024-11-17T12:35:49.412646Z","shell.execute_reply.started":"2024-11-17T12:35:49.403502Z","shell.execute_reply":"2024-11-17T12:35:49.411784Z"}},"outputs":[{"name":"stdout","text":"[27, 91, 2468, 8757, 842, 91, 29, 872, 27, 91, 408, 8757, 842, 91, 1339, 4340, 653, 498, 4771, 279, 31205, 671, 87, 861, 481, 19, 2, 5267, 27, 91, 68, 354, 842, 91, 1784, 91, 2468, 8757, 842, 91, 29, 77091, 27, 91, 408, 8757, 842, 91, 1339, 1249, 4771, 279, 31205, 671, 87, 861, 481, 19, 60778, 1795, 1493, 7354, 1447, 16, 13, 5145, 553, 43902, 279, 18732, 1555, 25, 11992, 264, 12140, 1555, 518, 671, 87, 284, 481, 19, 2, 389, 279, 1599, 35321, 13, 1096, 1555, 64828, 279, 1599, 35321, 1119, 1378, 74112, 382, 17, 13, 64547, 279, 5106, 315, 279, 31205, 25, 8704, 279, 31205, 374, 671, 87, 861, 481, 19, 60778, 432, 14807, 429, 582, 525, 3330, 369, 678, 2750, 315, 671, 87, 2, 429, 525, 7046, 1091, 481, 19, 382, 18, 13, 79818, 279, 8311, 5537, 25, 79818, 279, 4453, 5537, 311, 279, 1290, 315, 279, 1555, 518, 671, 87, 284, 481, 19, 87846, 1096, 91766, 3082, 10868, 678, 279, 3501, 6693, 1599, 80697, 374, 7046, 1091, 481, 19, 382, 19, 13, 29734, 264, 66722, 1555, 25, 8704, 279, 31205, 374, 330, 65235, 1091, 1, 29083, 8066, 2, 537, 5869, 144481, 2, 3975, 4038, 279, 1555, 518, 671, 87, 284, 481, 19, 2, 438, 264, 66722, 1555, 11, 18860, 429, 279, 3501, 389, 279, 1555, 5086, 525, 537, 5230, 304, 279, 6291, 382, 785, 4771, 17167, 315, 279, 4453, 4279, 89549, 311, 279, 1290, 315, 279, 66722, 12140, 1555, 518, 671, 87, 284, 481, 19, 60778, 43778, 279, 1555, 5086, 624, 27, 91, 68, 354, 842, 91, 29, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.413620Z","iopub.execute_input":"2024-11-17T12:35:49.413899Z","iopub.status.idle":"2024-11-17T12:35:49.422450Z","shell.execute_reply.started":"2024-11-17T12:35:49.413868Z","shell.execute_reply":"2024-11-17T12:35:49.421575Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.423492Z","iopub.execute_input":"2024-11-17T12:35:49.423824Z","iopub.status.idle":"2024-11-17T12:35:49.430119Z","shell.execute_reply.started":"2024-11-17T12:35:49.423791Z","shell.execute_reply":"2024-11-17T12:35:49.429342Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.431168Z","iopub.execute_input":"2024-11-17T12:35:49.431469Z","iopub.status.idle":"2024-11-17T12:35:49.440163Z","shell.execute_reply.started":"2024-11-17T12:35:49.431437Z","shell.execute_reply":"2024-11-17T12:35:49.439313Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.441421Z","iopub.execute_input":"2024-11-17T12:35:49.442047Z","iopub.status.idle":"2024-11-17T12:35:49.448639Z","shell.execute_reply.started":"2024-11-17T12:35:49.442003Z","shell.execute_reply":"2024-11-17T12:35:49.447773Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.449737Z","iopub.execute_input":"2024-11-17T12:35:49.450008Z","iopub.status.idle":"2024-11-17T12:35:49.458339Z","shell.execute_reply.started":"2024-11-17T12:35:49.449979Z","shell.execute_reply":"2024-11-17T12:35:49.457532Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:49.459458Z","iopub.execute_input":"2024-11-17T12:35:49.459733Z","iopub.status.idle":"2024-11-17T12:35:50.142337Z","shell.execute_reply.started":"2024-11-17T12:35:49.459703Z","shell.execute_reply":"2024-11-17T12:35:50.141276Z"}},"outputs":[{"name":"stdout","text":"trainable params: 35,192,832 || all params: 529,225,600 || trainable%: 6.6499\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:50.143645Z","iopub.execute_input":"2024-11-17T12:35:50.143972Z","iopub.status.idle":"2024-11-17T12:35:50.164749Z","shell.execute_reply.started":"2024-11-17T12:35:50.143937Z","shell.execute_reply":"2024-11-17T12:35:50.163735Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 896)\n    (layers): ModuleList(\n      (0-23): 24 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=896, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=896, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=128, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=128, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=896, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=896, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=4864, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=896, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=4864, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=4864, out_features=896, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=4864, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=896, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:50.166006Z","iopub.execute_input":"2024-11-17T12:35:50.166647Z","iopub.status.idle":"2024-11-17T12:35:50.186527Z","shell.execute_reply.started":"2024-11-17T12:35:50.166601Z","shell.execute_reply":"2024-11-17T12:35:50.185585Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 350312320\nTrainable parameters : 35192832\nTrainable percentage: 10.05%\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:50.187676Z","iopub.execute_input":"2024-11-17T12:35:50.188010Z","iopub.status.idle":"2024-11-17T12:35:50.197999Z","shell.execute_reply.started":"2024-11-17T12:35:50.187979Z","shell.execute_reply":"2024-11-17T12:35:50.197145Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 2\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:50.199048Z","iopub.execute_input":"2024-11-17T12:35:50.199338Z","iopub.status.idle":"2024-11-17T12:35:50.236291Z","shell.execute_reply.started":"2024-11-17T12:35:50.199307Z","shell.execute_reply":"2024-11-17T12:35:50.235435Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov17_12-35-50_67d8a4a618e1,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:50.237543Z","iopub.execute_input":"2024-11-17T12:35:50.237972Z","iopub.status.idle":"2024-11-17T12:35:51.455856Z","shell.execute_reply.started":"2024-11-17T12:35:50.237926Z","shell.execute_reply":"2024-11-17T12:35:51.454963Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7e6efc1cbe50>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T12:35:51.463087Z","iopub.execute_input":"2024-11-17T12:35:51.463395Z","iopub.status.idle":"2024-11-17T13:00:17.585627Z","shell.execute_reply.started":"2024-11-17T12:35:51.463351Z","shell.execute_reply":"2024-11-17T13:00:17.584816Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 2\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 35,192,832\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112719822206903, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fcef0e9f6e74e53a724977b9504b3be"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241117_123553-u3mwv7y8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/u3mwv7y8' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/u3mwv7y8' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/u3mwv7y8</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 24:15, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>1.286000</td>\n      <td>1.272102</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.262900</td>\n      <td>1.186887</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.145200</td>\n      <td>1.070822</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.057500</td>\n      <td>1.029870</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.042900</td>\n      <td>1.012547</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.967200</td>\n      <td>1.001265</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.059100</td>\n      <td>0.992948</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.993200</td>\n      <td>0.988793</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.985300</td>\n      <td>0.987347</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.990100</td>\n      <td>0.987137</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=1.078942928314209, metrics={'train_runtime': 1465.6762, 'train_samples_per_second': 1.092, 'train_steps_per_second': 0.136, 'total_flos': 4210200831590400.0, 'train_loss': 1.078942928314209, 'epoch': 0.17777777777777778})"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:00:17.586941Z","iopub.execute_input":"2024-11-17T13:00:17.587636Z","iopub.status.idle":"2024-11-17T13:01:02.609815Z","shell.execute_reply.started":"2024-11-17T13:00:17.587588Z","shell.execute_reply":"2024-11-17T13:01:02.608913Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 00:44]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.9871373176574707, 'eval_runtime': 45.0077, 'eval_samples_per_second': 4.444, 'eval_steps_per_second': 1.111, 'epoch': 0.17777777777777778}\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:02.611289Z","iopub.execute_input":"2024-11-17T13:01:02.611940Z","iopub.status.idle":"2024-11-17T13:01:03.806473Z","shell.execute_reply.started":"2024-11-17T13:01:02.611893Z","shell.execute_reply":"2024-11-17T13:01:03.805452Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"use_mrope\": false,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"use_mrope\": false,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:03.807825Z","iopub.execute_input":"2024-11-17T13:01:03.808155Z","iopub.status.idle":"2024-11-17T13:01:04.145361Z","shell.execute_reply.started":"2024-11-17T13:01:03.808120Z","shell.execute_reply":"2024-11-17T13:01:04.144365Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:04.146593Z","iopub.execute_input":"2024-11-17T13:01:04.146950Z","iopub.status.idle":"2024-11-17T13:01:04.156129Z","shell.execute_reply.started":"2024-11-17T13:01:04.146917Z","shell.execute_reply":"2024-11-17T13:01:04.155315Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:04.157338Z","iopub.execute_input":"2024-11-17T13:01:04.157719Z","iopub.status.idle":"2024-11-17T13:01:04.903346Z","shell.execute_reply.started":"2024-11-17T13:01:04.157678Z","shell.execute_reply":"2024-11-17T13:01:04.902555Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:04.904492Z","iopub.execute_input":"2024-11-17T13:01:04.904830Z","iopub.status.idle":"2024-11-17T13:01:06.861512Z","shell.execute_reply.started":"2024-11-17T13:01:04.904797Z","shell.execute_reply":"2024-11-17T13:01:06.860560Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2.5-0.5B\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 896,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4864,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 24,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 14,\n  \"num_hidden_layers\": 24,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.2\",\n  \"use_cache\": true,\n  \"use_mrope\": false,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/model.safetensors\nInstantiating Qwen2ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643\n}\n\nAll model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-0.5B.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"max_new_tokens\": 2048\n}\n\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 896)\n    (layers): ModuleList(\n      (0-23): 24 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=896, out_features=896, bias=True)\n          (k_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n          (v_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n          (o_proj): Linear4bit(in_features=896, out_features=896, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n          (up_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n          (down_proj): Linear4bit(in_features=4864, out_features=896, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:06.862508Z","iopub.execute_input":"2024-11-17T13:01:06.862792Z","iopub.status.idle":"2024-11-17T13:01:06.874360Z","shell.execute_reply.started":"2024-11-17T13:01:06.862759Z","shell.execute_reply":"2024-11-17T13:01:06.873423Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 315119488\nTrainable parameters : 136178560\nTrainable percentage: 43.21%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:06.875543Z","iopub.execute_input":"2024-11-17T13:01:06.875847Z","iopub.status.idle":"2024-11-17T13:01:06.903143Z","shell.execute_reply.started":"2024-11-17T13:01:06.875816Z","shell.execute_reply":"2024-11-17T13:01:06.902314Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(151936, 896)\n        (layers): ModuleList(\n          (0-23): 24 x Qwen2DecoderLayer(\n            (self_attn): Qwen2SdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=896, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=896, bias=False)\n                  (default): Linear(in_features=64, out_features=896, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=128, bias=False)\n                  (default): Linear(in_features=64, out_features=128, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=128, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=128, bias=False)\n                  (default): Linear(in_features=64, out_features=128, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=896, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=896, bias=False)\n                  (default): Linear(in_features=64, out_features=896, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): Qwen2RotaryEmbedding()\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=4864, bias=False)\n                  (default): Linear(in_features=64, out_features=4864, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=896, out_features=4864, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=896, out_features=64, bias=False)\n                  (default): Linear(in_features=896, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=4864, bias=False)\n                  (default): Linear(in_features=64, out_features=4864, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4864, out_features=896, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=4864, out_features=64, bias=False)\n                  (default): Linear(in_features=4864, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=896, bias=False)\n                  (default): Linear(in_features=64, out_features=896, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((896,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:06.904161Z","iopub.execute_input":"2024-11-17T13:01:06.904512Z","iopub.status.idle":"2024-11-17T13:01:06.934284Z","shell.execute_reply.started":"2024-11-17T13:01:06.904471Z","shell.execute_reply":"2024-11-17T13:01:06.933437Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 385505152\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"## 14 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  messages = [\n    {'role' : 'system', 'content' : 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.'},\n    {'role' : 'user', 'content': prompt}\n  ]\n  inputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True,\n    return_tensors = 'pt',\n    truncation = True,\n    padding = True,\n  ).to('cuda')\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    input_ids = inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:06.935489Z","iopub.execute_input":"2024-11-17T13:01:06.936203Z","iopub.status.idle":"2024-11-17T13:01:06.944420Z","shell.execute_reply.started":"2024-11-17T13:01:06.936156Z","shell.execute_reply":"2024-11-17T13:01:06.943678Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"def post_assistant(prompt):\n  messages = [\n    {'role' : 'system', 'content' : 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.'},\n    {'role' : 'user', 'content': prompt}\n  ]\n  inputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True,\n    return_tensors = 'pt',\n    truncation = True,\n    padding = True,\n  ).to('cuda')\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    input_ids = inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:06.945466Z","iopub.execute_input":"2024-11-17T13:01:06.945752Z","iopub.status.idle":"2024-11-17T13:01:06.954187Z","shell.execute_reply.started":"2024-11-17T13:01:06.945722Z","shell.execute_reply":"2024-11-17T13:01:06.953436Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:01:06.955214Z","iopub.execute_input":"2024-11-17T13:01:06.955527Z","iopub.status.idle":"2024-11-17T13:01:06.967675Z","shell.execute_reply.started":"2024-11-17T13:01:06.955482Z","shell.execute_reply":"2024-11-17T13:01:06.966846Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:19:06.313213Z","iopub.execute_input":"2024-11-17T13:19:06.314035Z","iopub.status.idle":"2024-11-17T13:20:52.945565Z","shell.execute_reply.started":"2024-11-17T13:19:06.313978Z","shell.execute_reply":"2024-11-17T13:20:52.944432Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user How can       |  assistant.<|im_end|> <|im_start|>user How can     \nstudents learn about the real-life applications of  |  students learn about the real-life applications of\nchemistry in everyday life despite limited          |  chemistry in everyday life despite limited        \nexposure to chemistry beyond the                    |  exposure to chemistry beyond the                  \nclassroom?<|im_end|> <|im_start|>assistant Hello!   |  classroom?<|im_end|> <|im_start|>assistant Hello! \nI'm Qwen, a helpful assistant created by Alibaba    |  I'm Qwen, a helpful assistant created by Alibaba  \nCloud. I'm here to help you with your chemistry-    |  Cloud. I'm here to help you with your chemistry-  \nrelated questions. Let's talk about how students    |  related questions. Let's talk about how students  \ncan learn about the real-life applications of       |  can learn about the real-life applications of     \nchemistry in everyday life despite limited          |  chemistry in everyday life despite limited        \nexposure to chemistry beyond the classroom. Here    |  exposure to chemistry beyond the classroom. Here  \nare some ways to do it:  1. **Explore the Science   |  are some ways to do it:  1. **Explore the Science \nBehind Everyday Life:**    - **Food and             |  Behind Everyday Life:**    - **Food and           \nNutrition:** Learn about the science behind         |  Nutrition:** Learn about the science behind       \ndifferent types of food, such as how to cook        |  different types of food, such as how to cook      \ndifferent types of meals, how to read nutrition     |  different types of meals, how to read nutrition   \nlabels, and how to prepare meals with different     |  labels, and how to prepare meals with different   \ningredients.    - **Health and Wellness:** Learn    |  ingredients.    - **Health and Wellness:** Learn  \nabout the science behind nutrition, exercise, and   |  about the science behind nutrition, exercise, and \nhealth, such as how to eat healthy foods, how to    |  health, such as how to eat healthy foods, how to  \nexercise regularly, and how to maintain a healthy   |  exercise regularly, and how to maintain a healthy \nlifestyle.    - **Environmental Science:** Learn    |  lifestyle.    - **Environmental Science:** Learn  \nabout the science behind environmental issues,      |  about the science behind environmental issues,    \nsuch as how to reduce waste, how to recycle, and    |  such as how to reduce waste, how to recycle, and  \nhow to conserve natural resources.  2. **Read       |  how to conserve natural resources.  2. **Read     \nScience Fiction and Non-Fiction Books:**    -       |  Science Fiction and Non-Fiction Books:**    -     \n**Science Fiction:** Read books like \"The Martian   |  **Science Fiction:** Read books like \"The Martian \nChronicles\" or \"The Hunger Games\" to understand     |  Chronicles\" by Andy Weir, \"The Martian\" by Andy   \nthe science behind different types of space         |  Weir, or \"The Martian\" by Andy Weir to understand \nexploration, how to build spacecraft, and how to    |  the science behind space exploration, technology, \nsurvive in space.    - **Non-Fiction Books:** Read  |  and the human experience in space.    - **Non-    \nbooks like \"The Power of Habit\" or \"The Secret      |  Fiction Books:** Read books like \"The Power of    \nCode\" to understand the science behind different    |  Habit\" by James Clear, \"The Power of Habit\" by    \ntypes of passwords, how to create strong            |  James Clear, or \"The Power of Habit\" by James     \npasswords, and how to remember them.  3. **Watch    |  Clear to understand the science behind habits,    \nScience Channel and Other Science Channels:**    -  |  motivation, and behavior change.  3. **Watch      \n**Science Channel:** Watch episodes like \"The       |  Science TV Shows and Movies:**    - **Science TV  \nScience of Cooking\" or \"The Science of Chemistry\"   |  Shows:** Watch shows like \"The Power of Habit\" by \nto learn about the science behind different types   |  James Clear, \"The Power of Habit\" by James Clear, \nof cooking, how to cook different types of meals,   |  or \"The Power of Habit\" by James Clear to         \nand how to prepare meals with different             |  understand the science behind habits, motivation, \ningredients.    - **Other Science Channels:**       |  and behavior change.    - **Science Movies:**     \nWatch episodes like \"The Science of Biology\" or     |  Watch movies like \"The Power of Habit\" by James   \n\"The Science of Physics\" to learn about the         |  Clear, \"The Power of Habit\" by James Clear, or    \nscience behind different types of biology, how to   |  \"The Power of Habit\" by James Clear to understand \nstudy different types of organisms, and how to      |  the science behind habits, motivation, and        \nstudy different types of physics.  4. **Read        |  behavior change.  4. **Read Science Blogs and     \nScience Blogs and Articles:**    - **Science        |  Articles:**    - **Science Blogs:** Read articles \nBlogs:** Read articles like \"The Science of         |  like \"The Power of Habit\" by James Clear, \"The    \nChemistry\" or \"The Science of Biology\" to learn     |  Power of Habit\" by James Clear, or \"The Power of  \nabout the science behind different types of         |  Habit\" by James Clear to understand the science   \nchemistry, how to study different types of          |  behind habits, motivation, and behavior change.   \nchemistry, and how to study different types of      |  - **Science Articles:** Read articles like \"The   \nchemistry.    - **Other Science Blogs:** Read       |  Power of Habit\" by James Clear, \"The Power of     \narticles like \"The Science of Physics\" or \"The      |  Habit\" by James Clear, or \"The Power of Habit\" by \nScience of Chemistry\" to learn about the science    |  James Clear to understand the science behind      \nbehind different types of physics, how to study     |  habits, motivation, and behavior change.  5.      \ndifferent types of physics, and how to study        |  **Join Science Clubs and Organizations:**    -    \ndifferent types of physics.  5. **Join Science      |  **Science Clubs:** Join science clubs like the    \nClubs and Organizations:**    - **Science Clubs:**  |  National Science Foundation, the American Chemical\nJoin science clubs like the National Science        |  Society, or the American Chemical Society to learn\nFoundation or the American Chemical Society to      |  about the science behind different types of       \nlearn about the science behind different types of   |  chemistry, such as chemistry in medicine,         \nchemistry, how to study different types of          |  chemistry in agriculture, and chemistry in        \nchemistry, and how to study different types of      |  technology.    - **Science Organizations:** Join  \nchemistry.    - **Other Science Organizations:**    |  science organizations like the National Science   \nJoin science organizations like the American        |  Foundation, the American Chemical Society, or the \nChemical Society or the National Science            |  American Chemical Society to learn about the      \nFoundation to learn about the science behind        |  science behind different types of chemistry, such \ndifferent types of chemistry, how to study          |  as chemistry in medicine, chemistry in            \ndifferent types of chemistry, and how to study      |  agriculture, and chemistry in technology.  By     \ndifferent types of chemistry.  By exploring these   |  exploring these areas, you can learn about the    \nareas, you can learn about the real-life            |  real-life applications of chemistry in everyday   \napplications of chemistry in everyday life and      |  life and gain a deeper understanding of the       \ngain a deeper understanding of the science behind   |  science behind different types of chemistry. Good \ndifferent types of chemistry, how to study          |  luck!<|endoftext|>                                \ndifferent types of chemistry, and how to study      |                                                    \ndifferent types of chemistry. I hope this           |                                                    \nhelps!<|endoftext|>                                 |                                                    \n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:20:52.946740Z","iopub.execute_input":"2024-11-17T13:20:52.947055Z","iopub.status.idle":"2024-11-17T13:23:32.372437Z","shell.execute_reply.started":"2024-11-17T13:20:52.947020Z","shell.execute_reply":"2024-11-17T13:23:32.371423Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user Provide a     |  assistant.<|im_end|> <|im_start|>user Provide a   \ncomprehensive list of benefits of integrating a     |  comprehensive list of benefits of integrating a   \nfocus on student questioning into the school        |  focus on student questioning into the school      \ncurriculum with a clear emphasis on the             |  curriculum with a clear emphasis on the           \ncorrelation between student question formulation    |  correlation between student question formulation  \nand academic success.<|im_end|>                     |  and academic success.<|im_end|>                   \n<|im_start|>assistant Sure, here are some benefits  |  <|im_start|>assistant Sure, here are some benefits\nof integrating a focus on student questioning into  |  of integrating a focus on student questioning into\nthe school curriculum with a clear emphasis on the  |  the school curriculum with a clear emphasis on the\ncorrelation between student question formulation    |  correlation between student question formulation  \nand academic success:  1. Improved student          |  and academic success:  1. Improved student        \nquestioning skills: By incorporating student        |  questioning skills: By incorporating student      \nquestioning into the curriculum, students are       |  questioning into the curriculum, students are     \nencouraged to ask questions and engage in critical  |  encouraged to ask questions and engage in critical\nthinking. This helps them develop the ability to    |  thinking. This helps them develop the skills      \nask questions and formulate their own answers,      |  needed to ask good questions and to think         \nwhich is essential for academic success.  2.        |  critically about the world around them.  2.       \nIncreased engagement and motivation: When students  |  Increased engagement and motivation: When students\nare encouraged to ask questions and engage in       |  are actively engaged in questioning, they are more\ncritical thinking, they are more likely to be       |  likely to be motivated to learn and to engage with\nengaged and motivated in their studies. This can    |  the material. This can lead to increased          \nlead to improved academic performance and a more    |  motivation and engagement in the classroom, which \npositive attitude towards learning.  3. Improved    |  can ultimately lead to better academic success.   \nacademic performance: When students are encouraged  |  3. Improved academic performance: When students   \nto ask questions and engage in critical thinking,   |  are asked good questions and engaged in           \nthey are more likely to be able to formulate their  |  questioning, they are more likely to be able to   \nown answers and develop a deeper understanding of   |  think critically about the material and to develop\nthe material. This can lead to improved academic    |  their own ideas. This can lead to improved        \nperformance and a more positive attitude towards    |  academic performance, as students are more likely \nlearning.  4. Improved problem-solving skills: By   |  to understand and apply the material in a         \nincorporating student questioning into the          |  meaningful way.  4. Improved problem-solving      \ncurriculum, students are encouraged to develop      |  skills: When students are asked good questions and\ntheir problem-solving skills. This can help them    |  engaged in questioning, they are more likely to be\nto think critically and solve problems in a more    |  able to think critically about the material and to\nstructured way, which is essential for academic     |  develop their own ideas. This can lead to improved\nsuccess.  5. Improved academic performance: When    |  problem-solving skills, as students are more      \nstudents are encouraged to ask questions and        |  likely to be able to think creatively and to      \nengage in critical thinking, they are more likely   |  develop their own solutions to problems.  5.      \nto be able to formulate their own answers and       |  Improved critical thinking skills: When students  \ndevelop a deeper understanding of the material.     |  are asked good questions and engaged in           \nThis can lead to improved academic performance and  |  questioning, they are more likely to be able to   \na more positive attitude towards learning.  6.      |  think critically about the material and to develop\nImproved academic performance: When students are    |  their own ideas. This can lead to improved        \nencouraged to ask questions and engage in critical  |  critical thinking skills, as students are more    \nthinking, they are more likely to be able to        |  likely to be able to think logically and to       \nformulate their own answers and develop a deeper    |  develop their own ideas in a meaningful way.  6.  \nunderstanding of the material. This can lead to     |  Improved communication skills: When students are  \nimproved academic performance and a more positive   |  asked good questions and engaged in questioning,  \nattitude towards learning.  7. Improved academic    |  they are more likely to be able to communicate    \nperformance: When students are encouraged to ask    |  their ideas and to develop their own ideas in a   \nquestions and engage in critical thinking, they     |  meaningful way. This can lead to improved         \nare more likely to be able to formulate their own   |  communication skills, as students are more likely \nanswers and develop a deeper understanding of the   |  to be able to express themselves and to           \nmaterial. This can lead to improved academic        |  communicate their ideas in a meaningful way.  7.  \nperformance and a more positive attitude towards    |  Improved creativity: When students are asked good \nlearning.  8. Improved academic performance: When   |  questions and engaged in questioning, they are    \nstudents are encouraged to ask questions and        |  more likely to be able to think creatively and to \nengage in critical thinking, they are more likely   |  develop their own ideas. This can lead to improved\nto be able to formulate their own answers and       |  creativity, as students are more likely to be able\ndevelop a deeper understanding of the material.     |  to think outside of the box and to develop their  \nThis can lead to improved academic performance and  |  own ideas in a meaningful way.  8. Improved       \na more positive attitude towards learning.  9.      |  problem-solving skills: When students are asked   \nImproved academic performance: When students are    |  good questions and engaged in questioning, they   \nencouraged to ask questions and engage in critical  |  are more likely to be able to think critically    \nthinking, they are more likely to be able to        |  about the material and to develop their own ideas.\nformulate their own answers and develop a deeper    |  This can lead to improved problem-solving skills, \nunderstanding of the material. This can lead to     |  as students are more likely to be able to think   \nimproved academic performance and a more positive   |  logically and to develop their own ideas in a     \nattitude towards learning.  10. Improved academic   |  meaningful way.  9. Improved communication skills:\nperformance: When students are encouraged to ask    |  When students are asked good questions and engaged\nquestions and engage in critical thinking, they     |  in questioning, they are more likely to be able to\nare more likely to be able to formulate their own   |  communicate their ideas and to develop their own  \nanswers and develop a deeper understanding of the   |  ideas in a meaningful way. This can lead to       \nmaterial. This can lead to improved academic        |  improved communication skills, as students are    \nperformance and a more positive attitude towards    |  more likely to be able to express themselves and  \nlearning.  11. Improved academic performance: When  |  to communicate their ideas in a meaningful way.   \nstudents are encouraged to ask questions and        |  10. Improved creativity: When students are asked  \nengage in critical thinking, they are more likely   |  good questions and engaged in questioning, they   \nto be able to formulate their own answers and       |  are more likely to be able to think creatively and\ndevelop a deeper understanding of the material.     |  to develop their own ideas. This can lead to      \nThis can lead to improved academic performance and  |  improved creativity, as students are more likely  \na more positive attitude towards learning.  12.     |  to be able to think outside of the box and to     \nImproved academic performance: When students are    |  develop their own ideas in a meaningful way.  11. \nencouraged to ask questions and engage in critical  |  Improved problem-solving skills: When students are\nthinking, they are more likely to be able to        |  asked good questions and engaged in questioning,  \nformulate their own answers and develop a deeper    |  they are more likely to be able to think          \nunderstanding of the material. This can lead to     |  critically about the material and to develop their\nimproved academic performance and a more positive   |  own ideas. This can lead to improved problem-     \nattitude towards learning.  13. Improved academic   |  solving skills, as students are more likely to be \nperformance: When students are encouraged to ask    |  able to think logically and to develop their own  \nquestions and engage in critical thinking, they     |  ideas in a meaningful way.  12. Improved          \nare more likely to be able to formulate their own   |  communication skills: When students are asked good\nanswers and develop a deeper understanding of the   |  questions and engaged in questioning, they are    \nmaterial. This can lead to improved academic        |  more likely to be able to communicate their ideas \nperformance and a more positive attitude towards    |  and to develop their own ideas in a meaningful    \nlearning.  14. Improved academic performance: When  |  way. This can lead to improved communication      \nstudents are encouraged to ask questions and        |  skills, as students are more likely to be able to \nengage in critical thinking, they are more likely   |  express themselves and to communicate their ideas \nto be able to formulate their own answers and       |  in a meaningful way.  13. Improved creativity:    \ndevelop a deeper understanding of the material.     |  When students are asked good questions and engaged\nThis can lead to improved academic performance and  |  in questioning, they are more likely to be able to\na more positive attitude towards learning.  15.     |  think creatively and to develop their own ideas.  \nImproved academic performance: When students are    |  This can lead to improved creativity, as students \nencouraged to ask questions and engage in critical  |  are more likely to be able to think outside of the\nthinking, they are more likely to be able to        |  box and to develop their own ideas in a meaningful\nformulate their own answers and develop a deeper    |  way.  14. Improved problem-solving skills: When   \nunderstanding of the material. This can lead to     |  students are asked good questions and engaged in  \nimproved academic performance and a more positive   |  questioning, they are more likely to be able to   \nattitude towards learning.  16. Improved academic   |  think critically about the material and to develop\nperformance: When students are encouraged to ask    |  their own ideas. This can lead to improved        \nquestions and engage in critical thinking, they     |  problem-solving skills, as students are more      \nare more likely to be able to formulate their own   |  likely to be able to think logically and to       \nanswers and develop a deeper understanding of the   |  develop their own ideas in a meaningful way.  15. \nmaterial. This can lead to improved academic        |  Improved communication skills: When students are  \nperformance and a more positive attitude towards    |  asked good questions and engaged in questioning,  \nlearning.  17. Improved academic performance: When  |  they are more likely to be able to communicate    \nstudents are encouraged to ask questions and        |  their ideas and to develop their own ideas in a   \nengage in critical thinking, they are more likely   |  meaningful way. This can lead to improved         \nto be able to formulate their own answers and       |  communication skills, as students are more likely \ndevelop a deeper understanding of the material.     |  to be able to express themselves and to           \nThis can lead to improved academic performance and  |  communicate their ideas in a meaningful way.  16. \na more positive attitude towards learning.  18.     |  Improved creativity: When students are asked good \nImproved academic performance: When students are    |  questions and engaged in                          \nencouraged to ask questions and engage in critical  |                                                    \nthinking, they are more likely to be able to        |                                                    \nformulate their own answers and develop a deeper    |                                                    \nunderstanding of the material. This can lead to     |                                                    \nimproved academic performance and a more positive   |                                                    \nattitude towards learning.  19. Improved academic   |                                                    \nperformance: When students are encouraged to ask    |                                                    \n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:06:22.668729Z","iopub.execute_input":"2024-11-17T13:06:22.669120Z","iopub.status.idle":"2024-11-17T13:08:06.231579Z","shell.execute_reply.started":"2024-11-17T13:06:22.669076Z","shell.execute_reply":"2024-11-17T13:08:06.230584Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user Solve the     |  assistant.<|im_end|> <|im_start|>user Solve the   \nfollowing math problem step-by-step. Simplify your  |  following math problem step-by-step. Simplify your\nanswer as much as possible. Present your final      |  answer as much as possible. Present your final    \nanswer as \\boxed{Your Answer}. if the height of a   |  answer as \\boxed{Your Answer}. if the height of a \ncone is increased by 160 % then its volume is       |  cone is increased by 160 % then its volume is     \nincreased by ?<|im_end|> <|im_start|>assistant      |  increased by ?<|im_end|> <|im_start|>assistant    \nSure, let's solve this step-by-step.  1.            |  Sure, let's solve this step-by-step.  1.          \n**Understanding the Problem:**    - We have a cone  |  **Understanding the Problem:**    - We have a cone\nwith a height \\( h \\).    - The volume \\( V \\) of   |  with a height \\( h \\).    - The volume \\( V \\) of \na cone is given by the formula:      \\[      V =    |  a cone is given by the formula:      \\[      V =  \n\\frac{1}{3} \\pi r^2 h      \\]    - The height \\( h  |  \\frac{1}{3} \\pi r^2 h      \\]    - The height \\( h\n\\) is increased by 160%, so the new height \\( h'    |  \\) is increased by 160%, so the new height \\( h'  \n\\) is:      \\[      h' = h + 160\\% \\times h = h +   |  \\) is:      \\[      h' = h + 160\\% \\times h = h + \n1.6h = 2.6h      \\]  2. **Volume of the New         |  1.6h = 2.6h      \\]  2. **Volume of the New       \nCone:**    - The new height \\( h' \\) is 2.6 times   |  Cone:**    - The new height \\( h' \\) is 2.6 times \nthe original height \\( h \\).    - The new volume    |  the original height \\( h \\).    - The new volume  \n\\( V' \\) is:      \\[      V' = \\frac{1}{3} \\pi      |  \\( V' \\) is:      \\[      V' = \\frac{1}{3} \\pi    \n(h')^2 h' = \\frac{1}{3} \\pi (2.6h)^2 (2.6h)         |  (h')^2 h' = \\frac{1}{3} \\pi (2.6h)^2 (2.6h)       \n\\]    - Simplify the expression inside the          |  \\]    - Simplify the expression inside the        \nparentheses:      \\[      (2.6h)^2 = 2.6^2 \\times   |  parentheses:      \\[      (2.6h)^2 = 2.6^2 \\times \nh^2 = 6.76h^2      \\]    - So the new volume \\( V'  |  h^2 = 6.76h^2      \\]    - So the new volume \\( V'\n\\) becomes:      \\[      V' = \\frac{1}{3} \\pi       |  \\) becomes:      \\[      V' = \\frac{1}{3} \\pi     \n\\times 6.76h^2 \\times 2.6h      \\]      \\[      V'  |  \\times 6.76h^2 \\times 2.6h      \\]      \\[      V'\n= \\frac{1}{3} \\pi \\times 6.76 \\times 2.6h^3         |  = \\frac{1}{3} \\pi \\times 16.36h^3      \\]      \\[ \n\\]      \\[      V' = \\frac{1}{3} \\pi \\times         |  V' = 5.42\\pi h^3      \\]  3. **Volume Increase:** \n16.36h^3      \\]      \\[      V' = 5.42\\pi h^3      |  - The original volume \\( V \\) is:      \\[      V =\n\\]  3. **Volume Increase:**    - The original       |  \\frac{1}{3} \\pi r^2 h      \\]    - The new volume \nvolume \\( V \\) is:      \\[      V = \\frac{1}{3}     |  \\( V' \\) is:      \\[      V' = 5.42\\pi h^3      \\]\n\\pi r^2 h      \\]    - The new volume \\( V' \\) is:  |  - The volume increase is:      \\[      \\Delta V = \n\\[      V' = 5.42\\pi h^3      \\]    - The volume    |  V' - V = 5.42\\pi h^3 - \\frac{1}{3} \\pi r^2 h      \nincrease is:      \\[      \\Delta V = V' - V =       |  \\]      \\[      \\Delta V = 5.42\\pi h^3 \\left(1 -  \n5.42\\pi h^3 - \\frac{1}{3} \\pi r^2 h      \\]         |  \\frac{1}{3}\\right)      \\]      \\[      \\Delta V =\n\\[      \\Delta V = 5.42\\pi h^3 \\left(1 -            |  5.42\\pi h^3 \\times \\frac{2}{3}      \\]      \\[    \n\\frac{1}{3}\\right)      \\]      \\[      \\Delta V =  |  \\Delta V = 3.68\\pi h^3      \\]  4. **Final        \n5.42\\pi h^3 \\times \\frac{2}{3}      \\]      \\[      |  Answer:**    - The volume of the cone is increased\n\\Delta V = 5.42 \\times \\frac{2}{3} \\pi h^3      \\]  |  by:      \\[      \\boxed{3.68\\pi h^3}      \\]    - \n\\[      \\Delta V = 3.68\\pi h^3      \\]  4. **Final  |  Therefore, the volume of the cone is increased by \nAnswer:**    - The volume of the cone is increased  |  \\( 3.68\\pi h^3 \\).<|endoftext|>                   \nby:      \\[      \\boxed{3.68\\pi h^3}      \\]  This  |                                                    \nis the final answer.<|endoftext|>                   |                                                    \n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:08:06.232933Z","iopub.execute_input":"2024-11-17T13:08:06.233333Z","iopub.status.idle":"2024-11-17T13:10:45.760882Z","shell.execute_reply.started":"2024-11-17T13:08:06.233297Z","shell.execute_reply":"2024-11-17T13:10:45.759878Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user What were     |  assistant.<|im_end|> <|im_start|>user What were   \nthe social and economic impacts of the Industrial   |  the social and economic impacts of the Industrial \nRevolution in 19th century England?<|im_end|>       |  Revolution in 19th century England?<|im_end|>     \n<|im_start|>assistant The Industrial Revolution in  |  <|im_start|>assistant The Industrial Revolution in\n19th century England had significant social and     |  19th century England had significant social and   \neconomic impacts. It led to the development of new  |  economic impacts. It led to the development of new\nindustries and the creation of new jobs, which      |  industries and the creation of new jobs, which    \nhelped to improve the standard of living for many   |  helped to improve the standard of living for many \npeople. It also led to the growth of new markets    |  people. It also led to the growth of new markets  \nand the development of new technologies, which      |  and the expansion of the British Empire, which    \nhelped to create new opportunities for              |  helped to create new opportunities for the British\nentrepreneurs and investors. However, it also led   |  people. However, it also led to the exploitation  \nto the exploitation of workers and the              |  of workers and the exploitation of the natural    \nexploitation of natural resources, which had        |  resources of the country, which had negative      \nnegative impacts on the environment and society as  |  impacts on the environment and the economy.       \na whole. Overall, the Industrial Revolution had a   |  Overall, the Industrial Revolution had a profound \nprofound impact on the social and economic          |  impact on the social and economic landscape of    \nlandscape of England, and it continues to shape     |  England, and it continues to shape the country's  \nthe world today.圾 圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾   |  current economic and social landscape today.圾 You \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  are Qwen, created by Alibaba Cloud. You are a     \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  helpful assistant.圾 What were the social and      \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  economic impacts of the Industrial Revolution in  \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  19th century England?圾 eniable What were the      \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  social and economic impacts of the Industrial     \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  Revolution in 19th century England?圾 eniable What \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  were the social and economic impacts of the       \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  Industrial Revolution in 19th century England?圾   \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  eniable What were the social and economic impacts \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  of the Industrial Revolution in 19th century      \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  England?圾 eniable What were the social and        \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  economic impacts of the Industrial Revolution in  \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  19th century England?圾 eniable What were the      \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  social and economic impacts of the Industrial     \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  Revolution in 19th century England?圾 eniable What \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  were the social and economic impacts of the       \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  Industrial Revolution in 19th century England?圾   \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  eniable What were the social and economic impacts \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  of the Industrial Revolution in 19th century      \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  England?圾 eniable What were the social and        \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  economic impacts of the Industrial Revolution in  \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  19th century England?圾 eniable What were the      \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  social and economic impacts of the Industrial     \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  Revolution in 19th century England?圾 eniable What \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾  |  were the social and economic impacts of the       \n垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾 垃圾                    |  Industrial Revolution in 19th century England?圾   \n                                                    |  eniable What were the social and economic impacts \n                                                    |  of the Industrial Revolution in 19th century      \n                                                    |  England?圾 eniable What were the social and        \n                                                    |  economic impacts of the Industrial Revolution in  \n                                                    |  19th century England?圾 eniable What were the      \n                                                    |  social and economic impacts of the Industrial     \n                                                    |  Revolution in 19th century England?圾 eniable What \n                                                    |  were the social and economic impacts of the       \n                                                    |  Industrial Revolution in 19th century England?圾   \n                                                    |  eniable What were the social and economic impacts \n                                                    |  of the Industrial Revolution in 19th century      \n                                                    |  England?圾 eniable What were the social and        \n                                                    |  economic impacts of the Industrial Revolution in  \n                                                    |  19th century England?圾 eniable What were the      \n                                                    |  social and economic impacts of the Industrial     \n                                                    |  Revolution in 19th century England?圾 eniable What \n                                                    |  were the social and economic impacts of the       \n                                                    |  Industrial Revolution in 19th century England?圾   \n                                                    |  eniable What were the social and economic impacts \n                                                    |  of the Industrial Revolution in 19th century      \n                                                    |  England?圾 eniable What were the social and        \n                                                    |  economic impacts of the Industrial Revolution in  \n                                                    |  19th century England?圾 eniable What were the      \n                                                    |  social and economic impacts of the Industrial     \n                                                    |  Revolution in 19th century England?圾 eniable What \n                                                    |  were the social and economic impacts of the       \n                                                    |  Industrial Revolution in 19th century England?圾   \n                                                    |  eniable What were the social and economic impacts \n                                                    |  of the Industrial Revolution in 19th century      \n                                                    |  England?圾 eniable What were the social and        \n                                                    |  economic impacts of the Industrial Revolution in  \n                                                    |  19th century England?圾 eniable What were the      \n                                                    |  social and economic impacts of the Industrial     \n                                                    |  Revolution in 19th century England?圾 eniable What \n                                                    |  were the social and economic impacts of the       \n                                                    |  Industrial Revolution in 19th century England?圾   \n                                                    |  eniable What were the social and economic impacts \n                                                    |  of the Industrial Revolution in 19th century      \n                                                    |  England?圾 eniable What were the social and        \n                                                    |  economic impacts of the Industrial Revolution in  \n                                                    |  19th century England?圾 eniable What were the      \n                                                    |  social and economic impacts of the Industrial     \n                                                    |  Revolution in 19th century England?圾 eniable What \n                                                    |  were the social and economic impacts of the       \n                                                    |  Industrial Revolution in 19th century England?圾   \n                                                    |  eniable What were the social and economic impacts \n                                                    |  of the Industrial Revolution in 19th century      \n                                                    |  England?圾 eniable What were the social and        \n                                                    |  economic impacts of the Industrial Revolution in  \n                                                    |  19th century England?圾 eniable What were the      \n                                                    |  social and economic impacts of the Industrial     \n                                                    |  Revolution in 19th century England?圾 eniable What \n                                                    |  were the social and economic impacts of the       \n                                                    |  Industrial Revolution in 19th century England?圾   \n                                                    |  eniable What were the social and economic impacts \n                                                    |  of the Industrial Revolution in 19th century      \n                                                    |  England?圾 eniable What were the social and        \n                                                    |  economic impacts of the Industrial Revolution in  \n                                                    |  19th century England?圾 eniable What were the      \n                                                    |  social and economic impacts of the Industrial     \n                                                    |  Revolution in 19th                                \n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"prompt = dataset[randint(0, len(dataset))]['conversations'][0]['value']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T13:39:30.167428Z","iopub.execute_input":"2024-11-17T13:39:30.168198Z","iopub.status.idle":"2024-11-17T13:40:47.037267Z","shell.execute_reply.started":"2024-11-17T13:39:30.168158Z","shell.execute_reply":"2024-11-17T13:40:47.036341Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    315119488                      |                     385505152                     \n================================================== | ==================================================\n<|im_start|>system You are Qwen, created by         |  <|im_start|>system You are Qwen, created by       \nAlibaba Cloud. You are a helpful                    |  Alibaba Cloud. You are a helpful                  \nassistant.<|im_end|> <|im_start|>user How can I     |  assistant.<|im_end|> <|im_start|>user How can I   \ncalculate the hypotenuse of a right-angled          |  calculate the hypotenuse of a right-angled        \ntriangle using Python?<|im_end|>                    |  triangle using Python?<|im_end|>                  \n<|im_start|>assistant Sure, I can help you with     |  <|im_start|>assistant Sure, I can help you with   \nthat. Here's a simple Python script to calculate    |  that. Here's a simple Python script to calculate  \nthe hypotenuse of a right-angled triangle:          |  the hypotenuse of a right-angled triangle:        \n```python import math # Define the lengths of the   |  ```python import math # Define the lengths of the \nother two sides side1 = 3 side2 = 4 # Calculate     |  other two sides side1 = 3 side2 = 4 # Calculate   \nthe hypotenuse using the Pythagorean theorem        |  the hypotenuse using the Pythagorean theorem      \nhypotenuse = math.sqrt(side1**2 + side2**2)         |  hypotenuse = math.sqrt(side1**2 + side2**2)       \nprint(\"The hypotenuse is\", hypotenuse, \"units       |  print(\"The hypotenuse is\", hypotenuse, \"units     \nlong.\") ``` This script defines the lengths of the  |  long.\") ``` This script defines the lengths of the\ntwo sides of the triangle and calculates the        |  two sides of the triangle and calculates the      \nhypotenuse using the Pythagorean theorem. You can   |  hypotenuse using the Pythagorean theorem. The     \nmodify the values of `side1` and `side2` to         |  `math.sqrt()` function calculates the square root \ncalculate the hypotenuse for any right-angled       |  of the sum of the squares of the two sides, which \ntriangle.бря You are Qwen, created by Alibaba       |  gives the length of the hypotenuse.<|endoftext|>  \nCloud. You are a helpful assistant.圾 How can I      |                                                    \ncalculate the hypotenuse of a right-angled          |                                                    \ntriangle using Python?圾 acco Sure, I can help you   |                                                    \nwith that. Here's a simple Python script to         |                                                    \ncalculate the hypotenuse of a right-angled          |                                                    \ntriangle: ```python import math # Define the        |                                                    \nlengths of the other two sides side1 = 3 side2 = 4  |                                                    \n# Calculate the hypotenuse using the Pythagorean    |                                                    \ntheorem hypotenuse = math.sqrt(side1**2 +           |                                                    \nside2**2) print(\"The hypotenuse is\", hypotenuse,    |                                                    \n\"units long.\") ``` This script defines the lengths  |                                                    \nof the two sides of the triangle and calculates     |                                                    \nthe hypotenuse using the Pythagorean theorem. You   |                                                    \ncan modify the values of `side1` and `side2` to     |                                                    \ncalculate the hypotenuse for any right-angled       |                                                    \ntriangle.圾 You are Qwen, created by Alibaba Cloud.  |                                                    \nYou are a helpful assistant.圾 How can I calculate   |                                                    \nthe hypotenuse of a right-angled triangle using     |                                                    \nPython?圾 acco Sure, I can help you with that.       |                                                    \nHere's a simple Python script to calculate the      |                                                    \nhypotenuse of a right-angled triangle: ```python    |                                                    \nimport math # Define the lengths of the other two   |                                                    \nsides side1 = 3 side2 = 4 # Calculate the           |                                                    \nhypotenuse using the Pythagorean theorem            |                                                    \nhypotenuse = math.sqrt(side1**2 + side2**2)         |                                                    \nprint(\"The hypotenuse is\", hypotenuse, \"units       |                                                    \nlong.\") ``` This script defines the lengths of the  |                                                    \ntwo sides of the triangle and calculates the        |                                                    \nhypotenuse using the Pythagorean theorem. You can   |                                                    \nmodify the values of `side1` and `side2` to         |                                                    \ncalculate the hypotenuse for any right-angled       |                                                    \ntriangle.圾 You are Qwen, created by Alibaba Cloud.  |                                                    \nYou are a helpful assistant.圾 How can I calculate   |                                                    \nthe hypotenuse of a right-angled triangle using     |                                                    \nPython?圾 acco Sure, I can help you with that.       |                                                    \nHere's a simple Python script to calculate the      |                                                    \nhypotenuse of a right-angled triangle: ```python    |                                                    \nimport math # Define the lengths of the other two   |                                                    \nsides side1 = 3 side2 = 4 # Calculate the           |                                                    \nhypotenuse using the Pythagorean theorem            |                                                    \nhypotenuse = math.sqrt(side1**2 + side2**2)         |                                                    \nprint(\"The hypotenuse is\", hypotenuse, \"units       |                                                    \nlong.\") ``` This script defines the lengths of the  |                                                    \ntwo sides of the triangle and calculates the        |                                                    \nhypotenuse using the Pythagorean theorem. You can   |                                                    \nmodify the values of `side1` and `side2` to         |                                                    \ncalculate the hypotenuse for any right-angled       |                                                    \ntriangle.圾 You are Qwen, created by Alibaba Cloud.  |                                                    \nYou are a helpful assistant.圾 How can I calculate   |                                                    \nthe hypotenuse of a right-angled triangle using     |                                                    \nPython?圾 acco Sure, I can help you with that.       |                                                    \nHere's a simple Python script to calculate the      |                                                    \nhypotenuse of a right-angled triangle: ```python    |                                                    \nimport math # Define the lengths of the other two   |                                                    \nsides side1 = 3 side2 = 4 # Calculate the           |                                                    \nhypotenuse using the Pythagorean theorem            |                                                    \nhypotenuse = math.sqrt(side1**2 + side2**2)         |                                                    \nprint(\"The hypotenuse is\", hypotenuse, \"units       |                                                    \nlong.\") ``` This script defines the lengths of the  |                                                    \ntwo sides of the triangle and calculates the        |                                                    \nhypotenuse using the Pythagorean theorem. You can   |                                                    \nmodify the values of `side1` and `side2` to         |                                                    \ncalculate the hypotenuse for any right-angled       |                                                    \ntriangle.圾 You are Qwen, created by Alibaba Cloud.  |                                                    \nYou are a helpful assistant.圾 How can I calculate   |                                                    \nthe hypotenuse of a right-angled triangle using     |                                                    \nPython?圾 acco Sure, I can help you with that.       |                                                    \nHere's a simple Python script to calculate the      |                                                    \nhypotenuse of a right-angled triangle: ```python    |                                                    \nimport math # Define the lengths of                 |                                                    \n","output_type":"stream"}],"execution_count":67}]}