{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"!pip install -q --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-07T12:44:20.824305Z","iopub.execute_input":"2024-12-07T12:44:20.825149Z","iopub.status.idle":"2024-12-07T12:45:18.419627Z","shell.execute_reply.started":"2024-12-07T12:44:20.825106Z","shell.execute_reply":"2024-12-07T12:45:18.418328Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntrl 0.12.2 requires transformers<4.47.0, but you have transformers 4.47.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-12-07T12:45:18.421683Z","iopub.execute_input":"2024-12-07T12:45:18.422003Z","iopub.status.idle":"2024-12-07T12:45:25.906444Z","shell.execute_reply.started":"2024-12-07T12:45:18.421973Z","shell.execute_reply":"2024-12-07T12:45:25.905544Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-12-07T12:45:25.907703Z","iopub.execute_input":"2024-12-07T12:45:25.907988Z","iopub.status.idle":"2024-12-07T12:45:26.228857Z","shell.execute_reply.started":"2024-12-07T12:45:25.907961Z","shell.execute_reply":"2024-12-07T12:45:26.227347Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"model_name = 'Qwen/Qwen2.5-3B'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-07T12:45:26.230654Z","iopub.execute_input":"2024-12-07T12:45:26.231015Z","iopub.status.idle":"2024-12-07T12:45:26.247574Z","shell.execute_reply.started":"2024-12-07T12:45:26.230961Z","shell.execute_reply":"2024-12-07T12:45:26.246733Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-12-07T12:45:26.248728Z","iopub.execute_input":"2024-12-07T12:45:26.249098Z","iopub.status.idle":"2024-12-07T12:45:26.257737Z","shell.execute_reply.started":"2024-12-07T12:45:26.249059Z","shell.execute_reply":"2024-12-07T12:45:26.257008Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:45:26.258673Z","iopub.execute_input":"2024-12-07T12:45:26.258941Z","iopub.status.idle":"2024-12-07T12:48:01.840157Z","shell.execute_reply.started":"2024-12-07T12:45:26.258915Z","shell.execute_reply":"2024-12-07T12:48:01.839368Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/683 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d07311f559c84b0faf510b1d23370411"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/35.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5be0ec80f5a84bd1821385554cd6bbe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33456c5d917c4737be1ae36e919cd124"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e77506b87b94e20b1c919ba8af7bb94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2495c93c1daf4f74988d354beef9d319"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e458501651594a90a5485ffdad9de924"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b609ac64e014bb5bec7c871bc66fa2b"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 2048)\n    (layers): ModuleList(\n      (0-35): 36 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n          (down_proj): Linear4bit(in_features=11008, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:01.841179Z","iopub.execute_input":"2024-12-07T12:48:01.841533Z","iopub.status.idle":"2024-12-07T12:48:01.849813Z","shell.execute_reply.started":"2024-12-07T12:48:01.841503Z","shell.execute_reply":"2024-12-07T12:48:01.848838Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1698672640\nTrainable parameters : 311314432\nTrainable percentage: 18.33%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:01.851188Z","iopub.execute_input":"2024-12-07T12:48:01.851531Z","iopub.status.idle":"2024-12-07T12:48:03.972657Z","shell.execute_reply.started":"2024-12-07T12:48:01.851494Z","shell.execute_reply":"2024-12-07T12:48:03.971865Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee657c2b8a94950922d233053688381"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f92c10cd976145b2aac3bd8dbe219f41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6aeb704d513f4f5aa568135427998d78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cc77a5a64734c8dba70ccaf2fc06ecc"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"dataset_name = 'microsoft/orca-math-word-problems-200k'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:03.974123Z","iopub.execute_input":"2024-12-07T12:48:03.974391Z","iopub.status.idle":"2024-12-07T12:48:03.978109Z","shell.execute_reply.started":"2024-12-07T12:48:03.974366Z","shell.execute_reply":"2024-12-07T12:48:03.977191Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 384","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:03.980902Z","iopub.execute_input":"2024-12-07T12:48:03.981199Z","iopub.status.idle":"2024-12-07T12:48:03.991028Z","shell.execute_reply.started":"2024-12-07T12:48:03.981171Z","shell.execute_reply":"2024-12-07T12:48:03.990037Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:03.992060Z","iopub.execute_input":"2024-12-07T12:48:03.992326Z","iopub.status.idle":"2024-12-07T12:48:05.722457Z","shell.execute_reply.started":"2024-12-07T12:48:03.992301Z","shell.execute_reply":"2024-12-07T12:48:05.721544Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question', 'answer'],\n    num_rows: 200035\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:05.723544Z","iopub.execute_input":"2024-12-07T12:48:05.723834Z","iopub.status.idle":"2024-12-07T12:48:05.730326Z","shell.execute_reply.started":"2024-12-07T12:48:05.723808Z","shell.execute_reply":"2024-12-07T12:48:05.729389Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:05.731614Z","iopub.execute_input":"2024-12-07T12:48:05.731941Z","iopub.status.idle":"2024-12-07T12:48:05.753552Z","shell.execute_reply.started":"2024-12-07T12:48:05.731908Z","shell.execute_reply":"2024-12-07T12:48:05.752616Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Jungkook is the 5th place. Find the number of ...   \n1  A number divided by 10 is 6. Yoongi got the re...   \n2  Dongju selects a piece of paper with a number ...   \n3  You wanted to subtract 46 from a number, but y...   \n4  The length of one span of Jinseo is about 12 c...   \n\n                                              answer  \n0  If Jungkook is in 5th place, then 4 people cro...  \n1  Let's call the certain number \"x\". According t...  \n2  To find the second smallest and third smallest...  \n3  If you accidentally subtracted 59 instead of 4...  \n4  If one span of Jinseo is about 12 centimeters ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jungkook is the 5th place. Find the number of ...</td>\n      <td>If Jungkook is in 5th place, then 4 people cro...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A number divided by 10 is 6. Yoongi got the re...</td>\n      <td>Let's call the certain number \"x\". According t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dongju selects a piece of paper with a number ...</td>\n      <td>To find the second smallest and third smallest...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You wanted to subtract 46 from a number, but y...</td>\n      <td>If you accidentally subtracted 59 instead of 4...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The length of one span of Jinseo is about 12 c...</td>\n      <td>If one span of Jinseo is about 12 centimeters ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:05.754913Z","iopub.execute_input":"2024-12-07T12:48:05.755713Z","iopub.status.idle":"2024-12-07T12:48:05.761644Z","shell.execute_reply.started":"2024-12-07T12:48:05.755667Z","shell.execute_reply":"2024-12-07T12:48:05.760782Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'question': 'Jungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.',\n 'answer': 'If Jungkook is in 5th place, then 4 people crossed the finish line faster than him.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:05.762798Z","iopub.execute_input":"2024-12-07T12:48:05.763101Z","iopub.status.idle":"2024-12-07T12:48:05.774211Z","shell.execute_reply.started":"2024-12-07T12:48:05.763073Z","shell.execute_reply":"2024-12-07T12:48:05.773447Z"}},"outputs":[{"name":"stdout","text":"['question', 'answer']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"### Question:\\n{}\\n### Answer:\\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:05.775216Z","iopub.execute_input":"2024-12-07T12:48:05.775493Z","iopub.status.idle":"2024-12-07T12:48:05.784249Z","shell.execute_reply.started":"2024-12-07T12:48:05.775468Z","shell.execute_reply":"2024-12-07T12:48:05.783482Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  input = examples['question']\n  output = examples['answer']\n  \n  text = prompt_format.format(input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:05.785257Z","iopub.execute_input":"2024-12-07T12:48:05.785522Z","iopub.status.idle":"2024-12-07T12:48:05.794007Z","shell.execute_reply.started":"2024-12-07T12:48:05.785488Z","shell.execute_reply":"2024-12-07T12:48:05.793179Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:05.795013Z","iopub.execute_input":"2024-12-07T12:48:05.795299Z","iopub.status.idle":"2024-12-07T12:48:06.250508Z","shell.execute_reply.started":"2024-12-07T12:48:05.795274Z","shell.execute_reply":"2024-12-07T12:48:06.249259Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f397e4b640f04df6a9caf0a6bfffdb12"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:06.251901Z","iopub.execute_input":"2024-12-07T12:48:06.252626Z","iopub.status.idle":"2024-12-07T12:48:06.257763Z","shell.execute_reply.started":"2024-12-07T12:48:06.252578Z","shell.execute_reply":"2024-12-07T12:48:06.256826Z"}},"outputs":[{"name":"stdout","text":"### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|endoftext|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:06.259024Z","iopub.execute_input":"2024-12-07T12:48:06.259395Z","iopub.status.idle":"2024-12-07T12:48:06.283038Z","shell.execute_reply.started":"2024-12-07T12:48:06.259347Z","shell.execute_reply":"2024-12-07T12:48:06.282204Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:06.284048Z","iopub.execute_input":"2024-12-07T12:48:06.284341Z","iopub.status.idle":"2024-12-07T12:48:15.654688Z","shell.execute_reply.started":"2024-12-07T12:48:06.284316Z","shell.execute_reply":"2024-12-07T12:48:15.653841Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70433155ea5f4137977e20870fd4fab1"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:15.655782Z","iopub.execute_input":"2024-12-07T12:48:15.656047Z","iopub.status.idle":"2024-12-07T12:48:15.661288Z","shell.execute_reply.started":"2024-12-07T12:48:15.656021Z","shell.execute_reply":"2024-12-07T12:48:15.660289Z"}},"outputs":[{"name":"stdout","text":"### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|endoftext|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:15.662544Z","iopub.execute_input":"2024-12-07T12:48:15.663333Z","iopub.status.idle":"2024-12-07T12:48:17.851818Z","shell.execute_reply.started":"2024-12-07T12:48:15.663292Z","shell.execute_reply":"2024-12-07T12:48:17.850870Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.852993Z","iopub.execute_input":"2024-12-07T12:48:17.853269Z","iopub.status.idle":"2024-12-07T12:48:17.858979Z","shell.execute_reply.started":"2024-12-07T12:48:17.853243Z","shell.execute_reply":"2024-12-07T12:48:17.858213Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.859864Z","iopub.execute_input":"2024-12-07T12:48:17.860106Z","iopub.status.idle":"2024-12-07T12:48:17.883962Z","shell.execute_reply.started":"2024-12-07T12:48:17.860082Z","shell.execute_reply":"2024-12-07T12:48:17.883047Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  ### Question:\\nThere is a two-digit natural nu...   \n1  ### Question:\\nIn a big box, there are marbles...   \n2  ### Question:\\nAdam goes to a small school, wh...   \n3  ### Question:\\nLisa is looking to attempt a Wo...   \n4  ### Question:\\nThere is a rectangular-shaped p...   \n\n                                           input_ids  \\\n0  [14374, 15846, 510, 3862, 374, 264, 1378, 4834...   \n1  [14374, 15846, 510, 641, 264, 2409, 3745, 11, ...   \n2  [14374, 15846, 510, 37575, 5780, 311, 264, 261...   \n3  [14374, 15846, 510, 72749, 374, 3330, 311, 477...   \n4  [14374, 15846, 510, 3862, 374, 264, 51424, 347...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>### Question:\\nThere is a two-digit natural nu...</td>\n      <td>[14374, 15846, 510, 3862, 374, 264, 1378, 4834...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>### Question:\\nIn a big box, there are marbles...</td>\n      <td>[14374, 15846, 510, 641, 264, 2409, 3745, 11, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>### Question:\\nAdam goes to a small school, wh...</td>\n      <td>[14374, 15846, 510, 37575, 5780, 311, 264, 261...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>### Question:\\nLisa is looking to attempt a Wo...</td>\n      <td>[14374, 15846, 510, 72749, 374, 3330, 311, 477...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>### Question:\\nThere is a rectangular-shaped p...</td>\n      <td>[14374, 15846, 510, 3862, 374, 264, 51424, 347...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.885172Z","iopub.execute_input":"2024-12-07T12:48:17.885847Z","iopub.status.idle":"2024-12-07T12:48:17.891209Z","shell.execute_reply.started":"2024-12-07T12:48:17.885805Z","shell.execute_reply":"2024-12-07T12:48:17.890221Z"}},"outputs":[{"name":"stdout","text":"### Question:\nThere is a two-digit natural number whose tens place is 3. Let A and B be the quotient of this number by 10 and the remainder of division by 10, respectively. If B multiplied by 10 plus A is 9 less than A multiplied by 10 plus B, what is the first number?\n### Answer:\nLet's denote the two-digit number as \\( XY \\), where \\( X \\) is the digit in the tens place and \\( Y \\) is the digit in the ones place. Since the tens place is 3, we have \\( X = 3 \\).\n\nAccording to the problem, \\( A \\) is the quotient of the number by 10, and \\( B \\) is the remainder of the division by 10. Therefore, \\( A = X = 3 \\) and \\( B = Y \\).\n\nThe problem states that \\( B \\times 10 + A \\) is 9 less than \\( A \\times 10 + B \\). This can be written as an equation:\n\n\\[ B \\times 10 + A = A \\times 10 + B - 9 \\]\n\nSubstituting \\( A \\) and \\( B \\) with \\( 3 \\) and \\( Y \\), respectively, we get:\n\n\\[ Y \\times 10 + 3 = 3 \\times 10 + Y - 9 \\]\n\nSimplifying the equation:\n\n\\[ 10Y + 3 = 30 + Y - 9 \\]\n\n\\[ 10Y + 3 = Y + 21 \\]\n\nSubtract \\( Y \\) from both sides:\n\n\\[ 9Y + 3 = 21 \\]\n\nSubtract 3 from both sides:\n\n\\[ 9Y = 18 \\]\n\nDivide both sides by 9:\n\n\\[ Y = 2 \\]\n\nSo the ones place digit is 2. Since we already know the tens place digit is 3, the two-digit number is \\( 32 \\).<|endoftext|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.892280Z","iopub.execute_input":"2024-12-07T12:48:17.892606Z","iopub.status.idle":"2024-12-07T12:48:17.903105Z","shell.execute_reply.started":"2024-12-07T12:48:17.892545Z","shell.execute_reply":"2024-12-07T12:48:17.902184Z"}},"outputs":[{"name":"stdout","text":"[14374, 15846, 510, 3862, 374, 264, 1378, 48342, 5810, 1372, 6693, 22008, 1992, 374, 220, 18, 13, 6771, 362, 323, 425, 387, 279, 74762, 315, 419, 1372, 553, 220, 16, 15, 323, 279, 26313, 315, 12804, 553, 220, 16, 15, 11, 15576, 13, 1416, 425, 54916, 553, 220, 16, 15, 5519, 362, 374, 220, 24, 2686, 1091, 362, 54916, 553, 220, 16, 15, 5519, 425, 11, 1128, 374, 279, 1156, 1372, 5267, 14374, 21806, 510, 10061, 594, 78064, 279, 1378, 48342, 1372, 438, 17767, 57319, 1124, 701, 1380, 17767, 1599, 1124, 8, 374, 279, 15723, 304, 279, 22008, 1992, 323, 17767, 809, 1124, 8, 374, 279, 15723, 304, 279, 6174, 1992, 13, 8704, 279, 22008, 1992, 374, 220, 18, 11, 582, 614, 17767, 1599, 284, 220, 18, 1124, 3593, 11190, 311, 279, 3491, 11, 17767, 362, 1124, 8, 374, 279, 74762, 315, 279, 1372, 553, 220, 16, 15, 11, 323, 17767, 425, 1124, 8, 374, 279, 26313, 315, 279, 12804, 553, 220, 16, 15, 13, 15277, 11, 17767, 362, 284, 1599, 284, 220, 18, 1124, 8, 323, 17767, 425, 284, 809, 1124, 3593, 785, 3491, 5302, 429, 17767, 425, 1124, 15136, 220, 16, 15, 488, 362, 1124, 8, 374, 220, 24, 2686, 1091, 17767, 362, 1124, 15136, 220, 16, 15, 488, 425, 1124, 568, 1096, 646, 387, 5326, 438, 458, 23606, 1447, 78045, 425, 1124, 15136, 220, 16, 15, 488, 362, 284, 362, 1124, 15136, 220, 16, 15, 488, 425, 481, 220, 24, 1124, 2533, 3136, 3696, 10607, 17767, 362, 1124, 8, 323, 17767, 425, 1124, 8, 448, 17767, 220, 18, 1124, 8, 323, 17767, 809, 1124, 701, 15576, 11, 582, 633, 1447, 78045, 809, 1124, 15136, 220, 16, 15, 488, 220, 18, 284, 220, 18, 1124, 15136, 220, 16, 15, 488, 809, 481, 220, 24, 1124, 2533, 50, 6383, 7766, 279, 23606, 1447, 78045, 220, 16, 15, 56, 488, 220, 18, 284, 220, 18, 15, 488, 809, 481, 220, 24, 1124, 2533, 78045, 220, 16, 15, 56, 488, 220, 18, 284, 809, 488, 220, 17, 16, 1124, 2533, 3136, 2144, 17767, 809, 1124, 8, 504, 2176, 11067, 1447, 78045, 220, 24, 56, 488, 220, 18, 284, 220, 17, 16, 1124, 2533, 3136, 2144, 220, 18, 504, 2176, 11067, 1447, 78045, 220, 24, 56, 284, 220, 16, 23, 1124, 2533, 12509, 577, 2176, 11067]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.909540Z","iopub.execute_input":"2024-12-07T12:48:17.909954Z","iopub.status.idle":"2024-12-07T12:48:17.917531Z","shell.execute_reply.started":"2024-12-07T12:48:17.909909Z","shell.execute_reply":"2024-12-07T12:48:17.916613Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.918796Z","iopub.execute_input":"2024-12-07T12:48:17.919058Z","iopub.status.idle":"2024-12-07T12:48:17.928155Z","shell.execute_reply.started":"2024-12-07T12:48:17.919032Z","shell.execute_reply":"2024-12-07T12:48:17.927346Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.929341Z","iopub.execute_input":"2024-12-07T12:48:17.930072Z","iopub.status.idle":"2024-12-07T12:48:17.941044Z","shell.execute_reply.started":"2024-12-07T12:48:17.930029Z","shell.execute_reply":"2024-12-07T12:48:17.940274Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.942036Z","iopub.execute_input":"2024-12-07T12:48:17.942310Z","iopub.status.idle":"2024-12-07T12:48:17.952307Z","shell.execute_reply.started":"2024-12-07T12:48:17.942281Z","shell.execute_reply":"2024-12-07T12:48:17.951445Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n\n#target_modules = [\"qkv_proj\", \"proj_1\", \"proj_2\", \"out_proj\"]\n\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.953559Z","iopub.execute_input":"2024-12-07T12:48:17.953865Z","iopub.status.idle":"2024-12-07T12:48:17.963695Z","shell.execute_reply.started":"2024-12-07T12:48:17.953838Z","shell.execute_reply":"2024-12-07T12:48:17.962822Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:17.964855Z","iopub.execute_input":"2024-12-07T12:48:17.965187Z","iopub.status.idle":"2024-12-07T12:48:19.506951Z","shell.execute_reply.started":"2024-12-07T12:48:17.965159Z","shell.execute_reply":"2024-12-07T12:48:19.506018Z"}},"outputs":[{"name":"stdout","text":"trainable params: 119,734,272 || all params: 3,205,672,960 || trainable%: 3.7351\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:19.508336Z","iopub.execute_input":"2024-12-07T12:48:19.509168Z","iopub.status.idle":"2024-12-07T12:48:19.528205Z","shell.execute_reply.started":"2024-12-07T12:48:19.509124Z","shell.execute_reply":"2024-12-07T12:48:19.527279Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1818406912\nTrainable parameters : 119734272\nTrainable percentage: 6.58%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:19.529223Z","iopub.execute_input":"2024-12-07T12:48:19.529539Z","iopub.status.idle":"2024-12-07T12:48:19.536027Z","shell.execute_reply.started":"2024-12-07T12:48:19.529507Z","shell.execute_reply":"2024-12-07T12:48:19.535241Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 2\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:19.537107Z","iopub.execute_input":"2024-12-07T12:48:19.537400Z","iopub.status.idle":"2024-12-07T12:48:19.581112Z","shell.execute_reply.started":"2024-12-07T12:48:19.537371Z","shell.execute_reply":"2024-12-07T12:48:19.580160Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Dec07_12-48-19_efd4326e2c23,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:19.582461Z","iopub.execute_input":"2024-12-07T12:48:19.583341Z","iopub.status.idle":"2024-12-07T12:48:21.677168Z","shell.execute_reply.started":"2024-12-07T12:48:19.583298Z","shell.execute_reply":"2024-12-07T12:48:21.676446Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7f10ec38cf40>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T12:48:21.678338Z","iopub.execute_input":"2024-12-07T12:48:21.678722Z","iopub.status.idle":"2024-12-07T13:31:56.396765Z","shell.execute_reply.started":"2024-12-07T12:48:21.678674Z","shell.execute_reply":"2024-12-07T13:31:56.395956Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 2\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 119,734,272\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011114199355546993, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc35fc1ff1564359a7dadf6f0dc70f5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241207_124823-u2p622vl</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/u2p622vl' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/u2p622vl' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/u2p622vl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 43:21, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.620100</td>\n      <td>0.585551</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.567000</td>\n      <td>0.496538</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.481900</td>\n      <td>0.460087</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.470900</td>\n      <td>0.438544</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.436400</td>\n      <td>0.432027</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.411600</td>\n      <td>0.429567</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.425400</td>\n      <td>0.428414</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.424000</td>\n      <td>0.427821</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.420300</td>\n      <td>0.427467</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.433100</td>\n      <td>0.427421</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.4690534591674805, metrics={'train_runtime': 2614.2295, 'train_samples_per_second': 0.612, 'train_steps_per_second': 0.077, 'total_flos': 1.11117028294656e+16, 'train_loss': 0.4690534591674805, 'epoch': 0.17777777777777778})"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:31:56.398043Z","iopub.execute_input":"2024-12-07T13:31:56.398307Z","iopub.status.idle":"2024-12-07T13:33:29.291362Z","shell.execute_reply.started":"2024-12-07T13:31:56.398281Z","shell.execute_reply":"2024-12-07T13:33:29.290402Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 01:31]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.4274212121963501, 'eval_runtime': 92.8801, 'eval_samples_per_second': 2.153, 'eval_steps_per_second': 0.538, 'epoch': 0.17777777777777778}\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:29.292639Z","iopub.execute_input":"2024-12-07T13:33:29.293023Z","iopub.status.idle":"2024-12-07T13:33:32.465127Z","shell.execute_reply.started":"2024-12-07T13:33:29.292982Z","shell.execute_reply":"2024-12-07T13:33:32.464143Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 36,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 36,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_mrope\": false,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 36,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 36,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_mrope\": false,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:32.466281Z","iopub.execute_input":"2024-12-07T13:33:32.466572Z","iopub.status.idle":"2024-12-07T13:33:32.743715Z","shell.execute_reply.started":"2024-12-07T13:33:32.466533Z","shell.execute_reply":"2024-12-07T13:33:32.742788Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:32.745025Z","iopub.execute_input":"2024-12-07T13:33:32.745400Z","iopub.status.idle":"2024-12-07T13:33:32.763175Z","shell.execute_reply.started":"2024-12-07T13:33:32.745360Z","shell.execute_reply":"2024-12-07T13:33:32.762309Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:32.764199Z","iopub.execute_input":"2024-12-07T13:33:32.764467Z","iopub.status.idle":"2024-12-07T13:33:34.880891Z","shell.execute_reply.started":"2024-12-07T13:33:32.764428Z","shell.execute_reply":"2024-12-07T13:33:34.880002Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:34.881937Z","iopub.execute_input":"2024-12-07T13:33:34.882204Z","iopub.status.idle":"2024-12-07T13:33:43.337880Z","shell.execute_reply.started":"2024-12-07T13:33:34.882178Z","shell.execute_reply":"2024-12-07T13:33:43.337125Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2.5-3B\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 36,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 36,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_mrope\": false,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b/model.safetensors.index.json\nInstantiating Qwen2ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bae531aabbf24fcfa25de3099a309ac8"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-3B.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-3B/snapshots/3aab1f1954e9cc14eb9509a215f9e5ca08227a9b/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151643,\n  \"max_new_tokens\": 2048\n}\n\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 2048)\n    (layers): ModuleList(\n      (0-35): 36 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=True)\n          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=True)\n          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n          (up_proj): Linear4bit(in_features=2048, out_features=11008, bias=False)\n          (down_proj): Linear4bit(in_features=11008, out_features=2048, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:43.339307Z","iopub.execute_input":"2024-12-07T13:33:43.339758Z","iopub.status.idle":"2024-12-07T13:33:43.350934Z","shell.execute_reply.started":"2024-12-07T13:33:43.339718Z","shell.execute_reply":"2024-12-07T13:33:43.350085Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1698672640\nTrainable parameters : 311314432\nTrainable percentage: 18.33%\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:43.351909Z","iopub.execute_input":"2024-12-07T13:33:43.352159Z","iopub.status.idle":"2024-12-07T13:33:43.380287Z","shell.execute_reply.started":"2024-12-07T13:33:43.352135Z","shell.execute_reply":"2024-12-07T13:33:43.379302Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(151936, 2048)\n        (layers): ModuleList(\n          (0-35): 36 x Qwen2DecoderLayer(\n            (self_attn): Qwen2SdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): Qwen2RotaryEmbedding()\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n                  (default): Linear(in_features=64, out_features=11008, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=2048, out_features=11008, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=2048, out_features=64, bias=False)\n                  (default): Linear(in_features=2048, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=11008, bias=False)\n                  (default): Linear(in_features=64, out_features=11008, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=11008, out_features=2048, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=11008, out_features=64, bias=False)\n                  (default): Linear(in_features=11008, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=2048, bias=False)\n                  (default): Linear(in_features=64, out_features=2048, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((2048,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((2048,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:43.381471Z","iopub.execute_input":"2024-12-07T13:33:43.381782Z","iopub.status.idle":"2024-12-07T13:33:43.413650Z","shell.execute_reply.started":"2024-12-07T13:33:43.381753Z","shell.execute_reply":"2024-12-07T13:33:43.412782Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1938141184\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## 14 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:43.414652Z","iopub.execute_input":"2024-12-07T13:33:43.414905Z","iopub.status.idle":"2024-12-07T13:33:43.423107Z","shell.execute_reply.started":"2024-12-07T13:33:43.414880Z","shell.execute_reply":"2024-12-07T13:33:43.422404Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def post_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:43.423966Z","iopub.execute_input":"2024-12-07T13:33:43.424207Z","iopub.status.idle":"2024-12-07T13:33:43.434596Z","shell.execute_reply.started":"2024-12-07T13:33:43.424182Z","shell.execute_reply":"2024-12-07T13:33:43.433750Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-07T13:33:43.435638Z","iopub.execute_input":"2024-12-07T13:33:43.435891Z","iopub.status.idle":"2024-12-07T13:33:43.445221Z","shell.execute_reply.started":"2024-12-07T13:33:43.435866Z","shell.execute_reply":"2024-12-07T13:33:43.444383Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T14:34:40.354420Z","iopub.execute_input":"2024-12-07T14:34:40.355227Z","iopub.status.idle":"2024-12-07T14:35:00.526698Z","shell.execute_reply.started":"2024-12-07T14:34:40.355189Z","shell.execute_reply":"2024-12-07T14:35:00.525761Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n### Question: Minji cleans the house for 0.6 hours  |  ### Question: Minji cleans the house for 0.6 hours\nevery day. How many total hours did Minji spend     |  every day. How many total hours did Minji spend   \ncleaning the house in 3 weeks? ### Answer: Minji    |  cleaning the house in 3 weeks? ### Answer: To find\nspends 0.6 hours cleaning the house every day.      |  the total hours Minji spent cleaning the house in \nThere are 7 days in a week. So, Minji spends 0.6 *  |  3 weeks, we need to multiply the number of hours  \n7 = 4.2 hours cleaning the house every week. In 3   |  she spends cleaning each day by the number of days\nweeks, Minji spends 4.2 * 3 = 12.6 hours cleaning   |  in 3 weeks.  First, let's find the number of days \nthe house.                                          |  in 3 weeks: 3 weeks * 7 days/week = 21 days  Now, \n                                                    |  let's multiply the number of days by the number of\n                                                    |  hours she spends cleaning each day: 21 days * 0.6 \n                                                    |  hours/day = 12.6 hours  So, Minji spent a total of\n                                                    |  12.6 hours cleaning the house in 3 weeks.         \n","output_type":"stream"}],"execution_count":82},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:39:51.585732Z","iopub.execute_input":"2024-12-07T15:39:51.586602Z","iopub.status.idle":"2024-12-07T15:43:02.354452Z","shell.execute_reply.started":"2024-12-07T15:39:51.586538Z","shell.execute_reply":"2024-12-07T15:43:02.353514Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n### Question: Tony has to run several errands in a  |  ### Question: Tony has to run several errands in a\nday.  He needs to drive 10 miles to get groceries,  |  day.  He needs to drive 10 miles to get groceries,\n15 miles to get a haircut and 5 miles to go to a    |  15 miles to get a haircut and 5 miles to go to a  \ndoctor's appointment.  How many miles will Tony     |  doctor's appointment.  How many miles will Tony   \nhave driven when he is halfway through driving      |  have driven when he is halfway through driving    \naround for his errands? ### Answer: 10 + 15 + 5 =   |  around for his errands? ### Answer: 10 + 15 + 5 = \n30 miles. 30 / 2 = 15 miles. Tony will have driven  |  30 miles. 30 / 2 = 15 miles. Tony will have driven\n15 miles when he is halfway through driving around  |  15 miles when he is halfway through driving around\nfor his errands. ## 2.1.2 ### Question: A school    |  for his errands. ## 2.1.2 ### Question: A school  \nis organizing a field trip for its students. The    |  is organizing a field trip for 30 students. The   \nschool has 120 students and 10 teachers. Each bus   |  school has 5 buses available for the trip. Each   \ncan carry 40 people. How many buses does the        |  bus can carry a maximum of 10 students. How many  \nschool need to rent to transport all the students   |  buses will the school need to transport all the   \nand teachers to the field trip destination? ###     |  students? ### Answer: To transport all 30         \nAnswer: The school needs to transport 120 + 10 =    |  students, the school will need 30 / 10 = 3 buses. \n130 people. 130 / 40 = 3.25 buses. The school       |  ## 2.1.3 ### Question: A company has 100          \nneeds to rent 4 buses to transport all the          |  employees. The company wants to give each employee\nstudents and teachers to the field trip             |  a bonus of $100. How much will the company spend  \ndestination. ## 2.1.3 ### Question: A farmer has    |  on bonuses? ### Answer: The company will spend 100\n100 chickens. Each chicken lays 3 eggs per day.     |  * $100 = $10,000 on bonuses. ## 2.1.4 ###         \nHow many eggs will the farmer collect in a week?    |  Question: A recipe calls for 2 cups of flour and 1\n### Answer: The farmer collects 100 * 3 = 300 eggs  |  cup of sugar. If you want to make half of the     \nper day. The farmer collects 300 * 7 = 2100 eggs    |  recipe, how much flour and sugar do you need? ### \nin a week. ## 2.1.4 ### Question: A company has     |  Answer: To make half of the recipe, you will need \n500 employees. 20% of the employees are women. How  |  2 / 2 = 1 cup of flour and 1 / 2 = 0.5 cups of    \nmany women work at the company? ### Answer: The     |  sugar. ## 2.1.5 ### Question: A car travels 100   \ncompany has 500 * 0.2 = 100 women. ## 2.1.5 ###     |  miles in 2 hours. How many miles will the car     \nQuestion: A school has 1000 students. 40% of the    |  travel in 5 hours? ### Answer: The car will travel\nstudents are girls. How many girls are there in     |  100 / 2 = 50 miles per hour. In 5 hours, the car  \nthe school? ### Answer: The school has 1000 * 0.4   |  will travel 50 * 5 = 250 miles. ## 2.1.6 ###      \n= 400 girls. ## 2.1.6 ### Question: A school has    |  Question: A school has 100 students. The school   \n1000 students. 40% of the students are girls. How   |  wants to give each student a book. Each book costs\nmany girls are there in the school? ### Answer:     |  $10. How much will the school spend on books? ### \nThe school has 1000 * 0.4 = 400 girls. ## 2.1.7     |  Answer: The school will spend 100 * $10 = $1000 on\n### Question: A school has 1000 students. 40% of    |  books. ## 2.1.7 ### Question: A company has 100   \nthe students are girls. How many girls are there    |  employees. The company wants to give each employee\nin the school? ### Answer: The school has 1000 *    |  a bonus of $100. How much will the company spend  \n0.4 = 400 girls. ## 2.1.8 ### Question: A school    |  on bonuses? ### Answer: The company will spend 100\nhas 1000 students. 40% of the students are girls.   |  * $100 = $10,000 on bonuses. ## 2.1.8 ###         \nHow many girls are there in the school? ###         |  Question: A school has 100 students. The school   \nAnswer: The school has 1000 * 0.4 = 400 girls. ##   |  wants to give each student a book. Each book costs\n2.1.9 ### Question: A school has 1000 students.     |  $10. How much will the school spend on books? ### \n40% of the students are girls. How many girls are   |  Answer: The school will spend 100 * $10 = $1000 on\nthere in the school? ### Answer: The school has     |  books. ## 2.1.9 ### Question: A car travels 100   \n1000 * 0.4 = 400 girls. ## 2.1.10 ### Question: A   |  miles in 2 hours. How many miles will the car     \nschool has 1000 students. 40% of the students are   |  travel in 5 hours? ### Answer: The car will travel\ngirls. How many girls are there in the school? ###  |  100 / 2 = 50 miles per hour. In 5 hours, the car  \nAnswer: The school has 1000 * 0.4 = 400 girls. ##   |  will travel 50 * 5 = 250 miles. ## 2.1.10 ###     \n2.1.11 ### Question: A school has 1000 students.    |  Question: A school has 100 students. The school   \n40% of the students are girls. How many girls are   |  wants to give each student a book. Each book costs\nthere in the school? ### Answer: The school has     |  $10. How much will the school spend on books? ### \n1000 * 0.4 = 400 girls. ## 2.1.12 ### Question: A   |  Answer: The school will spend 100 * $10 = $1000 on\nschool has 1000 students. 40% of the students are   |  books. ## 2.1.11 ### Question: A company has 100  \ngirls. How many girls are there in the school? ###  |  employees. The company wants to give each employee\nAnswer: The school has 1000 * 0.4 = 400 girls. ##   |  a bonus of $100. How much will the company spend  \n2.1.13 ### Question: A school has 1000 students.    |  on bonuses? ### Answer: The company will spend 100\n40% of the students are girls. How many girls are   |  * $100 = $10,000 on bonuses. ## 2.1.12 ###        \nthere in the school? ### Answer: The school has     |  Question: A school has 100 students. The school   \n1000 * 0.4 = 400 girls. ## 2.1.14 ### Question: A   |  wants to give each student a book. Each book costs\nschool has 1000 students. 40% of the students are   |  $10. How much will the school spend on books? ### \ngirls. How many girls are there in the school? ###  |  Answer: The school will spend 100 * $10 = $1000 on\nAnswer: The school has 1000 * 0.4 = 400 girls. ##   |  books. ## 2.1.13 ### Question: A car travels 100  \n2.1.15 ### Question: A school has 1000 students.    |  miles in 2 hours. How many miles will the car     \n40% of the students are girls. How many girls are   |  travel in 5 hours? ### Answer: The car will travel\nthere in the school? ### Answer: The school has     |  100 / 2 = 50 miles per hour. In 5 hours, the car  \n1000 * 0.4 = 400 girls. ## 2.1.16                   |  will travel 50 * 5 = 250 miles. ## 2.1.14 ###     \n                                                    |  Question: A school has 100 students. The school   \n                                                    |  wants to give each student a book. Each book costs\n                                                    |  $10. How much will the school spend on books? ### \n                                                    |  Answer: The school will spend 100 * $10 = $1000   \n","output_type":"stream"}],"execution_count":141},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:30:34.349011Z","iopub.execute_input":"2024-12-07T15:30:34.349349Z","iopub.status.idle":"2024-12-07T15:30:52.620349Z","shell.execute_reply.started":"2024-12-07T15:30:34.349319Z","shell.execute_reply":"2024-12-07T15:30:52.619479Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n### Question: There are 250 kilograms (kg) of       |  ### Question: There are 250 kilograms (kg) of     \ncarrots in the supermarket and 2.5 times as many    |  carrots in the supermarket and 2.5 times as many  \ncucumbers as carrots. How many kilograms (kg) are   |  cucumbers as carrots. How many kilograms (kg) are \nthere in both carrots and cucumbers? ### Answer:    |  there in both carrots and cucumbers? ### Answer:  \nTo find the total weight of carrots and cucumbers,  |  To find the total weight of carrots and cucumbers,\nwe need to multiply the weight of carrots by the    |  we need to add the weight of carrots and the      \nnumber of cucumbers. The weight of cucumbers is     |  weight of cucumbers. The weight of cucumbers is   \n2.5 times the weight of carrots. So, the total      |  2.5 times the weight of carrots. So, the weight of\nweight of cucumbers is 250 * 2.5 = 625 kg.          |  cucumbers is 2.5 * 250 = 625 kg. The total weight \nTherefore, the total weight of carrots and          |  of carrots and cucumbers is 250 + 625 = 875 kg.   \ncucumbers is 625 + 250 = 875 kg.                    |                                                    \n","output_type":"stream"}],"execution_count":132},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T14:38:08.981121Z","iopub.execute_input":"2024-12-07T14:38:08.981392Z","iopub.status.idle":"2024-12-07T14:38:27.229537Z","shell.execute_reply.started":"2024-12-07T14:38:08.981366Z","shell.execute_reply":"2024-12-07T14:38:27.228609Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n### Question: Two tapes of the same length are      |  ### Question: Two tapes of the same length are    \nstacked together and overlapped resulting in a      |  stacked together and overlapped resulting in a    \ntotal length of 512 centimeters (cm). If the        |  total length of 512 centimeters (cm). If the      \nlength of one piece of tape is 275 centimeters      |  length of one piece of tape is 275 centimeters    \n(cm), how many centimeters (cm) is the overlap?     |  (cm), how many centimeters (cm) is the overlap?   \n### Answer: To find the overlap, we need to         |  ### Answer: To find the overlap, we need to       \nsubtract the length of one piece of tape from the   |  subtract the length of one piece of tape from the \ntotal length of the two tapes.  The total length    |  total length of the two tapes. The total length of\nof the two tapes is 512 centimeters (cm).  The      |  the two tapes is 51cv2 centimeters (cm), and the  \nlength of one piece of tape is 275 centimeters      |  length of one piece of tape is 275 centimeters    \n(cm).  To find the overlap, we subtract the length  |  (cm). Therefore, the overlap is 512 - 275 = 237   \nof one piece of tape from the total length of the   |  centimeters (cm).                                 \ntwo tapes:  512 cm - 275 cm = 237 cm.  Therefore,   |                                                    \nthe overlap is 237 centimeters (cm).                |                                                    \n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-12-07T15:57:18.855090Z","iopub.execute_input":"2024-12-07T15:57:18.855445Z","iopub.status.idle":"2024-12-07T15:59:07.688709Z","shell.execute_reply.started":"2024-12-07T15:57:18.855412Z","shell.execute_reply":"2024-12-07T15:59:07.687854Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    1698672640                     |                     1938141184                    \n================================================== | ==================================================\n### Question: Find the 20th smallest number that    |  ### Question: Find the 20th smallest number that  \nleaves a remainder of 2 when divided by 3 and a     |  leaves a remainder of 2 when divided by 3 and a   \nremainder of 5 when divided by 8. ### Answer: To    |  remainder of 5 when divided by 8. ### Answer: To  \nfind the 20th smallest number that leaves a         |  find the 20th smallest number that leaves a       \nremainder of 2 when divided by 3 and a remainder    |  remainder of 2 when divided by 3 and a remainder  \nof 5 when divided by 8, we can use the Chinese      |  of 5 when divided by 8, we can use the Chinese    \nRemainder Theorem (CRT).  First, we need to find    |  Remainder Theorem (CRT).  First, we need to find  \nthe least common multiple (LCM) of 3 and 8. The     |  the least common multiple (LCM) of 3 and 8. The   \nLCM of 3 and 8 is 24.  Next, we need to find the    |  LCM of 3 and 8 is 24.  Next, we need to find the  \n20th smallest number that leaves a remainder of 2   |  20th smallest number that leaves a remainder of 2 \nwhen divided by 3 and a remainder of 5 when         |  when divided by 3 and a remainder of 5 when       \ndivided by 8. We can use the CRT to find this       |  divided by 8. We can use the CRT to find this     \nnumber.  The CRT states that if we have two         |  number.  The CRT states that if we have two       \ncongruences:  x ≡ a (mod m) x ≡ b (mod n)  where m  |  congruences:  x ≡ a (mod m) x ≡ b (mod n)  where m\nand n are coprime, then there exists a unique       |  and n are coprime, then there exists a unique     \nsolution modulo mn.  In our case, we have:  x ≡ 2   |  solution modulo mn.  In our case, we have:  x ≡ 2 \n(mod 3) x ≡ 5 (mod 8)  We can use the CRT to find   |  (mod 3) x ≡ 5 (mod 8)  We can use the CRT to find \nthe solution:  x ≡ 2 (mod 3) x ≡ 5 (mod 8)  We can  |  the solution:  x ≡ 2 (mod 3) x ≡ 5 (mod 8)  We can\nuse the following formula to find the solution:  x  |  use the following formula to find the solution:  x\n= (a * n * (n / m) + b * m * (m / n)) / (m * n)     |  = (a * n * (n / m) + b * m * (m / n)) / (m * n)   \nwhere a and b are the remainders, m and n are the   |  where a and b are the remainders, m and n are the \nmoduli, and n / m and m / n are the inverses of m   |  moduli, and n / m and m / n are the inverses of m \nand n modulo n.  In our case, we have:  x = (2 * 8  |  and n modulo n.  In our case, we have:  x = (2 * 8\n* (8 / 3) + 5 * 3 * (3 / 8)) / (3 * 8)  x = (16 *   |  * (8 / 3) + 5 * 3 * (3 / 8)) / (3 * 8)  x = (16 * \n8 + 15 * 3) / 24  x = (128 + 45) / 24  x = 173 /    |  8 + 15 * 3) / 24  x = (128 + 45) / 24  x = 173 /  \n24  x = 7.166666666666667  Since we are looking     |  24  x = 7.166666666666667  Since we are looking   \nfor the 20th smallest number, we need to find the   |  for the 20th smallest number, we need to find the \n20th smallest number that is congruent to           |  20th smallest number that is congruent to         \n7.166666666666667 modulo 24.  The 20th smallest     |  7.166666666666667 modulo 24.  The 20th smallest   \nnumber that is congruent to 7.166666666666667       |  number that is congruent to 7.166666666666667     \nmodulo 24 is:  20 * 24 + 7.166666666666667 =        |  modulo 24 is:  20 * 24 + 7.166666666666667 =      \n487.1666666666667  Therefore, the 20th smallest     |  487.1666666666667  Therefore, the 20th smallest   \nnumber that leaves a remainder of 2 when divided    |  number that leaves a remainder of 2 when divided  \nby 3 and a remainder of 5 when divided by 8 is      |  by 3 and a remainder of 5 when divided by 8 is    \n487.1666666666667.                                  |  487.1666666666667.                                \n","output_type":"stream"}],"execution_count":153}]}