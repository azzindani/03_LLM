{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-23T23:07:58.943810Z","iopub.execute_input":"2024-11-23T23:07:58.944153Z","iopub.status.idle":"2024-11-23T23:08:48.001559Z","shell.execute_reply.started":"2024-11-23T23:07:58.944125Z","shell.execute_reply":"2024-11-23T23:08:48.000627Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-11-23T23:08:48.003414Z","iopub.execute_input":"2024-11-23T23:08:48.003683Z","iopub.status.idle":"2024-11-23T23:09:07.380733Z","shell.execute_reply.started":"2024-11-23T23:08:48.003657Z","shell.execute_reply":"2024-11-23T23:09:07.379895Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-11-23T23:09:07.382002Z","iopub.execute_input":"2024-11-23T23:09:07.382300Z","iopub.status.idle":"2024-11-23T23:09:07.388859Z","shell.execute_reply.started":"2024-11-23T23:09:07.382268Z","shell.execute_reply":"2024-11-23T23:09:07.387810Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'HuggingFaceTB/SmolLM2-135M-Instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-23T23:09:07.391400Z","iopub.execute_input":"2024-11-23T23:09:07.391790Z","iopub.status.idle":"2024-11-23T23:09:07.417482Z","shell.execute_reply.started":"2024-11-23T23:09:07.391746Z","shell.execute_reply":"2024-11-23T23:09:07.416729Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-11-23T23:09:07.418453Z","iopub.execute_input":"2024-11-23T23:09:07.418712Z","iopub.status.idle":"2024-11-23T23:09:07.428324Z","shell.execute_reply.started":"2024-11-23T23:09:07.418688Z","shell.execute_reply":"2024-11-23T23:09:07.427700Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:07.429389Z","iopub.execute_input":"2024-11-23T23:09:07.430100Z","iopub.status.idle":"2024-11-23T23:09:16.164011Z","shell.execute_reply.started":"2024-11-23T23:09:07.430054Z","shell.execute_reply":"2024-11-23T23:09:16.163051Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/861 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3284819c3af446a8999cbe12f5c8e9a"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/269M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f8c816559c94e4e8714cfc21f2142e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"954d753864154bee9afb3c27db4f3cf9"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n    (layers): ModuleList(\n      (0-29): 30 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=576, out_features=576, bias=False)\n          (k_proj): Linear4bit(in_features=576, out_features=192, bias=False)\n          (v_proj): Linear4bit(in_features=576, out_features=192, bias=False)\n          (o_proj): Linear4bit(in_features=576, out_features=576, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=576, out_features=1536, bias=False)\n          (up_proj): Linear4bit(in_features=576, out_features=1536, bias=False)\n          (down_proj): Linear4bit(in_features=1536, out_features=576, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((576,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:16.165167Z","iopub.execute_input":"2024-11-23T23:09:16.165523Z","iopub.status.idle":"2024-11-23T23:09:16.173938Z","shell.execute_reply.started":"2024-11-23T23:09:16.165478Z","shell.execute_reply":"2024-11-23T23:09:16.173084Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 81430848\nTrainable parameters : 28346688\nTrainable percentage: 34.81%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:16.174893Z","iopub.execute_input":"2024-11-23T23:09:16.175194Z","iopub.status.idle":"2024-11-23T23:09:17.208051Z","shell.execute_reply.started":"2024-11-23T23:09:16.175160Z","shell.execute_reply":"2024-11-23T23:09:17.207353Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67d4970117c5467691598dc0115ea3f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/801k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa82a3454250441eadc034ea1ce1201f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e879f552763248a093c53a53d6c2954f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2dba7aa6964d4dc791d5db2936be9450"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/655 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9d402550493468293d1b14441ad188b"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'yahma/alpaca-cleaned'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:17.209039Z","iopub.execute_input":"2024-11-23T23:09:17.209311Z","iopub.status.idle":"2024-11-23T23:09:17.213508Z","shell.execute_reply.started":"2024-11-23T23:09:17.209285Z","shell.execute_reply":"2024-11-23T23:09:17.212600Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 512","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:17.216400Z","iopub.execute_input":"2024-11-23T23:09:17.216670Z","iopub.status.idle":"2024-11-23T23:09:17.226135Z","shell.execute_reply.started":"2024-11-23T23:09:17.216645Z","shell.execute_reply":"2024-11-23T23:09:17.225465Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:17.226896Z","iopub.execute_input":"2024-11-23T23:09:17.227141Z","iopub.status.idle":"2024-11-23T23:09:19.398641Z","shell.execute_reply.started":"2024-11-23T23:09:17.227117Z","shell.execute_reply":"2024-11-23T23:09:19.397768Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/11.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b8a11f56da4ce4b76ca38b0c141387"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"alpaca_data_cleaned.json:   0%|          | 0.00/44.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6aa78df941f4060b61f105ee14c24b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb7ae3f50fb545e5a0c5d8a9ad2d8e5d"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:19.399735Z","iopub.execute_input":"2024-11-23T23:09:19.399984Z","iopub.status.idle":"2024-11-23T23:09:19.406372Z","shell.execute_reply.started":"2024-11-23T23:09:19.399958Z","shell.execute_reply":"2024-11-23T23:09:19.405529Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:19.407482Z","iopub.execute_input":"2024-11-23T23:09:19.407838Z","iopub.status.idle":"2024-11-23T23:09:19.425714Z","shell.execute_reply.started":"2024-11-23T23:09:19.407802Z","shell.execute_reply":"2024-11-23T23:09:19.424881Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:19.426780Z","iopub.execute_input":"2024-11-23T23:09:19.427031Z","iopub.status.idle":"2024-11-23T23:09:19.434645Z","shell.execute_reply.started":"2024-11-23T23:09:19.427007Z","shell.execute_reply":"2024-11-23T23:09:19.433807Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:19.435607Z","iopub.execute_input":"2024-11-23T23:09:19.435851Z","iopub.status.idle":"2024-11-23T23:09:19.445953Z","shell.execute_reply.started":"2024-11-23T23:09:19.435827Z","shell.execute_reply":"2024-11-23T23:09:19.445179Z"}},"outputs":[{"name":"stdout","text":"['output', 'input', 'instruction']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:19.446831Z","iopub.execute_input":"2024-11-23T23:09:19.447069Z","iopub.status.idle":"2024-11-23T23:09:19.458761Z","shell.execute_reply.started":"2024-11-23T23:09:19.447046Z","shell.execute_reply":"2024-11-23T23:09:19.457886Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  instruction = examples['instruction']\n  input = examples['input']\n  output = examples['output']\n  \n  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:19.459766Z","iopub.execute_input":"2024-11-23T23:09:19.460024Z","iopub.status.idle":"2024-11-23T23:09:19.469295Z","shell.execute_reply.started":"2024-11-23T23:09:19.459999Z","shell.execute_reply":"2024-11-23T23:09:19.468438Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:19.470347Z","iopub.execute_input":"2024-11-23T23:09:19.471151Z","iopub.status.idle":"2024-11-23T23:09:20.038997Z","shell.execute_reply.started":"2024-11-23T23:09:19.471111Z","shell.execute_reply":"2024-11-23T23:09:20.037934Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"557c0abd72e942fba125beb655b9a79d"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:20.040140Z","iopub.execute_input":"2024-11-23T23:09:20.040400Z","iopub.status.idle":"2024-11-23T23:09:20.046062Z","shell.execute_reply.started":"2024-11-23T23:09:20.040376Z","shell.execute_reply":"2024-11-23T23:09:20.045237Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:20.047053Z","iopub.execute_input":"2024-11-23T23:09:20.047314Z","iopub.status.idle":"2024-11-23T23:09:20.066149Z","shell.execute_reply.started":"2024-11-23T23:09:20.047289Z","shell.execute_reply":"2024-11-23T23:09:20.065341Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:20.067184Z","iopub.execute_input":"2024-11-23T23:09:20.067556Z","iopub.status.idle":"2024-11-23T23:09:28.570183Z","shell.execute_reply.started":"2024-11-23T23:09:20.067507Z","shell.execute_reply":"2024-11-23T23:09:28.569340Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4303534b895641a3936ec80c7bfdda73"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.571211Z","iopub.execute_input":"2024-11-23T23:09:28.571474Z","iopub.status.idle":"2024-11-23T23:09:28.578710Z","shell.execute_reply.started":"2024-11-23T23:09:28.571448Z","shell.execute_reply":"2024-11-23T23:09:28.577801Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.579906Z","iopub.execute_input":"2024-11-23T23:09:28.580479Z","iopub.status.idle":"2024-11-23T23:09:28.664153Z","shell.execute_reply.started":"2024-11-23T23:09:28.580440Z","shell.execute_reply":"2024-11-23T23:09:28.663293Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.665276Z","iopub.execute_input":"2024-11-23T23:09:28.665853Z","iopub.status.idle":"2024-11-23T23:09:28.673882Z","shell.execute_reply.started":"2024-11-23T23:09:28.665813Z","shell.execute_reply":"2024-11-23T23:09:28.673152Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.674743Z","iopub.execute_input":"2024-11-23T23:09:28.675004Z","iopub.status.idle":"2024-11-23T23:09:28.699076Z","shell.execute_reply.started":"2024-11-23T23:09:28.674973Z","shell.execute_reply":"2024-11-23T23:09:28.698323Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n1  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n2  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n3  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n4  [19798, 314, 354, 5785, 338, 6601, 253, 3856, ...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[19798, 314, 354, 5785, 338, 6601, 253, 3856, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.700022Z","iopub.execute_input":"2024-11-23T23:09:28.700270Z","iopub.status.idle":"2024-11-23T23:09:28.705355Z","shell.execute_reply.started":"2024-11-23T23:09:28.700246Z","shell.execute_reply":"2024-11-23T23:09:28.704589Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|im_end|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.706449Z","iopub.execute_input":"2024-11-23T23:09:28.706751Z","iopub.status.idle":"2024-11-23T23:09:28.716595Z","shell.execute_reply.started":"2024-11-23T23:09:28.706711Z","shell.execute_reply":"2024-11-23T23:09:28.715806Z"}},"outputs":[{"name":"stdout","text":"[19798, 314, 354, 5785, 338, 6601, 253, 3856, 28, 20054, 351, 354, 3007, 338, 2433, 2030, 2468, 30, 9517, 253, 2426, 338, 13674, 32873, 260, 3116, 30, 198, 198, 3757, 20880, 42, 198, 24499, 2404, 260, 1836, 8216, 284, 2669, 624, 1085, 7374, 30, 198, 198, 3757, 18100, 42, 198, 10345, 8364, 11172, 2984, 281, 253, 5724, 3180, 29323, 94, 3528, 22657, 339, 856, 441, 2827, 1062, 76, 94, 3528, 325, 582, 32779, 28, 986, 339, 9318, 76, 94, 3528, 5328, 1187, 582, 347, 1869, 347, 339, 856, 76, 94, 2068, 837, 357, 18178, 281, 260, 656, 19477, 41227, 94, 76, 94, 10039, 2637, 260, 550, 28, 347, 915, 347, 3506, 29323, 94, 3528, 1953, 4012, 260, 1365, 2766, 29323, 94, 8653, 357, 436, 42661, 284, 4146, 5777, 41227, 94, 12908, 347, 327, 338, 260, 7685, 665, 76, 94, 39855, 11742, 601, 2159, 563, 260, 1142, 29323, 94, 504, 8364, 338, 5738, 7582, 2060, 76, 94, 788, 3711, 787, 1833, 761, 5855, 5745, 2632, 23113, 94, 16912, 28, 339, 2049, 260, 808, 327, 1372, 1194, 17, 76, 94, 16075, 6040, 638, 970, 4733, 335, 288, 970, 29323, 94, 57, 4995, 1132, 585, 339, 868, 2042, 1690, 1056, 23113, 94, 76, 94, 57, 3786, 325, 8932, 451, 351, 253, 44452, 76, 94, 4449, 2942, 6399, 284, 6399, 8913, 19199, 94, 10345, 8364, 11172, 2984, 281, 253, 3180, 28, 284, 339, 1265, 76, 94, 57, 2637, 260, 582, 1181, 12581, 411, 29323, 94, 3528, 338, 553, 1135, 511, 260, 3193, 30, 198, 198, 3757, 14212, 42, 198, 504, 1085, 7374, 282, 260, 8216, 314, 260, 2979, 282, 1625, 4975, 284, 260, 1645, 282, 967, 4975, 335, 582, 506, 1029, 30, 378, 10831, 314, 5263, 351, 253, 3062, 826, 827, 9146, 284, 5354, 23046, 260, 582, 1181, 12581, 28, 527, 5354, 6146, 480, 1029, 1786, 30, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.723167Z","iopub.execute_input":"2024-11-23T23:09:28.723438Z","iopub.status.idle":"2024-11-23T23:09:28.729018Z","shell.execute_reply.started":"2024-11-23T23:09:28.723412Z","shell.execute_reply":"2024-11-23T23:09:28.728198Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.730084Z","iopub.execute_input":"2024-11-23T23:09:28.730341Z","iopub.status.idle":"2024-11-23T23:09:28.739339Z","shell.execute_reply.started":"2024-11-23T23:09:28.730317Z","shell.execute_reply":"2024-11-23T23:09:28.738617Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.740372Z","iopub.execute_input":"2024-11-23T23:09:28.740947Z","iopub.status.idle":"2024-11-23T23:09:28.749013Z","shell.execute_reply.started":"2024-11-23T23:09:28.740908Z","shell.execute_reply":"2024-11-23T23:09:28.748352Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.750081Z","iopub.execute_input":"2024-11-23T23:09:28.750666Z","iopub.status.idle":"2024-11-23T23:09:28.758930Z","shell.execute_reply.started":"2024-11-23T23:09:28.750627Z","shell.execute_reply":"2024-11-23T23:09:28.758302Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.759773Z","iopub.execute_input":"2024-11-23T23:09:28.760035Z","iopub.status.idle":"2024-11-23T23:09:28.770212Z","shell.execute_reply.started":"2024-11-23T23:09:28.760010Z","shell.execute_reply":"2024-11-23T23:09:28.769528Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:28.771236Z","iopub.execute_input":"2024-11-23T23:09:28.771585Z","iopub.status.idle":"2024-11-23T23:09:29.232713Z","shell.execute_reply.started":"2024-11-23T23:09:28.771527Z","shell.execute_reply":"2024-11-23T23:09:29.231778Z"}},"outputs":[{"name":"stdout","text":"trainable params: 19,537,920 || all params: 154,052,928 || trainable%: 12.6826\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:29.233933Z","iopub.execute_input":"2024-11-23T23:09:29.234633Z","iopub.status.idle":"2024-11-23T23:09:29.251195Z","shell.execute_reply.started":"2024-11-23T23:09:29.234594Z","shell.execute_reply":"2024-11-23T23:09:29.250384Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n    (layers): ModuleList(\n      (0-29): 30 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=576, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=576, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=192, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=192, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=576, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=576, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=1536, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=576, out_features=1536, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=576, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=576, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=576, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((576,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:29.252425Z","iopub.execute_input":"2024-11-23T23:09:29.252849Z","iopub.status.idle":"2024-11-23T23:09:29.273256Z","shell.execute_reply.started":"2024-11-23T23:09:29.252809Z","shell.execute_reply":"2024-11-23T23:09:29.272402Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 100968768\nTrainable parameters : 19537920\nTrainable percentage: 19.35%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:29.274498Z","iopub.execute_input":"2024-11-23T23:09:29.274876Z","iopub.status.idle":"2024-11-23T23:09:29.284793Z","shell.execute_reply.started":"2024-11-23T23:09:29.274838Z","shell.execute_reply":"2024-11-23T23:09:29.284012Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 2\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:29.285851Z","iopub.execute_input":"2024-11-23T23:09:29.286130Z","iopub.status.idle":"2024-11-23T23:09:29.325168Z","shell.execute_reply.started":"2024-11-23T23:09:29.286101Z","shell.execute_reply":"2024-11-23T23:09:29.324293Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov23_23-09-29_e085d4847dbc,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:29.326236Z","iopub.execute_input":"2024-11-23T23:09:29.326506Z","iopub.status.idle":"2024-11-23T23:09:30.445887Z","shell.execute_reply.started":"2024-11-23T23:09:29.326481Z","shell.execute_reply":"2024-11-23T23:09:30.445035Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7bc0d0e46080>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:09:30.446928Z","iopub.execute_input":"2024-11-23T23:09:30.447182Z","iopub.status.idle":"2024-11-23T23:21:02.656600Z","shell.execute_reply.started":"2024-11-23T23:09:30.447157Z","shell.execute_reply":"2024-11-23T23:21:02.655907Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 2\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 19,537,920\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113461199996285, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ecb68f3b97f43079368ad5b48951034"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241123_231357-2dgupx0c</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/2dgupx0c' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/2dgupx0c' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/2dgupx0c</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 07:00, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>2.209800</td>\n      <td>2.144948</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.163200</td>\n      <td>2.101492</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.056800</td>\n      <td>2.045093</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.005900</td>\n      <td>1.986312</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.968100</td>\n      <td>1.932429</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.918700</td>\n      <td>1.886240</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.897500</td>\n      <td>1.854204</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.772400</td>\n      <td>1.834269</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.820400</td>\n      <td>1.826273</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.736200</td>\n      <td>1.825030</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=1.9548969268798828, metrics={'train_runtime': 691.7683, 'train_samples_per_second': 2.313, 'train_steps_per_second': 0.289, 'total_flos': 714076795699200.0, 'train_loss': 1.9548969268798828, 'epoch': 0.17777777777777778})"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:02.657527Z","iopub.execute_input":"2024-11-23T23:21:02.657786Z","iopub.status.idle":"2024-11-23T23:21:12.265779Z","shell.execute_reply.started":"2024-11-23T23:21:02.657762Z","shell.execute_reply":"2024-11-23T23:21:12.264981Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 00:09]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 1.8250302076339722, 'eval_runtime': 9.5958, 'eval_samples_per_second': 20.842, 'eval_steps_per_second': 5.211, 'epoch': 0.17777777777777778}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:12.267066Z","iopub.execute_input":"2024-11-23T23:21:12.267742Z","iopub.status.idle":"2024-11-23T23:21:13.054341Z","shell.execute_reply.started":"2024-11-23T23:21:12.267701Z","shell.execute_reply":"2024-11-23T23:21:13.053684Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/050424aa44a9502a0e051069286a57c5fbf65710/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 576,\n  \"initializer_range\": 0.041666666666666664,\n  \"intermediate_size\": 1536,\n  \"is_llama_config\": true,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 9,\n  \"num_hidden_layers\": 30,\n  \"num_key_value_heads\": 3,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_interleaved\": false,\n  \"rope_scaling\": null,\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/050424aa44a9502a0e051069286a57c5fbf65710/config.json\nModel config LlamaConfig {\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 576,\n  \"initializer_range\": 0.041666666666666664,\n  \"intermediate_size\": 1536,\n  \"is_llama_config\": true,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 9,\n  \"num_hidden_layers\": 30,\n  \"num_key_value_heads\": 3,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_interleaved\": false,\n  \"rope_scaling\": null,\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:13.055333Z","iopub.execute_input":"2024-11-23T23:21:13.055581Z","iopub.status.idle":"2024-11-23T23:21:13.184949Z","shell.execute_reply.started":"2024-11-23T23:21:13.055536Z","shell.execute_reply":"2024-11-23T23:21:13.183944Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:13.186050Z","iopub.execute_input":"2024-11-23T23:21:13.186313Z","iopub.status.idle":"2024-11-23T23:21:13.197042Z","shell.execute_reply.started":"2024-11-23T23:21:13.186286Z","shell.execute_reply":"2024-11-23T23:21:13.196368Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:13.198198Z","iopub.execute_input":"2024-11-23T23:21:13.198520Z","iopub.status.idle":"2024-11-23T23:21:13.754355Z","shell.execute_reply.started":"2024-11-23T23:21:13.198484Z","shell.execute_reply":"2024-11-23T23:21:13.753630Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:13.755463Z","iopub.execute_input":"2024-11-23T23:21:13.755824Z","iopub.status.idle":"2024-11-23T23:21:15.092396Z","shell.execute_reply.started":"2024-11-23T23:21:13.755785Z","shell.execute_reply":"2024-11-23T23:21:15.091590Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/050424aa44a9502a0e051069286a57c5fbf65710/config.json\nModel config LlamaConfig {\n  \"_name_or_path\": \"HuggingFaceTB/SmolLM2-135M-Instruct\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"head_dim\": 64,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 576,\n  \"initializer_range\": 0.041666666666666664,\n  \"intermediate_size\": 1536,\n  \"is_llama_config\": true,\n  \"max_position_embeddings\": 8192,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 9,\n  \"num_hidden_layers\": 30,\n  \"num_key_value_heads\": 3,\n  \"pad_token_id\": 2,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_interleaved\": false,\n  \"rope_scaling\": null,\n  \"rope_theta\": 100000,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers.js_config\": {\n    \"kv_cache_dtype\": {\n      \"fp16\": \"float16\",\n      \"q4f16\": \"float16\"\n    }\n  },\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"vocab_size\": 49152\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/050424aa44a9502a0e051069286a57c5fbf65710/model.safetensors\nInstantiating LlamaForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"pad_token_id\": 2\n}\n\nAll model checkpoint weights were used when initializing LlamaForCausalLM.\n\nAll the weights of LlamaForCausalLM were initialized from the model checkpoint at HuggingFaceTB/SmolLM2-135M-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--HuggingFaceTB--SmolLM2-135M-Instruct/snapshots/050424aa44a9502a0e051069286a57c5fbf65710/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"pad_token_id\": 2\n}\n\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"LlamaForCausalLM(\n  (model): LlamaModel(\n    (embed_tokens): Embedding(49152, 576, padding_idx=2)\n    (layers): ModuleList(\n      (0-29): 30 x LlamaDecoderLayer(\n        (self_attn): LlamaSdpaAttention(\n          (q_proj): Linear4bit(in_features=576, out_features=576, bias=False)\n          (k_proj): Linear4bit(in_features=576, out_features=192, bias=False)\n          (v_proj): Linear4bit(in_features=576, out_features=192, bias=False)\n          (o_proj): Linear4bit(in_features=576, out_features=576, bias=False)\n          (rotary_emb): LlamaRotaryEmbedding()\n        )\n        (mlp): LlamaMLP(\n          (gate_proj): Linear4bit(in_features=576, out_features=1536, bias=False)\n          (up_proj): Linear4bit(in_features=576, out_features=1536, bias=False)\n          (down_proj): Linear4bit(in_features=1536, out_features=576, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n        (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n      )\n    )\n    (norm): LlamaRMSNorm((576,), eps=1e-05)\n    (rotary_emb): LlamaRotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:15.093365Z","iopub.execute_input":"2024-11-23T23:21:15.093608Z","iopub.status.idle":"2024-11-23T23:21:15.103444Z","shell.execute_reply.started":"2024-11-23T23:21:15.093584Z","shell.execute_reply":"2024-11-23T23:21:15.102699Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 81430848\nTrainable parameters : 28346688\nTrainable percentage: 34.81%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:15.104510Z","iopub.execute_input":"2024-11-23T23:21:15.104875Z","iopub.status.idle":"2024-11-23T23:21:15.133370Z","shell.execute_reply.started":"2024-11-23T23:21:15.104838Z","shell.execute_reply":"2024-11-23T23:21:15.132613Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): LlamaForCausalLM(\n      (model): LlamaModel(\n        (embed_tokens): Embedding(49152, 576, padding_idx=2)\n        (layers): ModuleList(\n          (0-29): 30 x LlamaDecoderLayer(\n            (self_attn): LlamaSdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=576, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=576, bias=False)\n                  (default): Linear(in_features=64, out_features=576, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=192, bias=False)\n                  (default): Linear(in_features=64, out_features=192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=192, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=192, bias=False)\n                  (default): Linear(in_features=64, out_features=192, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=576, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=576, bias=False)\n                  (default): Linear(in_features=64, out_features=576, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): LlamaRotaryEmbedding()\n            )\n            (mlp): LlamaMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=576, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=576, out_features=64, bias=False)\n                  (default): Linear(in_features=576, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=576, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=576, bias=False)\n                  (default): Linear(in_features=64, out_features=576, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n            (post_attention_layernorm): LlamaRMSNorm((576,), eps=1e-05)\n          )\n        )\n        (norm): LlamaRMSNorm((576,), eps=1e-05)\n        (rotary_emb): LlamaRotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=576, out_features=49152, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:15.134343Z","iopub.execute_input":"2024-11-23T23:21:15.134622Z","iopub.status.idle":"2024-11-23T23:21:15.159846Z","shell.execute_reply.started":"2024-11-23T23:21:15.134560Z","shell.execute_reply":"2024-11-23T23:21:15.159036Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 120506688\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## 14 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt, inputs):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      inputs,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:15.161070Z","iopub.execute_input":"2024-11-23T23:21:15.161747Z","iopub.status.idle":"2024-11-23T23:21:15.170546Z","shell.execute_reply.started":"2024-11-23T23:21:15.161705Z","shell.execute_reply":"2024-11-23T23:21:15.169840Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def post_assistant(prompt, inputs):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      inputs,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:15.171586Z","iopub.execute_input":"2024-11-23T23:21:15.171925Z","iopub.status.idle":"2024-11-23T23:21:15.183451Z","shell.execute_reply.started":"2024-11-23T23:21:15.171884Z","shell.execute_reply":"2024-11-23T23:21:15.182503Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:21:15.184392Z","iopub.execute_input":"2024-11-23T23:21:15.184681Z","iopub.status.idle":"2024-11-23T23:21:15.194195Z","shell.execute_reply.started":"2024-11-23T23:21:15.184640Z","shell.execute_reply":"2024-11-23T23:21:15.193579Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:11:41.893918Z","iopub.execute_input":"2024-11-24T00:11:41.894627Z","iopub.status.idle":"2024-11-24T00:13:12.027442Z","shell.execute_reply.started":"2024-11-24T00:11:41.894589Z","shell.execute_reply":"2024-11-24T00:13:12.026615Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Explain    |  completes the request.  ### Instruction: Explain  \nthe concept of a fully connected network.  ###      |  the concept of a fully connected network.  ###    \nInput:   ### Response: A fully connected network    |  Input:   ### Response: A fully connected network  \nis a type of artificial neural network that         |  is a type of artificial neural network that       \ncombines multiple layers of neurons to learn        |  combines multiple layers of neurons to learn      \ncomplex patterns in data. It consists of a set of   |  complex patterns in data. It consists of a set of \nnodes or neurons, each connected to the others      |  nodes or neurons, each connected to the others    \nthrough a set of connections or links, which are    |  through a set of connections or links, which are  \nused to represent the relationships between the     |  used to represent the relationships between the   \nnodes. Each node is connected to all the nodes in   |  nodes. Each node is connected to all other nodes, \nthe network, and each connection is connected to    |  and the connections are used to represent the     \nall the nodes in the nodes.  ### Output:  A fully   |  relationships between the nodes and the nodes and \nconnected network is a type of artificial neural    |  the connections between the nodes and the nodes.  \nnetwork that combines multiple layers of neurons    |  ### Output:  A fully connected network is a type  \nto learn complex patterns in data. It consists of   |  of artificial neural network that combines        \na set of nodes or neurons, each connected to the    |  multiple layers of neurons to learn complex       \nothers through a set of connections or links,       |  patterns in data. It consists of a set of nodes or\nwhich are used to represent the relationships       |  neurons, each connected to the others through a   \nbetween the nodes. Each node is connected to all    |  set of connections or links, which are used to    \nthe nodes in the network, and each connection is    |  represent the relationships between the nodes and \nconnected to all the nodes in the nodes.  ###       |  the nodes and the connections between the nodes   \nExplanation:  A fully connected network is a type   |  and the nodes. Each node is connected to all other\nof artificial neural network that combines          |  nodes, and the connections are used to represent  \nmultiple layers of neurons to learn complex         |  the relationships between the nodes and the nodes \npatterns in data. It consists of a set of nodes or  |  and the connections between the nodes and the     \nneurons, each connected to the others through a     |  nodes.                                            \nset of connections or links, which are used to      |                                                    \nrepresent the relationships between the nodes.      |                                                    \nEach node is connected to all the nodes in the      |                                                    \nnetwork, and each connection is connected to all    |                                                    \nthe nodes in the nodes.  ### Output:  A fully       |                                                    \nconnected network is a type of artificial neural    |                                                    \nnetwork that combines multiple layers of neurons    |                                                    \nto learn complex patterns in data. It consists of   |                                                    \na set of nodes or neurons, each connected to the    |                                                    \nothers through a set of connections or links,       |                                                    \nwhich are used to represent the relationships       |                                                    \nbetween the nodes. Each node is connected to all    |                                                    \nthe nodes in the network, and each connection is    |                                                    \nconnected to all the nodes in the nodes.  ###       |                                                    \nExplanation:  A fully connected network is a type   |                                                    \nof artificial neural network that combines          |                                                    \nmultiple layers of neurons to learn complex         |                                                    \npatterns in data. It consists of a set of nodes or  |                                                    \nneurons, each connected to the others through a     |                                                    \nset of connections or links, which are used to      |                                                    \nrepresent the relationships between the nodes.      |                                                    \nEach node is connected to all the nodes in the      |                                                    \nnetwork, and each connection is connected to all    |                                                    \nthe nodes in the nodes.  ### Output:  A fully       |                                                    \nconnected network is a type of artificial neural    |                                                    \nnetwork that combines multiple layers of neurons    |                                                    \nto learn complex patterns in data. It consists of   |                                                    \na set of nodes or neurons, each connected to the    |                                                    \nothers through a set of connections or links,       |                                                    \nwhich are used to represent the relationships       |                                                    \nbetween the nodes. Each node is connected to all    |                                                    \nthe nodes in the network, and each connection is    |                                                    \nconnected to all the nodes in the nodes.  ###       |                                                    \nExplanation:  A fully connected network is a type   |                                                    \nof artificial neural network that combines          |                                                    \nmultiple layers of neurons to learn complex         |                                                    \npatterns in data. It consists of a set of nodes or  |                                                    \nneurons, each connected to the others through a     |                                                    \nset of connections or links, which are used to      |                                                    \nrepresent the relationships between the nodes.      |                                                    \nEach node is connected to all the nodes in the      |                                                    \nnetwork, and each connection is connected to all    |                                                    \nthe nodes in the nodes.  ### Output:  A fully       |                                                    \nconnected network is a type of artificial neural    |                                                    \nnetwork that combines multiple layers of neurons    |                                                    \nto learn complex patterns in data. It consists of   |                                                    \na set of nodes or neurons, each connected to the    |                                                    \nothers through a set of connections or links,       |                                                    \nwhich are used to represent the relationships       |                                                    \nbetween the nodes. Each node is connected to all    |                                                    \nthe nodes in the network, and each connection is    |                                                    \nconnected to all the nodes in the nodes.  ###       |                                                    \nExplanation:  A fully connected network is a type   |                                                    \nof artificial neural network that combines          |                                                    \nmultiple layers of neurons to learn complex         |                                                    \npatterns in data. It consists of a set of nodes or  |                                                    \nneurons, each connected to the others through a     |                                                    \nset of connections or links, which are used to      |                                                    \nrepresent the relationships between the nodes.      |                                                    \nEach node is connected to all the nodes in the      |                                                    \nnetwork, and each connection is connected to all    |                                                    \nthe nodes in the nodes.  ### Output:  A fully       |                                                    \nconnected network is a type of artificial neural    |                                                    \nnetwork that combines multiple layers of neurons    |                                                    \nto learn complex patterns in data. It consists of   |                                                    \na set of nodes or neurons, each connected to the    |                                                    \nothers through a set of connections or links,       |                                                    \nwhich are used to represent the relationships       |                                                    \nbetween the nodes. Each node is connected to all    |                                                    \nthe nodes in the network, and each connection is    |                                                    \nconnected to all the nodes in the nodes.  ###       |                                                    \nExplanation:  A fully connected network is a type   |                                                    \nof artificial neural network that combines          |                                                    \nmultiple layers of neurons to learn complex         |                                                    \npatterns in data. It consists of a set of nodes or  |                                                    \nneurons, each connected to the others through a     |                                                    \nset of connections or links, which are used to      |                                                    \nrepresent the relationships between the nodes.      |                                                    \nEach node is connected to all the nodes in the      |                                                    \nnetwork, and each connection is connected to all    |                                                    \nthe nodes in the nodes.  ### Output:  A fully       |                                                    \nconnected network is a type of artificial neural    |                                                    \nnetwork that combines multiple layers of neurons    |                                                    \nto learn complex patterns in data. It consists of   |                                                    \na set of nodes or neurons,                          |                                                    \n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:19:04.170156Z","iopub.execute_input":"2024-11-24T00:19:04.170488Z","iopub.status.idle":"2024-11-24T00:20:44.842125Z","shell.execute_reply.started":"2024-11-24T00:19:04.170460Z","shell.execute_reply":"2024-11-24T00:20:44.841288Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Name 3     |  completes the request.  ### Instruction: Name 3   \nelements that are characteristics of a well-        |  elements that are characteristics of a well-      \nstructured essay.  ### Input:   ### Response:  The  |  structured essay.  ### Input:   ### Response:  The\nfirst element of a well-structured essay is a       |  first element of a well-structured essay is a     \nclear topic sentence that introduces the main idea  |  clear topic sentence that introduces the main idea\nor thesis of the essay. This sentence should be     |  or thesis of the essay. This sentence should be   \nconcise and focused, providing a roadmap for the    |  concise and focused, providing a roadmap for the  \nrest of the essay.  The second element of a well-   |  rest of the essay.  The second element of a well- \nstructured essay is a topic sentence that provides  |  structured essay is a topic sentence that provides\nevidence or supporting details to support the main  |  evidence or supporting details to support the main\nidea of the essay. This sentence should be          |  idea of the essay. This sentence should be        \nspecific, providing concrete examples or examples   |  specific, providing concrete examples or examples \nthat demonstrate the main idea.  The third element  |  that demonstrate the main idea.  The third element\nof a well-structured essay is a conclusion that     |  of a well-structured essay is a conclusion that   \nsummarizes the main idea of the essay and           |  summarizes the main idea of the essay and         \nreiterates the main idea of the thesis. This        |  reiterates the main idea of the thesis. This      \nsentence should be concise and focused, providing   |  sentence should be concise and focused, providing \na final thought or reflection that leaves the       |  a final thought or reflection that leaves the     \nreader with a lasting impression.  In a well-       |  reader with a lasting impression.  In a well-     \nstructured essay, the use of transitional words     |  structured essay, the use of transitional words   \nand phrases helps to connect the different          |  and phrases helps to connect the different        \nelements of the essay, creating a cohesive and      |  elements of the essay, creating a cohesive and    \nflowing narrative. This is achieved by using words  |  flowing narrative. This is achieved by using words\nand phrases that indicate the relationship between  |  and phrases that indicate the relationship between\nthe different elements of the essay, such as        |  the different elements of the essay, such as      \n\"however,\" \"in addition,\" \"meanwhile,\" and          |  \"however,\" \"in addition,\" \"meanwhile,\" and        \n\"furthermore.\"  In a well-structured essay, the     |  \"furthermore.\"  In a well-structured essay, the   \nuse of active voice and varied sentence structures  |  use of active voice and varied sentence structures\nhelps to create a dynamic and engaging narrative.   |  helps to create a dynamic and engaging narrative. \nThis is achieved by using active voice, where the   |  This is achieved by using active voice, where the \nsubject of the sentence is performing the action,   |  subject of the sentence is performing the action, \nand varied sentence structures, where different     |  and varied sentence structures, where different   \nsentence structures are used to create a variety    |  sentence structures are used to create a variety  \nof effects.  In a well-structured essay, the use    |  of effects.  In a well-structured essay, the use  \nof a clear thesis statement helps to guide the      |  of transitions and connections between different  \nreader through the essay, providing a roadmap for   |  elements helps to create a cohesive and flowing   \nthe reader to follow. This is achieved by using a   |  narrative, and the use of active voice and varied \nclear thesis statement, which is specific,          |  sentence structures helps to create a dynamic and \nproviding concrete examples or examples that        |  engaging narrative.                               \ndemonstrate the main idea of the thesis.  In a      |                                                    \nwell-structured essay, the use of a conclusion      |                                                    \nhelps to summarize the main idea of the essay and   |                                                    \nreiterates the main idea of the thesis. This is     |                                                    \nachieved by using a conclusion, which is concise    |                                                    \nand focused, providing a final thought or           |                                                    \nreflection that leaves the reader with a lasting    |                                                    \nimpression.  In a well-structured essay, the use    |                                                    \nof a conclusion helps to create a lasting           |                                                    \nimpression on the reader, providing a lasting       |                                                    \nimpression that leaves the reader with a lasting    |                                                    \nimpression. This is achieved by using a             |                                                    \nconclusion, which is concise and focused,           |                                                    \nproviding a final thought or reflection that        |                                                    \nleaves the reader with a lasting impression.  In a  |                                                    \nwell-structured essay, the use of a conclusion      |                                                    \nhelps to create a lasting impression on the         |                                                    \nreader, providing a lasting impression that leaves  |                                                    \nthe reader with a lasting impression. This is       |                                                    \nachieved by using a conclusion, which is concise    |                                                    \nand focused, providing a final thought or           |                                                    \nreflection that leaves the reader with a lasting    |                                                    \nimpression.  In a well-structured essay, the use    |                                                    \nof a conclusion helps to create a lasting           |                                                    \nimpression on the reader, providing a lasting       |                                                    \nimpression that leaves the reader with a lasting    |                                                    \nimpression. This is achieved by using a             |                                                    \nconclusion, which is concise and focused,           |                                                    \nproviding a final thought or reflection that        |                                                    \nleaves the reader with a lasting impression.  In a  |                                                    \nwell-structured essay, the use of a conclusion      |                                                    \nhelps to create a lasting impression on the         |                                                    \nreader, providing a lasting impression that leaves  |                                                    \nthe reader with a lasting impression. This is       |                                                    \nachieved by using a conclusion, which is concise    |                                                    \nand focused, providing a final thought or           |                                                    \nreflection that leaves the reader with a lasting    |                                                    \nimpression.  In a well-structured essay, the use    |                                                    \nof a conclusion helps to create a lasting           |                                                    \nimpression on the reader, providing a lasting       |                                                    \nimpression that leaves the reader with a lasting    |                                                    \nimpression. This is achieved by using a             |                                                    \nconclusion, which is concise and focused,           |                                                    \nproviding a final thought or reflection that        |                                                    \nleaves the reader with a lasting impression.  In a  |                                                    \nwell-structured essay, the use of a conclusion      |                                                    \nhelps to create a lasting impression on the         |                                                    \nreader, providing a lasting impression that leaves  |                                                    \nthe reader with a lasting impression. This is       |                                                    \nachieved by using a conclusion, which is concise    |                                                    \nand focused, providing a final thought or           |                                                    \nreflection that leaves the reader with a lasting    |                                                    \nimpression.  In a well-structured essay, the use    |                                                    \nof a conclusion helps to create a lasting           |                                                    \nimpression on the reader, providing a lasting       |                                                    \nimpression that leaves the reader with a lasting    |                                                    \nimpression. This is achieved by using a             |                                                    \nconclusion, which is concise and focused,           |                                                    \nproviding a final thought or reflection that        |                                                    \nleaves the reader with a lasting impression.  In a  |                                                    \nwell-structured essay, the use of a conclusion      |                                                    \nhelps to create a lasting impression on the         |                                                    \nreader, providing a lasting impression that leaves  |                                                    \nthe reader with a lasting impression. This is       |                                                    \nachieved by using a conclusion, which is concise    |                                                    \nand focused, providing a final thought or           |                                                    \nreflection that leaves the reader with a lasting    |                                                    \nimpression.  In a well-structured essay, the use    |                                                    \nof a conclusion helps to create a lasting           |                                                    \nimpression on the reader, providing a lasting       |                                                    \nimpression that leaves the reader with a lasting    |                                                    \nimpression. This is achieved by using a             |                                                    \nconclusion, which is concise and focused,           |                                                    \nproviding a final thought or reflection that        |                                                    \nleaves the reader with a lasting impression.  In a  |                                                    \nwell-structured essay, the use of a conclusion      |                                                    \nhelps to create a lasting impression on the         |                                                    \nreader,                                             |                                                    \n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T00:50:00.525265Z","iopub.execute_input":"2024-11-24T00:50:00.526062Z","iopub.status.idle":"2024-11-24T00:50:12.044330Z","shell.execute_reply.started":"2024-11-24T00:50:00.526028Z","shell.execute_reply":"2024-11-24T00:50:12.043410Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Provide a  |  completes the request.  ### Instruction: Provide a\nsuitable title  ### Input: This is a report on the  |  suitable title  ### Input: This is a report on the\npotential benefits of implementing renewable        |  potential benefits of implementing renewable      \nenergy  ### Response: The report highlights the     |  energy  ### Response: The report on renewable     \nimportance of renewable energy in reducing          |  energy is a comprehensive overview of the benefits\ngreenhouse gas emissions and promoting a more       |  and challenges associated with this sector. It    \nsustainable future. It also explores the various    |  provides detailed information on the various forms\nways in which renewable energy can contribute to    |  of renewable energy sources, their environmental  \nthis goal.                                          |  impact, and their role in reducing greenhouse gas \n                                                    |  emissions and mitigating climate change. The      \n                                                    |  report also highlights the opportunities and      \n                                                    |  challenges of transitioning to a more sustainable \n                                                    |  energy mix, including the role of government      \n                                                    |  policies and incentives, and the impact on local  \n                                                    |  communities and the environment.                  \n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-11-23T23:30:00.240294Z","iopub.execute_input":"2024-11-23T23:30:00.241005Z","iopub.status.idle":"2024-11-23T23:30:06.032765Z","shell.execute_reply.started":"2024-11-23T23:30:00.240963Z","shell.execute_reply":"2024-11-23T23:30:06.031911Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: In the     |  completes the request.  ### Instruction: In the   \nsentence below, identify the part of speech for     |  sentence below, identify the part of speech for   \neach word.  ### Input: He quickly dashed across     |  each word.  ### Input: He quickly dashed across   \nthe street.  ### Response: The word \"quick\" is an   |  the street.  ### Response: The word \"quick\" is an \nadjective, which describes the action of the        |  adjective, which describes the action of the      \nperson who is doing the action.  ### Output: The    |  person who is doing the action.                   \nword \"quick\" is an adjective, which describes the   |                                                    \naction of the person who is doing the action.       |                                                    \n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninputs = dataset[loc]['input']\npre_text = pre_assistant(prompt, inputs)\npost_text = post_assistant(prompt, inputs)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T01:05:02.287429Z","iopub.execute_input":"2024-11-24T01:05:02.288282Z","iopub.status.idle":"2024-11-24T01:07:59.463240Z","shell.execute_reply.started":"2024-11-24T01:05:02.288246Z","shell.execute_reply":"2024-11-24T01:07:59.462338Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                     81430848                      |                     120506688                     \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Compose a  |  completes the request.  ### Instruction: Compose a\npoem on the theme of autumn.  ### Input:   ###      |  poem on the theme of autumn.  ### Input:   ###    \nResponse:  The poem \"The Autumn Leaves\" is a        |  Response:  The poem \"The Autumn Leaves\" is a      \nbeautiful piece that captures the essence of the    |  beautiful piece that captures the essence of the  \nseason. It's a simple yet powerful piece that       |  season. It's a simple yet powerful piece that     \ncaptures the changing colors of the leaves in a     |  captures the changing colors of the leaves in a   \nway that's both beautiful and haunting. The poem    |  way that's both beautiful and haunting. The poem  \nis a bit of a slow-burning, slow-burning piece      |  is a bit of a slow-burning, slow-burning piece    \nthat's meant to be read slowly and deeply. It's a   |  that's meant to be read slowly and deeply.  The   \npiece that's meant to be read aloud, and it's       |  poem is written in a simple, yet beautiful style  \nmeant to be read aloud.  The poem is written in a   |  that's meant to be read slowly and deeply. It's   \nway that's meant to be read aloud, with a slow,     |  written in a way that's meant to be read slowly   \nslow, slow pace that's meant to be read aloud.      |  and deeply, with a focus on the emotional and     \nIt's meant to be read aloud, with a slow, slow      |  sensory aspects of the poem. The poem is written  \npace that's meant to be read aloud. It's meant to   |  in a way that's meant to be read slowly and       \nbe read aloud, with a slow, slow pace that's meant  |  deeply, with a focus on the emotional and sensory \nto be read aloud. It's meant to be read aloud,      |  aspects of the poem.  The poem is written in a way\nwith a slow, slow pace that's meant to be read      |  that's meant to be read slowly and deeply, with a \naloud. It's meant to be read aloud, with a slow,    |  focus on the emotional and sensory aspects of the \nslow pace that's meant to be read aloud. It's       |  poem. It's written in a way that's meant to be    \nmeant to be read aloud, with a slow, slow pace      |  read slowly and deeply, with a focus on the       \nthat's meant to be read aloud. It's meant to be     |  emotional and sensory aspects of the poem. It's   \nread aloud, with a slow, slow pace that's meant to  |  written in a way that's meant to be read slowly   \nbe read aloud. It's meant to be read aloud, with a  |  and deeply, with a focus on the emotional and     \nslow, slow pace that's meant to be read aloud.      |  sensory aspects of the poem. It's written in a way\nIt's meant to be read aloud, with a slow, slow      |  that's meant to be read slowly and deeply, with a \npace that's meant to be read aloud. It's meant to   |  focus on the emotional and sensory aspects of the \nbe read aloud, with a slow, slow pace that's meant  |  poem. It's written in a way that's meant to be    \nto be read aloud. It's meant to be read aloud,      |  read slowly and deeply, with a focus on the       \nwith a slow, slow pace that's meant to be read      |  emotional and sensory aspects of the poem. It's   \naloud. It's meant to be read aloud, with a slow,    |  written in a way that's meant to be read slowly   \nslow pace that's meant to be read aloud. It's       |  and deeply, with a focus on the emotional and     \nmeant to be read aloud, with a slow, slow pace      |  sensory aspects of the poem. It's written in a way\nthat's meant to be read aloud. It's meant to be     |  that's meant to be read slowly and deeply, with a \nread aloud, with a slow, slow pace that's meant to  |  focus on the emotional and sensory aspects of the \nbe read aloud. It's meant to be read aloud, with a  |  poem. It's written in a way that's meant to be    \nslow, slow pace that's meant to be read aloud.      |  read slowly and deeply, with a focus on the       \nIt's meant to be read aloud, with a slow, slow      |  emotional and sensory aspects of the poem. It's   \npace that's meant to be read aloud. It's meant to   |  written in a way that's meant to be read slowly   \nbe read aloud, with a slow, slow pace that's meant  |  and deeply, with a focus on the emotional and     \nto be read aloud. It's meant to be read aloud,      |  sensory aspects of the poem. It's written in a way\nwith a slow, slow pace that's meant to be read      |  that's meant to be read slowly and deeply, with a \naloud. It's meant to be read aloud, with a slow,    |  focus on the emotional and sensory aspects of the \nslow pace that's meant to be read aloud. It's       |  poem. It's written in a way that's meant to be    \nmeant to be read aloud, with a slow, slow pace      |  read slowly and deeply, with a focus on the       \nthat's meant to be read aloud. It's meant to be     |  emotional and sensory aspects of the poem. It's   \nread aloud, with a slow, slow pace that's meant to  |  written in a way that's meant to be read slowly   \nbe read aloud. It's meant to be read aloud, with a  |  and deeply, with a focus on the emotional and     \nslow, slow pace that's meant to be read aloud.      |  sensory aspects of the poem. It's written in a way\nIt's meant to be read aloud, with a slow, slow      |  that's meant to be read slowly and deeply, with a \npace that's meant to be read aloud. It's meant to   |  focus on the emotional and sensory aspects of the \nbe read aloud, with a slow, slow pace that's meant  |  poem. It's written in a way that's meant to be    \nto be read aloud. It's meant to be read aloud,      |  read slowly and deeply, with a focus on the       \nwith a slow, slow pace that's meant to be read      |  emotional and sensory aspects of the poem. It's   \naloud. It's meant to be read aloud, with a slow,    |  written in a way that's meant to be read slowly   \nslow pace that's meant to be read aloud. It's       |  and deeply, with a focus on the emotional and     \nmeant to be read aloud, with a slow, slow pace      |  sensory aspects of the poem. It's written in a way\nthat's meant to be read aloud. It's meant to be     |  that's meant to be read slowly and deeply, with a \nread aloud, with a slow, slow pace that's meant to  |  focus on the emotional and sensory aspects of the \nbe read aloud. It's meant to be read aloud, with a  |  poem. It's written in a way that's meant to be    \nslow, slow pace that's meant to be read aloud.      |  read slowly and deeply, with a focus on the       \nIt's meant to be read aloud, with a slow, slow      |  emotional and sensory aspects of the poem. It's   \npace that's meant to be read aloud. It's meant to   |  written in a way that's meant to be read slowly   \nbe read aloud, with a slow, slow pace that's meant  |  and deeply, with a focus on the emotional and     \nto be read aloud. It's meant to be read aloud,      |  sensory aspects of the poem. It's written in a way\nwith a slow, slow pace that's meant to be read      |  that's meant to be read slowly and deeply, with a \naloud. It's meant to be read aloud, with a slow,    |  focus on the emotional and sensory aspects of the \nslow pace that's meant to be read aloud. It's       |  poem. It's written in a way that's meant to be    \nmeant to be read aloud, with a slow, slow pace      |  read slowly and deeply, with a focus on the       \nthat's meant to be read aloud. It's meant to be     |  emotional and sensory aspects of the poem. It's   \nread aloud, with a slow, slow pace that's meant to  |  written in a way that's meant to be read slowly   \nbe read aloud. It's meant to be read aloud, with a  |  and deeply, with a focus on the emotional and     \nslow, slow pace that's meant to be read aloud.      |  sensory aspects of the poem. It's written in a way\nIt's meant to be read aloud, with a slow, slow      |  that's meant to be read slowly and deeply, with a \npace that's meant to be read aloud. It's meant to   |  focus on the emotional and sensory aspects of the \nbe read aloud, with a slow, slow pace that's meant  |  poem. It's written in a way that's meant to be    \nto be read aloud. It's meant to be read aloud,      |  read slowly and deeply, with a focus on the       \nwith a slow, slow pace that's meant to be read      |  emotional and sensory aspects of the poem. It's   \naloud. It's meant to be read aloud, with a slow,    |  written in a way that's meant to be read slowly   \nslow pace that's meant to be read aloud. It's       |  and deeply, with a focus on the emotional and     \nmeant to be read aloud, with a slow, slow pace      |  sensory aspects of the poem. It's written in a way\nthat's meant to be read aloud. It's meant to be     |  that's meant to be read slowly and deeply, with a \nread aloud, with a slow, slow pace that's meant to  |  focus on the emotional and sensory aspects of the \nbe read                                             |  poem. It's written in a way that's meant to be    \n                                                    |  read slowly and deeply, with a focus on the       \n                                                    |  emotional and sensory aspects of the poem. It's   \n                                                    |  written in a way that's meant to be read slowly   \n                                                    |  and deeply, with a focus on the emotional and     \n                                                    |  sensory aspects of the poem. It's written in a way\n                                                    |  that's meant to be read slowly and deeply, with a \n                                                    |  focus on the emotional and sensory aspects of the \n                                                    |  poem. It's written in a way that's meant to be    \n                                                    |  read slowly and deeply, with a focus on the       \n                                                    |  emotional and sensory aspects of the poem. It's   \n                                                    |  written in a way that's meant to be read slowly   \n                                                    |  and deeply, with a focus on the emotional and     \n                                                    |  sensory aspects of the poem                       \n","output_type":"stream"}],"execution_count":80}]}