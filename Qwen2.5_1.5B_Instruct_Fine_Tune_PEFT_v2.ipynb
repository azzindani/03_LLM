{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"#!pip install --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-22T12:35:22.762693Z","iopub.execute_input":"2024-11-22T12:35:22.763063Z","iopub.status.idle":"2024-11-22T12:35:55.561321Z","shell.execute_reply.started":"2024-11-22T12:35:22.763021Z","shell.execute_reply":"2024-11-22T12:35:55.560050Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-11-22T12:35:55.563317Z","iopub.execute_input":"2024-11-22T12:35:55.563644Z","iopub.status.idle":"2024-11-22T12:36:02.535876Z","shell.execute_reply.started":"2024-11-22T12:35:55.563614Z","shell.execute_reply":"2024-11-22T12:36:02.534896Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-11-22T12:36:02.536940Z","iopub.execute_input":"2024-11-22T12:36:02.537187Z","iopub.status.idle":"2024-11-22T12:36:02.543831Z","shell.execute_reply.started":"2024-11-22T12:36:02.537162Z","shell.execute_reply":"2024-11-22T12:36:02.542900Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/Qwen/Qwen2.5-0.5B'\n#model_name = url.split('.co/')[-1]\n\nmodel_name = 'Qwen/Qwen2.5-1.5B-Instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-11-22T12:36:02.545954Z","iopub.execute_input":"2024-11-22T12:36:02.546218Z","iopub.status.idle":"2024-11-22T12:36:02.554276Z","shell.execute_reply.started":"2024-11-22T12:36:02.546193Z","shell.execute_reply":"2024-11-22T12:36:02.553604Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-11-22T12:36:02.555263Z","iopub.execute_input":"2024-11-22T12:36:02.555500Z","iopub.status.idle":"2024-11-22T12:36:02.565591Z","shell.execute_reply.started":"2024-11-22T12:36:02.555476Z","shell.execute_reply":"2024-11-22T12:36:02.564860Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:02.566762Z","iopub.execute_input":"2024-11-22T12:36:02.567052Z","iopub.status.idle":"2024-11-22T12:36:06.812090Z","shell.execute_reply.started":"2024-11-22T12:36:02.567028Z","shell.execute_reply":"2024-11-22T12:36:06.811282Z"}},"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 1536)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=1536, out_features=1536, bias=True)\n          (k_proj): Linear4bit(in_features=1536, out_features=256, bias=True)\n          (v_proj): Linear4bit(in_features=1536, out_features=256, bias=True)\n          (o_proj): Linear4bit(in_features=1536, out_features=1536, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=1536, out_features=8960, bias=False)\n          (up_proj): Linear4bit(in_features=1536, out_features=8960, bias=False)\n          (down_proj): Linear4bit(in_features=8960, out_features=1536, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:06.813224Z","iopub.execute_input":"2024-11-22T12:36:06.813496Z","iopub.status.idle":"2024-11-22T12:36:06.821040Z","shell.execute_reply.started":"2024-11-22T12:36:06.813468Z","shell.execute_reply":"2024-11-22T12:36:06.820193Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 888616448\nTrainable parameters : 233461248\nTrainable percentage: 26.27%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:06.822048Z","iopub.execute_input":"2024-11-22T12:36:06.822335Z","iopub.status.idle":"2024-11-22T12:36:07.227891Z","shell.execute_reply.started":"2024-11-22T12:36:06.822295Z","shell.execute_reply":"2024-11-22T12:36:07.226885Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"#url = 'https://huggingface.co/datasets/KingNish/reasoning-base-20k'\n#dataset_name = url.split('datasets/')[-1]\n\ndataset_name = 'yahma/alpaca-cleaned'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:07.229044Z","iopub.execute_input":"2024-11-22T12:36:07.229305Z","iopub.status.idle":"2024-11-22T12:36:07.233774Z","shell.execute_reply.started":"2024-11-22T12:36:07.229280Z","shell.execute_reply":"2024-11-22T12:36:07.232730Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 512","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:07.237375Z","iopub.execute_input":"2024-11-22T12:36:07.237723Z","iopub.status.idle":"2024-11-22T12:36:07.244078Z","shell.execute_reply.started":"2024-11-22T12:36:07.237695Z","shell.execute_reply":"2024-11-22T12:36:07.243156Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:07.245149Z","iopub.execute_input":"2024-11-22T12:36:07.245402Z","iopub.status.idle":"2024-11-22T12:36:08.766196Z","shell.execute_reply.started":"2024-11-22T12:36:07.245377Z","shell.execute_reply":"2024-11-22T12:36:08.765393Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['output', 'input', 'instruction'],\n    num_rows: 51760\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.767315Z","iopub.execute_input":"2024-11-22T12:36:08.767706Z","iopub.status.idle":"2024-11-22T12:36:08.775042Z","shell.execute_reply.started":"2024-11-22T12:36:08.767664Z","shell.execute_reply":"2024-11-22T12:36:08.774045Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.775961Z","iopub.execute_input":"2024-11-22T12:36:08.776210Z","iopub.status.idle":"2024-11-22T12:36:08.798418Z","shell.execute_reply.started":"2024-11-22T12:36:08.776186Z","shell.execute_reply":"2024-11-22T12:36:08.797596Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                              output input  \\\n0  1. Eat a balanced and nutritious diet: Make su...         \n1  The three primary colors are red, blue, and ye...         \n2  An atom is the basic building block of all mat...         \n3  There are several ways to reduce air pollution...         \n4  I had to make a difficult decision when I was ...         \n\n                                         instruction  \n0               Give three tips for staying healthy.  \n1                 What are the three primary colors?  \n2                 Describe the structure of an atom.  \n3                   How can we reduce air pollution?  \n4  Pretend you are a project manager of a constru...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>output</th>\n      <th>input</th>\n      <th>instruction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1. Eat a balanced and nutritious diet: Make su...</td>\n      <td></td>\n      <td>Give three tips for staying healthy.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The three primary colors are red, blue, and ye...</td>\n      <td></td>\n      <td>What are the three primary colors?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>An atom is the basic building block of all mat...</td>\n      <td></td>\n      <td>Describe the structure of an atom.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>There are several ways to reduce air pollution...</td>\n      <td></td>\n      <td>How can we reduce air pollution?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I had to make a difficult decision when I was ...</td>\n      <td></td>\n      <td>Pretend you are a project manager of a constru...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.799346Z","iopub.execute_input":"2024-11-22T12:36:08.799640Z","iopub.status.idle":"2024-11-22T12:36:08.805316Z","shell.execute_reply.started":"2024-11-22T12:36:08.799614Z","shell.execute_reply":"2024-11-22T12:36:08.804449Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'output': '1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\\n\\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\\n\\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.',\n 'input': '',\n 'instruction': 'Give three tips for staying healthy.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.806226Z","iopub.execute_input":"2024-11-22T12:36:08.806466Z","iopub.status.idle":"2024-11-22T12:36:08.814928Z","shell.execute_reply.started":"2024-11-22T12:36:08.806441Z","shell.execute_reply":"2024-11-22T12:36:08.814128Z"}},"outputs":[{"name":"stdout","text":"['output', 'input', 'instruction']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.815958Z","iopub.execute_input":"2024-11-22T12:36:08.816205Z","iopub.status.idle":"2024-11-22T12:36:08.825385Z","shell.execute_reply.started":"2024-11-22T12:36:08.816181Z","shell.execute_reply":"2024-11-22T12:36:08.824710Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  instruction = examples['instruction']\n  input = examples['input']\n  output = examples['output']\n  \n  text = prompt_format.format(instruction, input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.826463Z","iopub.execute_input":"2024-11-22T12:36:08.827025Z","iopub.status.idle":"2024-11-22T12:36:08.834586Z","shell.execute_reply.started":"2024-11-22T12:36:08.826997Z","shell.execute_reply":"2024-11-22T12:36:08.833942Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.835486Z","iopub.execute_input":"2024-11-22T12:36:08.835756Z","iopub.status.idle":"2024-11-22T12:36:08.848989Z","shell.execute_reply.started":"2024-11-22T12:36:08.835731Z","shell.execute_reply":"2024-11-22T12:36:08.848226Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"cZya4tPEWUc9","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.850105Z","iopub.execute_input":"2024-11-22T12:36:08.850748Z","iopub.status.idle":"2024-11-22T12:36:08.857487Z","shell.execute_reply.started":"2024-11-22T12:36:08.850695Z","shell.execute_reply":"2024-11-22T12:36:08.856594Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.858638Z","iopub.execute_input":"2024-11-22T12:36:08.859256Z","iopub.status.idle":"2024-11-22T12:36:08.866862Z","shell.execute_reply.started":"2024-11-22T12:36:08.859216Z","shell.execute_reply":"2024-11-22T12:36:08.866152Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.867821Z","iopub.execute_input":"2024-11-22T12:36:08.868093Z","iopub.status.idle":"2024-11-22T12:36:08.976021Z","shell.execute_reply.started":"2024-11-22T12:36:08.868060Z","shell.execute_reply":"2024-11-22T12:36:08.975137Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.977415Z","iopub.execute_input":"2024-11-22T12:36:08.977831Z","iopub.status.idle":"2024-11-22T12:36:08.985385Z","shell.execute_reply.started":"2024-11-22T12:36:08.977789Z","shell.execute_reply":"2024-11-22T12:36:08.984580Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nGive three tips for staying healthy.\n\n### Input:\n\n\n### Response:\n1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.<|im_end|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:08.986420Z","iopub.execute_input":"2024-11-22T12:36:08.986693Z","iopub.status.idle":"2024-11-22T12:36:08.999429Z","shell.execute_reply.started":"2024-11-22T12:36:08.986668Z","shell.execute_reply":"2024-11-22T12:36:08.998601Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.000631Z","iopub.execute_input":"2024-11-22T12:36:09.000970Z","iopub.status.idle":"2024-11-22T12:36:09.007162Z","shell.execute_reply.started":"2024-11-22T12:36:09.000932Z","shell.execute_reply":"2024-11-22T12:36:09.006035Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.008229Z","iopub.execute_input":"2024-11-22T12:36:09.008467Z","iopub.status.idle":"2024-11-22T12:36:09.033934Z","shell.execute_reply.started":"2024-11-22T12:36:09.008443Z","shell.execute_reply":"2024-11-22T12:36:09.033221Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  Below is an instruction that describes a task,...   \n1  Below is an instruction that describes a task,...   \n2  Below is an instruction that describes a task,...   \n3  Below is an instruction that describes a task,...   \n4  Below is an instruction that describes a task,...   \n\n                                           input_ids  \\\n0  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n1  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n2  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n3  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n4  [38214, 374, 458, 7600, 429, 16555, 264, 3383,...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Below is an instruction that describes a task,...</td>\n      <td>[38214, 374, 458, 7600, 429, 16555, 264, 3383,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.034768Z","iopub.execute_input":"2024-11-22T12:36:09.034977Z","iopub.status.idle":"2024-11-22T12:36:09.039804Z","shell.execute_reply.started":"2024-11-22T12:36:09.034955Z","shell.execute_reply":"2024-11-22T12:36:09.038939Z"}},"outputs":[{"name":"stdout","text":"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nAnalyze the given poem and identify its main theme.\n\n### Input:\nTwo roads diverged in a yellow wood,\\nAnd sorry I could not travel both\\nAnd be one traveler, long I stood\\nAnd looked down one as far as I could\\nTo where it bent in the undergrowth;\\n\\nThen took the other, as just as fair,\\nAnd having perhaps the better claim,\\nBecause it was grassy and wanted wear;\\nThough as for that the passing there\\nHad worn them really about the same,\\nThe roads that morning equally lay\\nIn leaves no step had trodden black.\\nOh, I left the first for another day!\\nYet knowing how way leads on to way,\\nI doubted if I should ever come back.\\n\\nI shall be telling this with a sigh\\nSomewhere ages and ages hence:\\nTwo roads diverged in a wood, and I—\\nI took the one less traveled by,\\nAnd that has made all the difference.\n\n### Response:\nThe main theme of the poem is the importance of making choices and the impact of those choices on one's life. The speaker is faced with a decision between two paths and ultimately chooses the one less traveled, which ultimately shapes their life experience.<|im_end|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.040817Z","iopub.execute_input":"2024-11-22T12:36:09.041072Z","iopub.status.idle":"2024-11-22T12:36:09.049197Z","shell.execute_reply.started":"2024-11-22T12:36:09.041047Z","shell.execute_reply":"2024-11-22T12:36:09.048412Z"}},"outputs":[{"name":"stdout","text":"[38214, 374, 458, 7600, 429, 16555, 264, 3383, 11, 34426, 448, 458, 1946, 429, 5707, 4623, 2266, 13, 9645, 264, 2033, 429, 34901, 44595, 279, 1681, 382, 14374, 29051, 510, 2082, 55856, 279, 2661, 32794, 323, 10542, 1181, 1887, 6912, 382, 14374, 5571, 510, 11613, 19241, 36341, 3556, 304, 264, 13753, 7579, 26266, 77, 3036, 14589, 358, 1410, 537, 5821, 2176, 1699, 3036, 387, 825, 62765, 11, 1293, 358, 14638, 1699, 3036, 6966, 1495, 825, 438, 3041, 438, 358, 1410, 1699, 1249, 1380, 432, 29180, 304, 279, 1212, 73089, 17882, 77, 1699, 12209, 3867, 279, 1008, 11, 438, 1101, 438, 6624, 26266, 77, 3036, 3432, 8365, 279, 2664, 3717, 26266, 77, 17949, 432, 572, 16359, 88, 323, 4829, 9850, 17882, 77, 26733, 438, 369, 429, 279, 12299, 1052, 1699, 55468, 23704, 1105, 2167, 911, 279, 1852, 26266, 88230, 19241, 429, 6556, 18308, 10962, 1699, 641, 10901, 902, 3019, 1030, 8185, 10792, 3691, 7110, 77, 11908, 11, 358, 2115, 279, 1156, 369, 2441, 1899, 14771, 77, 28074, 14063, 1246, 1616, 11508, 389, 311, 1616, 26266, 77, 40, 92662, 421, 358, 1265, 3512, 2525, 1182, 7110, 77, 1699, 40, 4880, 387, 11629, 419, 448, 264, 30138, 1699, 49882, 60652, 16639, 323, 16639, 16085, 7190, 77, 11613, 19241, 36341, 3556, 304, 264, 7579, 11, 323, 358, 2293, 59, 77, 40, 3867, 279, 825, 2686, 30696, 553, 26266, 77, 3036, 429, 702, 1865, 678, 279, 6672, 382, 14374, 5949, 510, 785, 1887, 6912, 315, 279, 32794, 374, 279, 12650, 315, 3259, 11454, 323, 279, 5421, 315, 1846, 11454, 389, 825, 594, 2272, 13, 576, 18601, 374, 16601, 448, 264, 5480, 1948, 1378, 12716, 323, 13653, 39911, 279, 825, 2686, 30696, 11, 892, 13653, 20816, 862, 2272, 3139, 13, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645, 151645]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.055699Z","iopub.execute_input":"2024-11-22T12:36:09.056298Z","iopub.status.idle":"2024-11-22T12:36:09.062254Z","shell.execute_reply.started":"2024-11-22T12:36:09.056269Z","shell.execute_reply":"2024-11-22T12:36:09.061297Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.063200Z","iopub.execute_input":"2024-11-22T12:36:09.063443Z","iopub.status.idle":"2024-11-22T12:36:09.072772Z","shell.execute_reply.started":"2024-11-22T12:36:09.063418Z","shell.execute_reply":"2024-11-22T12:36:09.071912Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.073751Z","iopub.execute_input":"2024-11-22T12:36:09.074002Z","iopub.status.idle":"2024-11-22T12:36:09.082366Z","shell.execute_reply.started":"2024-11-22T12:36:09.073977Z","shell.execute_reply":"2024-11-22T12:36:09.081657Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.083371Z","iopub.execute_input":"2024-11-22T12:36:09.083715Z","iopub.status.idle":"2024-11-22T12:36:09.093050Z","shell.execute_reply.started":"2024-11-22T12:36:09.083675Z","shell.execute_reply":"2024-11-22T12:36:09.092358Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 64\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.094135Z","iopub.execute_input":"2024-11-22T12:36:09.094392Z","iopub.status.idle":"2024-11-22T12:36:09.103315Z","shell.execute_reply.started":"2024-11-22T12:36:09.094368Z","shell.execute_reply":"2024-11-22T12:36:09.102602Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:09.104285Z","iopub.execute_input":"2024-11-22T12:36:09.104600Z","iopub.status.idle":"2024-11-22T12:36:10.071764Z","shell.execute_reply.started":"2024-11-22T12:36:09.104539Z","shell.execute_reply":"2024-11-22T12:36:10.070848Z"}},"outputs":[{"name":"stdout","text":"trainable params: 73,859,072 || all params: 1,617,573,376 || trainable%: 4.5660\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"model","metadata":{"id":"ikF6Yfkz1myd","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:10.072906Z","iopub.execute_input":"2024-11-22T12:36:10.073233Z","iopub.status.idle":"2024-11-22T12:36:10.088402Z","shell.execute_reply.started":"2024-11-22T12:36:10.073204Z","shell.execute_reply":"2024-11-22T12:36:10.087506Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 1536)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (k_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (v_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=256, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (o_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8960, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (up_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=8960, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (down_proj): lora.Linear4bit(\n            (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n            (lora_dropout): ModuleDict(\n              (LoRA): Dropout(p=0.1, inplace=False)\n            )\n            (lora_A): ModuleDict(\n              (LoRA): Linear(in_features=8960, out_features=64, bias=False)\n            )\n            (lora_B): ModuleDict(\n              (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n            )\n            (lora_embedding_A): ParameterDict()\n            (lora_embedding_B): ParameterDict()\n            (lora_magnitude_vector): ModuleDict()\n          )\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:10.089564Z","iopub.execute_input":"2024-11-22T12:36:10.090342Z","iopub.status.idle":"2024-11-22T12:36:10.109777Z","shell.execute_reply.started":"2024-11-22T12:36:10.090297Z","shell.execute_reply":"2024-11-22T12:36:10.108961Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 962475520\nTrainable parameters : 73859072\nTrainable percentage: 7.67%\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:10.110912Z","iopub.execute_input":"2024-11-22T12:36:10.111265Z","iopub.status.idle":"2024-11-22T12:36:10.122301Z","shell.execute_reply.started":"2024-11-22T12:36:10.111227Z","shell.execute_reply":"2024-11-22T12:36:10.121393Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 2\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:10.123316Z","iopub.execute_input":"2024-11-22T12:36:10.123608Z","iopub.status.idle":"2024-11-22T12:36:10.166444Z","shell.execute_reply.started":"2024-11-22T12:36:10.123578Z","shell.execute_reply":"2024-11-22T12:36:10.165156Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Nov22_12-36-10_0e401e72b6f5,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=2,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:10.167471Z","iopub.execute_input":"2024-11-22T12:36:10.167776Z","iopub.status.idle":"2024-11-22T12:36:11.652684Z","shell.execute_reply.started":"2024-11-22T12:36:10.167749Z","shell.execute_reply":"2024-11-22T12:36:11.651831Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x797ad0096260>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T12:36:11.653770Z","iopub.execute_input":"2024-11-22T12:36:11.654090Z","iopub.status.idle":"2024-11-22T13:06:58.244585Z","shell.execute_reply.started":"2024-11-22T12:36:11.654061Z","shell.execute_reply":"2024-11-22T13:06:58.243705Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 2\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 2\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 73,859,072\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113006633332942, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c6b92d55e68492db79fc728c2891f90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241122_123613-fsa29g3i</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/fsa29g3i' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/fsa29g3i' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/fsa29g3i</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 30:36, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>1.544000</td>\n      <td>1.375959</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.279200</td>\n      <td>1.197480</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.144200</td>\n      <td>1.125963</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.081000</td>\n      <td>1.091574</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.074000</td>\n      <td>1.075260</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.039300</td>\n      <td>1.070559</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.056800</td>\n      <td>1.068659</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.009000</td>\n      <td>1.067997</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.059300</td>\n      <td>1.067666</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.973300</td>\n      <td>1.067627</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=1.1260184669494628, metrics={'train_runtime': 1846.2009, 'train_samples_per_second': 0.867, 'train_steps_per_second': 0.108, 'total_flos': 7166650377830400.0, 'train_loss': 1.1260184669494628, 'epoch': 0.17777777777777778})"},"metadata":{}}],"execution_count":39},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:06:58.246680Z","iopub.execute_input":"2024-11-22T13:06:58.247071Z","iopub.status.idle":"2024-11-22T13:08:02.074322Z","shell.execute_reply.started":"2024-11-22T13:06:58.247029Z","shell.execute_reply":"2024-11-22T13:08:02.073472Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 01:02]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 1.0676270723342896, 'eval_runtime': 63.8154, 'eval_samples_per_second': 3.134, 'eval_steps_per_second': 0.784, 'epoch': 0.17777777777777778}\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:02.075445Z","iopub.execute_input":"2024-11-22T13:08:02.075727Z","iopub.status.idle":"2024-11-22T13:08:03.349556Z","shell.execute_reply.started":"2024-11-22T13:08:02.075701Z","shell.execute_reply":"2024-11-22T13:08:03.348857Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 1536,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8960,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 1536,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8960,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:03.350745Z","iopub.execute_input":"2024-11-22T13:08:03.351091Z","iopub.status.idle":"2024-11-22T13:08:03.786902Z","shell.execute_reply.started":"2024-11-22T13:08:03.351047Z","shell.execute_reply":"2024-11-22T13:08:03.785943Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:03.788144Z","iopub.execute_input":"2024-11-22T13:08:03.788941Z","iopub.status.idle":"2024-11-22T13:08:03.797501Z","shell.execute_reply.started":"2024-11-22T13:08:03.788910Z","shell.execute_reply":"2024-11-22T13:08:03.796770Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:03.798366Z","iopub.execute_input":"2024-11-22T13:08:03.798640Z","iopub.status.idle":"2024-11-22T13:08:04.937823Z","shell.execute_reply.started":"2024-11-22T13:08:03.798614Z","shell.execute_reply":"2024-11-22T13:08:04.937127Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:04.938826Z","iopub.execute_input":"2024-11-22T13:08:04.939093Z","iopub.status.idle":"2024-11-22T13:08:09.091176Z","shell.execute_reply.started":"2024-11-22T13:08:04.939065Z","shell.execute_reply":"2024-11-22T13:08:09.090416Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2.5-1.5B-Instruct\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 1536,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 8960,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 21,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": true,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 151936\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/model.safetensors\nInstantiating Qwen2ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645\n}\n\nAll model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-1.5B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-1.5B-Instruct/snapshots/989aa7980e4cf806f80c7fef2b1adb7bc71aa306/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    151645,\n    151643\n  ],\n  \"pad_token_id\": 151643,\n  \"repetition_penalty\": 1.1,\n  \"temperature\": 0.7,\n  \"top_k\": 20,\n  \"top_p\": 0.8\n}\n\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(151936, 1536)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=1536, out_features=1536, bias=True)\n          (k_proj): Linear4bit(in_features=1536, out_features=256, bias=True)\n          (v_proj): Linear4bit(in_features=1536, out_features=256, bias=True)\n          (o_proj): Linear4bit(in_features=1536, out_features=1536, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=1536, out_features=8960, bias=False)\n          (up_proj): Linear4bit(in_features=1536, out_features=8960, bias=False)\n          (down_proj): Linear4bit(in_features=8960, out_features=1536, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:09.092122Z","iopub.execute_input":"2024-11-22T13:08:09.092345Z","iopub.status.idle":"2024-11-22T13:08:09.101848Z","shell.execute_reply.started":"2024-11-22T13:08:09.092321Z","shell.execute_reply":"2024-11-22T13:08:09.101014Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 888616448\nTrainable parameters : 233461248\nTrainable percentage: 26.27%\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:09.102963Z","iopub.execute_input":"2024-11-22T13:08:09.103232Z","iopub.status.idle":"2024-11-22T13:08:09.124805Z","shell.execute_reply.started":"2024-11-22T13:08:09.103207Z","shell.execute_reply":"2024-11-22T13:08:09.123814Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(151936, 1536)\n        (layers): ModuleList(\n          (0-27): 28 x Qwen2DecoderLayer(\n            (self_attn): Qwen2SdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=256, bias=False)\n                  (default): Linear(in_features=64, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): Qwen2RotaryEmbedding()\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8960, bias=False)\n                  (default): Linear(in_features=64, out_features=8960, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=1536, out_features=64, bias=False)\n                  (default): Linear(in_features=1536, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=8960, bias=False)\n                  (default): Linear(in_features=64, out_features=8960, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=8960, out_features=64, bias=False)\n                  (default): Linear(in_features=8960, out_features=64, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=64, out_features=1536, bias=False)\n                  (default): Linear(in_features=64, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:09.125862Z","iopub.execute_input":"2024-11-22T13:08:09.126226Z","iopub.status.idle":"2024-11-22T13:08:09.150212Z","shell.execute_reply.started":"2024-11-22T13:08:09.126180Z","shell.execute_reply":"2024-11-22T13:08:09.149424Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 1036334592\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"## 13 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      '',\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:09.151203Z","iopub.execute_input":"2024-11-22T13:08:09.151560Z","iopub.status.idle":"2024-11-22T13:08:09.161198Z","shell.execute_reply.started":"2024-11-22T13:08:09.151503Z","shell.execute_reply":"2024-11-22T13:08:09.160344Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def post_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      '',\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0])#, skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:09.162212Z","iopub.execute_input":"2024-11-22T13:08:09.162565Z","iopub.status.idle":"2024-11-22T13:08:09.171091Z","shell.execute_reply.started":"2024-11-22T13:08:09.162510Z","shell.execute_reply":"2024-11-22T13:08:09.170291Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:08:09.172109Z","iopub.execute_input":"2024-11-22T13:08:09.172793Z","iopub.status.idle":"2024-11-22T13:08:09.181848Z","shell.execute_reply.started":"2024-11-22T13:08:09.172764Z","shell.execute_reply":"2024-11-22T13:08:09.181088Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:49:16.914758Z","iopub.execute_input":"2024-11-22T13:49:16.915126Z","iopub.status.idle":"2024-11-22T13:49:47.277178Z","shell.execute_reply.started":"2024-11-22T13:49:16.915093Z","shell.execute_reply":"2024-11-22T13:49:47.276259Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Explain    |  completes the request.  ### Instruction: Explain  \nthe concept of a fully connected network.  ###      |  the concept of a fully connected network.  ###    \nInput:   ### Response: A fully connected network    |  Input:   ### Response: A fully connected network  \nis a type of network topology where every node (or  |  is a type of network topology where every node (or\ndevice) is directly connected to every other node.  |  device) is directly connected to every other node.\nThis means that each node in the network is         |  This means that each node in the network is       \nconnected to all other nodes, forming a single,     |  connected to all other nodes, forming a single,   \ninterconnected network. In a fully connected        |  interconnected network. In a fully connected      \nnetwork, there are no isolated nodes, and every     |  network, there are no isolated nodes, and every   \nnode is part of the same network. This type of      |  node is part of the same network. This type of    \nnetwork topology is often used in computer          |  network topology is often used in computer        \nnetworks, such as local area networks (LANs) or     |  networks, such as local area networks (LANs) or   \nwide area networks (WANs), where every device is    |  wide area networks (WANs), where every device is  \ndirectly connected to every other device. The term  |  directly connected to every other device. The term\n\"fully connected\" is also used in the context of    |  \"fully connected\" is also used in the context of  \nfully connected graphs in computer science, where   |  fully connected graphs in computer science, where \neach node is connected to every other node in the   |  each node is connected to every other node in the \ngraph. In a fully connected network, the network    |  graph. In a fully connected network, the network  \nis highly efficient and can handle a large amount   |  is highly efficient and can handle a large amount \nof data, but it can also be difficult to manage     |  of data, but it can also be difficult to manage   \nand maintain, as every node must be updated and     |  and maintain, as every node must be updated and   \nsynchronized.                                       |  synchronized with every other node.<|endoftext|>  \n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T14:24:04.846124Z","iopub.execute_input":"2024-11-22T14:24:04.846475Z","iopub.status.idle":"2024-11-22T14:25:09.055819Z","shell.execute_reply.started":"2024-11-22T14:24:04.846444Z","shell.execute_reply":"2024-11-22T14:25:09.055033Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Explain    |  completes the request.  ### Instruction: Explain  \nthe 3 main components of a simple robotic system    |  the 3 main components of a simple robotic system  \nin a conversational manner as if you were talking   |  in a conversational manner as if you were talking \nto a friend.  ### Input:   ### Response: Sure,      |  to a friend.  ### Input:   ### Response: Sure,    \nlet's dive into the basics of a simple robotic      |  let's dive into the basics of a simple robotic    \nsystem. Imagine you're building a little robot      |  system. Imagine you're building a little robot    \nthat can do some basic tasks. Here's how you can    |  that can do some basic tasks. Here's how you can  \nthink about the three main components:  1. **The    |  think about the three main components:  1. **The  \nBrain**: This is the central part of your robot,    |  Brain**: This is the central part of your robot,  \nkind of like the brain of a human. It's where all   |  kind of like the brain of a human. It's where all \nthe instructions are stored and processed. In a     |  the instructions are stored and processed. In a   \nrobotic system, this is often called the            |  robotic system, this is often called the          \n\"controller\" or \"brain.\" It's where you write the   |  \"controller\" or \"brain controller.\" It's where you\ncode that tells the robot what to do. Think of it   |  write the code that tells the robot what to do.   \nas the \"command center\" of your robot.  2. **The    |  Think of it as the \"command center\" of your robot.\nBody**: This is the physical part of your robot,    |  2. **The Body**: This is the physical part of your\nlike the arms, legs, and wheels. It's where the     |  robot, like the body of a human. It's where all   \nrobot's movements are controlled. In a robotic      |  the parts are put together to make the robot work.\nsystem, this is often called the \"actuator\" or      |  In a robotic system, this is often called the     \n\"mechanism.\" It's where the robot's movements are   |  \"mechanical system\" or \"mechanical body.\" It's    \nmade possible. Think of it as the \"body\" of your    |  where you put the motors, sensors, and other parts\nrobot.  3. **The Senses**: This is the part of      |  that make the robot move and sense its            \nyour robot that helps it \"see\" and \"hear.\" It's     |  environment. Think of it as the \"body\" of your    \nlike the eyes and ears of your robot. In a robotic  |  robot.  3. **The Senses**: This is the part of    \nsystem, this is often called the \"sensor\" or        |  your robot that helps it \"see\" and \"hear\" its     \n\"detector.\" It's where the robot gets information   |  environment. It's like the eyes and ears of a     \nabout its environment. Think of it as the \"senses\"  |  human. In a robotic system, this is often called  \nof your robot.  So, in summary, a simple robotic    |  the \"sensing system\" or \"sensing body.\" It's where\nsystem is like a little robot that can do some      |  you put the sensors that help the robot \"see\" and \nbasic tasks. It has a brain (controller) that       |  \"hear\" its surroundings. Think of it as the       \ntells it what to do, a body (actuator) that makes   |  \"senses\" of your robot.  So, in summary, a simple \nit do those things, and a set of senses (sensor)    |  robotic system is like a little robot that can do \nthat help it understand its environment. It's like  |  some basic tasks. It has a brain that tells it    \na little robot that can move and see, but it's      |  what to do, a body that makes it move, and senses \nstill a very basic system. But with more complex    |  that help it \"see\" and \"hear\" its environment.    \nsystems, you can add more components like a memory  |  It's like a little robot that can do some basic   \n(storage) and a power supply (battery) to make      |  tasks, just like a human!<|endoftext|>            \nyour robot even more powerful and capable. But      |                                                    \nthat's a whole other topic! 😊  Does that help       |                                                    \nexplain it? Let me know if you have any more        |                                                    \nquestions! 🤖✨  [End of Response]                    |                                                    \n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:13:39.118562Z","iopub.execute_input":"2024-11-22T13:13:39.118947Z","iopub.status.idle":"2024-11-22T13:16:23.959152Z","shell.execute_reply.started":"2024-11-22T13:13:39.118906Z","shell.execute_reply":"2024-11-22T13:16:23.958304Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Construct  |  completes the request.  ### Instruction: Construct\na story of love and loss.  ### Input:   ###         |  a story of love and loss.  ### Input:   ###       \nResponse: In the quiet town of Willowbrook,         |  Response: In the quiet town of Willowbrook,       \nnestled between rolling hills and a whispering      |  nestled between rolling hills and a whispering    \nforest, lived a young couple named Sarah and Jack.  |  forest, lived a young couple named Sarah and Jack.\nThey had been together for five years, a time when  |  They had been together for five years, a time when\nthe world seemed to hold its breath, and their      |  the world seemed to hold its breath, and their    \nlove was as pure as the morning dew on the dewy     |  love was as pure as the morning dew on the dewy   \ngrass. Sarah was a poet, her words as delicate as   |  grass. Sarah was a poet, her words as delicate as \nthe petals of a flower, and Jack was a musician,    |  the petals of a flower, and Jack was a musician,  \nhis melodies as haunting as the moon's silver       |  his melodies as haunting as the moon's silver     \nlight. They spent their days exploring the town,    |  light. They spent their days exploring the town,  \nvisiting the local café, and sharing their love     |  visiting the local café where Sarah's poems were  \nfor each other in small, intimate moments.  One     |  often read, and the library where Jack's music was\nday, Jack received a call from his best friend, a   |  played. They were a perfect couple, a perfect     \nman named Leo, who had been diagnosed with a        |  couple, and they knew it.  One day, Jack received \nterminal illness. Jack was devastated, but Sarah,   |  a call from his friend, a renowned composer, who  \nwho had always been the more emotional of the two,  |  had been invited to perform at a prestigious      \nknew that she needed to be strong for Jack. They    |  concert in the city. Jack was overjoyed, and      \ndecided to spend their last days together, in the   |  Sarah, though she knew the world was a cruel      \ntown where they had fallen in love, in the café     |  place, was overjoyed too. They packed their bags, \nwhere they had shared their first kiss.  As they    |  and the journey began. They traveled through the  \nsat at the counter, Jack's eyes filled with tears,  |  countryside, through the mountains, and through   \nand Sarah's voice trembled with emotion. \"I love    |  the city, where they were greeted with warm smiles\nyou,\" she whispered, her words a gentle caress      |  and kind eyes. They arrived in the city, and the  \nagainst his heart. Jack's eyes closed, and he       |  concert was a success, and Jack was invited to    \nleaned into her, his lips brushing against hers in  |  perform at a concert in the countryside. Sarah was\na tender kiss. \"I love you too,\" he murmured, his   |  overjoyed, and Jack was overjoyed too.  But as the\nvoice barely audible.  As the night wore on,        |  days passed, Jack began to feel the weight of the \nJack's condition worsened, and he became more and   |  world. The city was a place of endless            \nmore distant. Sarah, who had always been the more   |  possibilities, and the countryside was a place of \nemotional of the two, found herself struggling to   |  endless solitude. Jack began to feel the weight of\nhold back her tears. She knew that she needed to    |  the world, and the loneliness that came with it.  \nbe strong for Jack, but she also knew that she      |  Sarah, though she knew the world was a cruel      \nneeded to be strong for herself. She decided to     |  place, was overjoyed too. She knew that Jack was  \ntake a walk in the forest, to clear her mind and    |  in love, and she knew that Jack was in love, and  \nfind the strength to face the future.  As she       |  she knew that Jack was in love, and she knew that \nwalked, she felt the weight of the world on her     |  Jack was in love, and she knew that Jack was in   \nshoulders, and she knew that she needed to face     |  love, and she knew that Jack was in love, and she \nit. She decided to write a letter to Jack, to tell  |  knew that Jack was in love, and she knew that Jack\nhim how much she loved him, and to tell him that    |  was in love, and she knew that Jack was in love,  \nshe would always be there for him, no matter what.  |  and she knew that Jack was in love, and she knew  \nShe wrote her letter, and as she finished it, she   |  that Jack was in love, and she knew that Jack was \nfelt a sense of peace wash over her.  As she        |  in love, and she knew that Jack was in love, and  \nwalked back to the café, she saw Jack's friend      |  she knew that Jack was in love, and she knew that \nLeo, who had been there for Jack since the          |  Jack was in love, and she knew that Jack was in   \nbeginning. \"I'm so sorry,\" Leo said, his voice      |  love, and she knew that Jack was in love, and she \nfilled with sorrow. \"I'm so sorry for you,\" Sarah   |  knew that Jack was in love, and she knew that Jack\nsaid, her voice filled with emotion. \"I'm so sorry  |  was in love, and she knew that Jack was in love,  \nfor Jack,\" Leo said, his voice filled with sorrow.  |  and she knew that Jack was in love, and she knew  \n\"I'm so sorry for you,\" Sarah said, her voice       |  that Jack was in love, and she knew that Jack was \nfilled with emotion.  As they sat together, Sarah   |  in love, and she knew that Jack was in love, and  \nand Jack, they shared a final kiss, and as they     |  she knew that Jack was in love, and she knew that \ndid, they knew that they would always be together,  |  Jack was in love, and she knew that Jack was in   \nno matter what. They knew that they would always    |  love, and she knew that Jack was in love, and she \nbe there for each other, no matter what, and that   |  knew that Jack was in love, and she knew that Jack\nthey would always be loved, no matter what. And as  |  was in love, and she knew that Jack was in love,  \nthey lay in each other's arms, they knew that they  |  and she knew that Jack was in love, and she knew  \nhad found the love of their lives, and that they    |  that Jack was in love, and she knew that Jack was \nwould always be together, no matter what. And as    |  in love, and she knew that Jack was in love, and  \nthey lay in each other's arms, they knew that they  |  she knew that Jack was in love, and she knew that \nhad found the love of their lives, and that they    |  Jack was in love, and she knew that Jack was in   \nwould always be together, no matter what. And as    |  love, and she knew that Jack was in love, and she \nthey lay in each other's arms, they knew that they  |  knew that Jack was in love, and she knew that Jack\nhad found the love of their lives, and that they    |  was in love, and she knew that Jack was in love,  \nwould always be together, no matter what. And as    |  and she knew that Jack was in love, and she knew  \nthey lay in each other's arms, they knew that they  |  that Jack was in love, and she knew that Jack was \nhad found the love of their lives, and that they    |  in love, and she knew that Jack was in love, and  \nwould always be together, no matter what. And as    |  she knew that Jack was in love, and she knew that \nthey lay in each other's arms, they knew that they  |  Jack was in love, and she knew that Jack was in   \nhad found the love of their lives, and that they    |  love, and she knew that Jack was in love, and she \nwould always be together, no matter what. And as    |  knew that Jack was in love, and she knew that Jack\nthey lay in each other's arms, they knew that they  |  was in love, and she knew that Jack was in love,  \nhad found the love of their lives, and that they    |  and she knew that Jack was in love, and she knew  \nwould always be together, no matter what. And as    |  that Jack was in love, and she knew that Jack was \nthey lay in each other's arms, they knew that they  |  in love, and she knew that Jack was in love, and  \nhad found the love of their lives, and that they    |  she knew that Jack was in love, and she knew that \nwould always be together, no matter what. And as    |  Jack was in love, and she knew that Jack was in   \nthey lay in each other's arms, they knew that they  |  love, and she knew that Jack was in love, and she \nhad found the love of their lives, and that they    |  knew that Jack was in love, and she knew that Jack\nwould always be together, no matter what. And as    |  was in love, and she knew that Jack was in love,  \nthey lay in each other's arms, they knew that they  |  and she knew that Jack was in love, and she knew  \nhad found the love of their lives, and that they    |  that Jack was in love, and she knew that Jack was \nwould always be together, no matter what. And as    |  in love, and she knew that Jack was in love, and  \nthey lay in each other's arms, they knew that they  |  she knew that Jack was in love, and she knew that \nhad found the love of their lives, and that they    |  Jack was in love, and she knew that Jack was in   \nwould always be together, no matter what. And as    |  love, and she knew that Jack was in love, and she \nthey lay in each other's arms, they knew that they  |  knew that Jack was in love, and she knew that Jack\nhad found the love of their lives, and that they    |  was in love, and she knew that Jack was in love,  \nwould always be together, no matter what. And as    |  and she knew that Jack was in love,               \nthey lay in each other's arms, they knew that they  |                                                    \nhad found the love of their lives, and that they    |                                                    \nwould always be together, no matter what. And as    |                                                    \nthey lay in each other's arms, they knew            |                                                    \n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:24:03.568933Z","iopub.execute_input":"2024-11-22T13:24:03.569176Z","iopub.status.idle":"2024-11-22T13:25:31.662629Z","shell.execute_reply.started":"2024-11-22T13:24:03.569151Z","shell.execute_reply":"2024-11-22T13:25:31.661601Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: Think of   |  completes the request.  ### Instruction: Think of \nan example of a moral dilemma and explain why it    |  an example of a moral dilemma and explain why it  \nis difficult to make a decision.  ### Input:   ###  |  is difficult to make a decision.  ### Input:   ###\nResponse: The moral dilemma I would like to         |  Response: The moral dilemma I would like to       \nconsider is the following: A company has            |  consider is the following: A company has          \ndiscovered a way to increase its profits by         |  discovered a way to increase its profits by       \ncutting corners on safety regulations. The CEO is   |  cutting corners on safety regulations. The CEO is \nfaced with the decision of either continuing with   |  faced with the decision of either continuing with \nthe plan or stopping it altogether.   This dilemma  |  the plan or stopping it altogether.   This dilemma\nis difficult to make a decision about because the   |  is difficult to make a decision on because the    \nconsequences of each option are far-reaching and    |  consequences of both options are significant. If  \npotentially devastating. If the company continues   |  the company continues with the plan, it will      \nwith the plan, it could lead to increased profits,  |  increase profits but at the cost of endangering   \nbut at the cost of endangering the health and       |  the safety of its employees. On the other hand, if\nsafety of its employees and customers. On the       |  the company stops the plan, it will lose out on   \nother hand, if the company stops the plan, it       |  the opportunity to increase profits, but it will  \ncould lead to financial losses and damage to its    |  also prevent harm to its employees.   The decision\nreputation, but it would also prevent the           |  is further complicated by the fact that the CEO is\npotential harm caused by the continued violation    |  not entirely sure whether the safety regulations  \nof safety regulations.   In this case, the          |  are necessary or not. They may be necessary, but  \ndecision is not just about the immediate financial  |  they may also be outdated or ineffective.         \ngain or loss, but also about the long-term          |  Therefore, the CEO is left with the difficult task\nconsequences of the actions taken. It is a          |  of weighing the potential benefits and risks of   \ndifficult decision because the potential outcomes   |  each option.   In conclusion, the moral dilemma of\nare so severe and the consequences of each option   |  the company's decision-making process highlights  \nare so far-reaching. Therefore, it is difficult to  |  the importance of considering the long-term       \nmake a decision because the options are not just    |  consequences of one's actions and the need for a  \nabout the immediate consequences, but also about    |  balanced approach to decision-making. It also     \nthe long-term consequences of the actions taken.    |  highlights the importance of seeking advice from  \nIn conclusion, the moral dilemma of the company's   |  experts or stakeholders when faced with a         \ndecision to continue or stop the plan is difficult  |  difficult decision.<|endoftext|>                  \nto make a decision about because the consequences   |                                                    \nof each option are far-reaching and potentially     |                                                    \ndevastating. It is a difficult decision because     |                                                    \nthe options are not just about the immediate        |                                                    \nfinancial gain or loss, but also about the long-    |                                                    \nterm consequences of the actions taken. Therefore,  |                                                    \nit is difficult to make a decision because the      |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   In             |                                                    \nconclusion, the moral dilemma of the company's      |                                                    \ndecision to continue or stop the plan is difficult  |                                                    \nto make a decision about because the consequences   |                                                    \nof each option are far-reaching and potentially     |                                                    \ndevastating. It is a difficult decision because     |                                                    \nthe options are not just about the immediate        |                                                    \nfinancial gain or loss, but also about the long-    |                                                    \nterm consequences of the actions taken. Therefore,  |                                                    \nit is difficult to make a decision because the      |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   In             |                                                    \nconclusion, the moral dilemma of the company's      |                                                    \ndecision to continue or stop the plan is difficult  |                                                    \nto make a decision about because the consequences   |                                                    \nof each option are far-reaching and potentially     |                                                    \ndevastating. It is a difficult decision because     |                                                    \nthe options are not just about the immediate        |                                                    \nfinancial gain or loss, but also about the long-    |                                                    \nterm consequences of the actions taken. Therefore,  |                                                    \nit is difficult to make a decision because the      |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   In             |                                                    \nconclusion, the moral dilemma of the company's      |                                                    \ndecision to continue or stop the plan is difficult  |                                                    \nto make a decision about because the consequences   |                                                    \nof each option are far-reaching and potentially     |                                                    \ndevastating. It is a difficult decision because     |                                                    \nthe options are not just about the immediate        |                                                    \nfinancial gain or loss, but also about the long-    |                                                    \nterm consequences of the actions taken. Therefore,  |                                                    \nit is difficult to make a decision because the      |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   In             |                                                    \nconclusion, the moral dilemma of the company's      |                                                    \ndecision to continue or stop the plan is difficult  |                                                    \nto make a decision about because the consequences   |                                                    \nof each option are far-reaching and potentially     |                                                    \ndevastating. It is a difficult decision because     |                                                    \nthe options are not just about the immediate        |                                                    \nfinancial gain or loss, but also about the long-    |                                                    \nterm consequences of the actions taken. Therefore,  |                                                    \nit is difficult to make a decision because the      |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   In             |                                                    \nconclusion, the moral dilemma of the company's      |                                                    \ndecision to continue or stop the plan is difficult  |                                                    \nto make a decision about because the consequences   |                                                    \nof each option are far-reaching and potentially     |                                                    \ndevastating. It is a difficult decision because     |                                                    \nthe options are not just about the immediate        |                                                    \nfinancial gain or loss, but also about the long-    |                                                    \nterm consequences of the actions taken. Therefore,  |                                                    \nit is difficult to make a decision because the      |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   In             |                                                    \nconclusion, the moral dilemma of the company's      |                                                    \ndecision to continue or stop the plan is difficult  |                                                    \nto make a decision about because the consequences   |                                                    \nof each option are far-reaching and potentially     |                                                    \ndevastating. It is a difficult decision because     |                                                    \nthe options are not just about the immediate        |                                                    \nfinancial gain or loss, but also about the long-    |                                                    \nterm consequences of the actions taken. Therefore,  |                                                    \nit is difficult to make a decision because the      |                                                    \noptions are not just about the immediate            |                                                    \nconsequences, but also about the long-term          |                                                    \nconsequences of the actions taken.   In             |                                                    \nconclusion, the moral dilemma of the company's      |                                                    \ndecision to continue or stop the plan is difficult  |                                                    \nto make a decision about because the consequences   |                                                    \nof each option are far-reaching and potentially     |                                                    \ndevastating. It is a difficult decision because     |                                                    \nthe options are not just about the immediate        |                                                    \nfinancial gain or loss, but also about the long-    |                                                    \nterm consequences of the actions taken. Therefore,  |                                                    \nit is difficult to make a decision because the      |                                                    \noptions are not just about the immediate            |                                                    \nconsequences,                                       |                                                    \n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['instruction']\ninput = dataset[loc]['input']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T13:25:31.665363Z","iopub.execute_input":"2024-11-22T13:25:31.666126Z","iopub.status.idle":"2024-11-22T13:25:52.954489Z","shell.execute_reply.started":"2024-11-22T13:25:31.666094Z","shell.execute_reply":"2024-11-22T13:25:52.953538Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    888616448                      |                     1036334592                    \n================================================== | ==================================================\nBelow is an instruction that describes a task,      |  Below is an instruction that describes a task,    \npaired with an input that provides further          |  paired with an input that provides further        \ncontext. Write a response that appropriately        |  context. Write a response that appropriately      \ncompletes the request.  ### Instruction: List two   |  completes the request.  ### Instruction: List two \nproblems caused by climate change  ### Input:       |  problems caused by climate change  ### Input:     \n### Response: Climate change is a significant       |  ### Response: 1. **Increased Frequency of Extreme \nglobal issue that has far-reaching consequences.    |  Weather Events**: Climate change is causing more  \nTwo problems caused by climate change are rising    |  frequent and intense extreme weather events such  \nsea levels and extreme weather events. Rising sea   |  as hurricanes, heatwaves, and droughts. These     \nlevels can lead to flooding in coastal areas,       |  events can lead to significant economic and social\nwhile extreme weather events such as hurricanes,    |  impacts, including damage to infrastructure, loss \ndroughts, and heatwaves can cause significant       |  of life, and disruption of daily life.  2.        \ndamage to infrastructure and disrupt daily life.    |  **Disruption of Ecosystems and Biodiversity**:    \nThese problems highlight the urgent need for        |  Changes in temperature and precipitation patterns \naction to mitigate the effects of climate change.   |  due to climate change are leading to shifts in the\n                                                    |  distribution and abundance of species. This can   \n                                                    |  result in the loss of biodiversity, which can have\n                                                    |  cascading effects on ecosystems, including changes\n                                                    |  in food chains and the ability of ecosystems to   \n                                                    |  provide services such as pollination and water    \n                                                    |  purification. Additionally, the loss of certain   \n                                                    |  species can lead to a decrease in the resilience  \n                                                    |  of ecosystems, making them more vulnerable to     \n                                                    |  other disturbances.<|endoftext|>                  \n","output_type":"stream"}],"execution_count":60}]}