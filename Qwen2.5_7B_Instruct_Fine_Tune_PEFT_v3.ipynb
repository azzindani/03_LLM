{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/00-llm-fine-tune-peft-v1-8640645a-48d1-4ab4-9544-e0101eabb0ed.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241101/auto/storage/goog4_request&X-Goog-Date=20241101T092253Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=0d6f408ecb309cbcd081e92a7e45eaa76ae38073acfabe7de338f38021bb9de9c13868853c33f34831bc749caf833c0eae4452632ce05d01aed60b8e202481abdf3f85fb2124e578a87c289913e4386e67eec1b8510ebbf45aa8e8ab4e0aea1a6ee13fff5d5f5544c374a2a19367298840061b1abc594452b913b29c0dcbf0677b5540c1ee5825d4f8eeb1e6bf71bd6eba6ccbcd61f2f66d425a9704cacc11e988f36fe47f76770a22c523699c43670e07f57608c8325cc285bbf7553ef98fececc0dff4f2279f7e198d7c3ea516df946b1ff376b45045a4611794f28eb96af6a262d756ddfdcc74e3e5bff83708e05ef6d2cbf1646d86ccadc850e30567f7f8","timestamp":1730693187949}]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"c05760c966c84d548d89a4a4549479bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_afecb1fe723940a196412f460073c6e3","IPY_MODEL_51a3b74552984703bedcc773eb3f6222","IPY_MODEL_2e8773bd96e24ad6911b102fd0be1722"],"layout":"IPY_MODEL_14152e2ae69a4378921eb9212ad11ac3"}},"afecb1fe723940a196412f460073c6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6b7b2b12542447c804bb2e32aefaa67","placeholder":"​","style":"IPY_MODEL_e19d7a430d4f45b08b981aa35f0ff871","value":"config.json: 100%"}},"51a3b74552984703bedcc773eb3f6222":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d19469c8fc474c8f8329f380d6c4fa15","max":928,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb59838449ea44209b3a1dec302ee9a7","value":928}},"2e8773bd96e24ad6911b102fd0be1722":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a5111d532894f89b76374c07e8c4d39","placeholder":"​","style":"IPY_MODEL_95795695644e48f8b740a7a1743e96c7","value":" 928/928 [00:00&lt;00:00, 26.0kB/s]"}},"14152e2ae69a4378921eb9212ad11ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6b7b2b12542447c804bb2e32aefaa67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e19d7a430d4f45b08b981aa35f0ff871":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d19469c8fc474c8f8329f380d6c4fa15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb59838449ea44209b3a1dec302ee9a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a5111d532894f89b76374c07e8c4d39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95795695644e48f8b740a7a1743e96c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3773fae71bf647aa81c8f3a5b91b6405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc77cb8b178d445396939b272f08e81d","IPY_MODEL_80d1c465546d4fd79d07d1b914ee85f3","IPY_MODEL_d5f0eb7210b0421ba2795063457ea558"],"layout":"IPY_MODEL_483e6ce056fc4de682f3e198e394a9cc"}},"fc77cb8b178d445396939b272f08e81d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e0e68b59a804dea96da0f3af8887d90","placeholder":"​","style":"IPY_MODEL_3ffbaf008b824f76b16a3bc76f863dd9","value":"model.safetensors:   6%"}},"80d1c465546d4fd79d07d1b914ee85f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_96044d3717a34651b96e210fd423308b","max":6425529112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29c938c0b79942c8a1ce54a1368975b6","value":356515840}},"d5f0eb7210b0421ba2795063457ea558":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_167842de375d4d4eb1c795b8e193c069","placeholder":"​","style":"IPY_MODEL_227c4d9a5a5b47b1a347396ab14a1a7c","value":" 357M/6.43G [00:08&lt;02:20, 43.1MB/s]"}},"483e6ce056fc4de682f3e198e394a9cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e0e68b59a804dea96da0f3af8887d90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ffbaf008b824f76b16a3bc76f863dd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96044d3717a34651b96e210fd423308b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29c938c0b79942c8a1ce54a1368975b6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"167842de375d4d4eb1c795b8e193c069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"227c4d9a5a5b47b1a347396ab14a1a7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 00 Import Modules","metadata":{"id":"iNW_MCROx_hX"}},{"cell_type":"code","source":"!pip install -q --upgrade transformers\n!pip install -q peft\n!pip install -U -q bitsandbytes\n!pip install -q datasets\n!pip install -q trl","metadata":{"id":"0-QxfiDVyT74","trusted":true,"outputId":"69d52dc0-ca27-4fd1-81c4-bc2f70300670","executionInfo":{"status":"ok","timestamp":1731567442462,"user_tz":-420,"elapsed":23144,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-08T06:47:47.192267Z","iopub.execute_input":"2024-12-08T06:47:47.192850Z","iopub.status.idle":"2024-12-08T06:48:44.168944Z","shell.execute_reply.started":"2024-12-08T06:47:47.192816Z","shell.execute_reply":"2024-12-08T06:48:44.167781Z"}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntrl 0.12.2 requires transformers<4.47.0, but you have transformers 4.47.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport numpy as np\nimport textwrap\n\nfrom random import randint\nfrom itertools import zip_longest\nfrom datetime import datetime\nfrom datasets import load_dataset\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nfrom trl import SFTTrainer\n\nfrom transformers import (\n  AutoTokenizer,\n  AutoModelForCausalLM,\n  AutoModelForSeq2SeqLM,\n  AutoModel,\n  AutoModelForSequenceClassification,\n  DataCollatorForLanguageModeling,\n  Trainer,\n  TrainingArguments,\n  pipeline,\n  TextDataset,\n  EvalPrediction,\n  DataCollatorWithPadding,\n  GenerationConfig,\n  BitsAndBytesConfig,\n  DataCollatorForSeq2Seq,\n  TextStreamer\n)\n\nfrom peft import (\n  LoraConfig,\n  PeftModelForSequenceClassification,\n  PeftModel,\n  TaskType,\n  AutoPeftModelForSequenceClassification,\n  get_peft_model,\n  prepare_model_for_kbit_training\n)\n\nif torch.cuda.is_available():\n  print(\"GPU is available!\")\nelse:\n  print(\"GPU is not available.\")","metadata":{"id":"TIgNx9Orx0It","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":36099,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"248c8f10-5eae-49a5-ba03-c6c30698404f","execution":{"iopub.status.busy":"2024-12-08T06:48:44.170760Z","iopub.execute_input":"2024-12-08T06:48:44.171068Z","iopub.status.idle":"2024-12-08T06:48:55.442574Z","shell.execute_reply.started":"2024-12-08T06:48:44.171038Z","shell.execute_reply":"2024-12-08T06:48:55.441593Z"}},"outputs":[{"name":"stdout","text":"GPU is available!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"id":"i-nwkyTDybqY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":6,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"outputId":"f7789872-8053-4e26-a665-0c4f94689529","execution":{"iopub.status.busy":"2024-12-08T06:48:55.443651Z","iopub.execute_input":"2024-12-08T06:48:55.443967Z","iopub.status.idle":"2024-12-08T06:48:55.748025Z","shell.execute_reply.started":"2024-12-08T06:48:55.443939Z","shell.execute_reply":"2024-12-08T06:48:55.747200Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 01 Import Model","metadata":{"id":"grIeJpUdyX0Y"}},{"cell_type":"code","source":"model_name = 'Qwen/Qwen2.5-7B-Instruct'","metadata":{"id":"14Lkvw4cyZkY","trusted":true,"executionInfo":{"status":"ok","timestamp":1731567478549,"user_tz":-420,"elapsed":4,"user":{"displayName":"Ahsjsjsj Ajjajaja","userId":"14924339173580079290"}},"execution":{"iopub.status.busy":"2024-12-08T06:48:55.750715Z","iopub.execute_input":"2024-12-08T06:48:55.751092Z","iopub.status.idle":"2024-12-08T06:48:55.762269Z","shell.execute_reply.started":"2024-12-08T06:48:55.751054Z","shell.execute_reply":"2024-12-08T06:48:55.761606Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_model(model_name, base = True):\n  if base == True:\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      torch_dtype = torch.float16,\n      trust_remote_code = True\n    ).to(device)\n\n    return model\n    \n  else:\n    bnb_config = BitsAndBytesConfig(\n      load_in_4bit = True,\n      bnb_4bit_quant_type = 'nf4',\n      bnb_4bit_compute_dtype = torch.float16,\n      bnb_4bit_use_double_quant = True,\n    )\n    model = AutoModelForCausalLM.from_pretrained(\n      model_name,\n      quantization_config = bnb_config,\n      trust_remote_code = True\n    ).to(device)\n\n    return model","metadata":{"id":"GlskFscYyeco","trusted":true,"outputId":"f13e208f-69a8-4f9a-a814-0e87d3dda84f","execution":{"iopub.status.busy":"2024-12-08T06:48:55.763178Z","iopub.execute_input":"2024-12-08T06:48:55.763460Z","iopub.status.idle":"2024-12-08T06:48:55.774150Z","shell.execute_reply.started":"2024-12-08T06:48:55.763434Z","shell.execute_reply":"2024-12-08T06:48:55.773341Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"id":"HIYgZ1xF1qsl","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:48:55.775098Z","iopub.execute_input":"2024-12-08T06:48:55.775460Z","iopub.status.idle":"2024-12-08T06:56:23.660963Z","shell.execute_reply.started":"2024-12-08T06:48:55.775419Z","shell.execute_reply":"2024-12-08T06:56:23.660097Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc74e0d260504ea2b763933c6ceec51d"}},"metadata":{}},{"name":"stderr","text":"`low_cpu_mem_usage` was None, now default to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c05047be0d0847ca8c3db293b06b9945"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a551c16fb4ad45bcb4e90e7fa4e1dc29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b8d1c78cb3d4740970989df70196156"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e45f2e255177472bbb6080c90f13d250"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"066aa5975b5b4d1aad4b3d56aa982fe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76d72dca4f6440f58c3c591d4b9b0171"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7ed208104ea4152b0c7a202e7c5aae9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81e93ce1a20d4348bb145755b842a82b"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(152064, 3584)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"j6d6uYBfzCC4","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:23.662148Z","iopub.execute_input":"2024-12-08T06:56:23.662430Z","iopub.status.idle":"2024-12-08T06:56:23.670230Z","shell.execute_reply.started":"2024-12-08T06:56:23.662403Z","shell.execute_reply":"2024-12-08T06:56:23.669381Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 4352972288\nTrainable parameters : 1090199040\nTrainable percentage: 25.04%\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## 02 Import Tokenizer","metadata":{"id":"MU_19rT5zEIZ"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_name)\n#tokenizer","metadata":{"id":"lpB5JUjSzGtJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:23.671258Z","iopub.execute_input":"2024-12-08T06:56:23.671514Z","iopub.status.idle":"2024-12-08T06:56:28.499010Z","shell.execute_reply.started":"2024-12-08T06:56:23.671488Z","shell.execute_reply":"2024-12-08T06:56:28.498225Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"362ae245a5a74a308fd480d9df3f8444"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9738864a01c842509b80f8a6e6f27228"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78577966c75f4beabdd3a2bf16570ab8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29f418f4f42c4df5a6d4cf9f72151686"}},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## 03 Import Dataset","metadata":{"id":"3QJUqcUVzNoJ"}},{"cell_type":"code","source":"dataset_name = 'microsoft/orca-math-word-problems-200k'","metadata":{"id":"U01UXJdLzPXS","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:28.500179Z","iopub.execute_input":"2024-12-08T06:56:28.500464Z","iopub.status.idle":"2024-12-08T06:56:28.504571Z","shell.execute_reply.started":"2024-12-08T06:56:28.500436Z","shell.execute_reply":"2024-12-08T06:56:28.503661Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"max_length = 384","metadata":{"id":"ZGIUyIDhNJC2","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:28.508401Z","iopub.execute_input":"2024-12-08T06:56:28.508996Z","iopub.status.idle":"2024-12-08T06:56:28.517166Z","shell.execute_reply.started":"2024-12-08T06:56:28.508965Z","shell.execute_reply":"2024-12-08T06:56:28.516324Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split = 'train')\ndataset","metadata":{"id":"0ucM3l_FzUkp","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:28.518369Z","iopub.execute_input":"2024-12-08T06:56:28.519155Z","iopub.status.idle":"2024-12-08T06:56:33.495851Z","shell.execute_reply.started":"2024-12-08T06:56:28.519098Z","shell.execute_reply":"2024-12-08T06:56:33.494934Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question', 'answer'],\n    num_rows: 200035\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"dataset = dataset.select(range(10000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:33.496907Z","iopub.execute_input":"2024-12-08T06:56:33.497235Z","iopub.status.idle":"2024-12-08T06:56:33.503336Z","shell.execute_reply.started":"2024-12-08T06:56:33.497205Z","shell.execute_reply":"2024-12-08T06:56:33.502528Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"dataset.select(range(5)).to_pandas().head()","metadata":{"id":"FLRSMhJDzY5Z","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:33.504508Z","iopub.execute_input":"2024-12-08T06:56:33.504893Z","iopub.status.idle":"2024-12-08T06:56:33.530924Z","shell.execute_reply.started":"2024-12-08T06:56:33.504855Z","shell.execute_reply":"2024-12-08T06:56:33.529984Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Jungkook is the 5th place. Find the number of ...   \n1  A number divided by 10 is 6. Yoongi got the re...   \n2  Dongju selects a piece of paper with a number ...   \n3  You wanted to subtract 46 from a number, but y...   \n4  The length of one span of Jinseo is about 12 c...   \n\n                                              answer  \n0  If Jungkook is in 5th place, then 4 people cro...  \n1  Let's call the certain number \"x\". According t...  \n2  To find the second smallest and third smallest...  \n3  If you accidentally subtracted 59 instead of 4...  \n4  If one span of Jinseo is about 12 centimeters ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jungkook is the 5th place. Find the number of ...</td>\n      <td>If Jungkook is in 5th place, then 4 people cro...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A number divided by 10 is 6. Yoongi got the re...</td>\n      <td>Let's call the certain number \"x\". According t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dongju selects a piece of paper with a number ...</td>\n      <td>To find the second smallest and third smallest...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You wanted to subtract 46 from a number, but y...</td>\n      <td>If you accidentally subtracted 59 instead of 4...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The length of one span of Jinseo is about 12 c...</td>\n      <td>If one span of Jinseo is about 12 centimeters ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"dataset[0]","metadata":{"id":"3exPEy0JdLyI","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:33.532092Z","iopub.execute_input":"2024-12-08T06:56:33.532464Z","iopub.status.idle":"2024-12-08T06:56:33.538314Z","shell.execute_reply.started":"2024-12-08T06:56:33.532438Z","shell.execute_reply":"2024-12-08T06:56:33.537483Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'question': 'Jungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.',\n 'answer': 'If Jungkook is in 5th place, then 4 people crossed the finish line faster than him.'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"features = list(dataset.features.keys())\nprint(features)","metadata":{"id":"xYKmTDtkAnt5","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:33.539372Z","iopub.execute_input":"2024-12-08T06:56:33.539682Z","iopub.status.idle":"2024-12-08T06:56:33.550210Z","shell.execute_reply.started":"2024-12-08T06:56:33.539654Z","shell.execute_reply":"2024-12-08T06:56:33.549406Z"}},"outputs":[{"name":"stdout","text":"['question', 'answer']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## 04 Text Formatting","metadata":{"id":"Wq59WgYJCDY0"}},{"cell_type":"code","source":"prompt_format = \"\"\"### Question:\\n{}\\n### Answer:\\n{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:33.551179Z","iopub.execute_input":"2024-12-08T06:56:33.551439Z","iopub.status.idle":"2024-12-08T06:56:33.562503Z","shell.execute_reply.started":"2024-12-08T06:56:33.551414Z","shell.execute_reply":"2024-12-08T06:56:33.561622Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\ndef preprocess(examples):\n  input = examples['question']\n  output = examples['answer']\n  \n  text = prompt_format.format(input, output) + EOS_TOKEN\n  return {'prompt' : text}","metadata":{"id":"0wXJNFBWWNYP","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:33.563552Z","iopub.execute_input":"2024-12-08T06:56:33.563888Z","iopub.status.idle":"2024-12-08T06:56:33.574707Z","shell.execute_reply.started":"2024-12-08T06:56:33.563848Z","shell.execute_reply":"2024-12-08T06:56:33.574015Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"formatted_dataset = dataset.map(preprocess, remove_columns = features)\nformatted_dataset","metadata":{"id":"7TFGpGhoWS9e","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:33.575507Z","iopub.execute_input":"2024-12-08T06:56:33.575745Z","iopub.status.idle":"2024-12-08T06:56:34.032942Z","shell.execute_reply.started":"2024-12-08T06:56:33.575722Z","shell.execute_reply":"2024-12-08T06:56:34.032051Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"735307111a264d3b96b305efec8d1fd5"}},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"print(formatted_dataset[0]['prompt'])","metadata":{"id":"Kidf8H5zefDC","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:34.034025Z","iopub.execute_input":"2024-12-08T06:56:34.034443Z","iopub.status.idle":"2024-12-08T06:56:34.040010Z","shell.execute_reply.started":"2024-12-08T06:56:34.034395Z","shell.execute_reply":"2024-12-08T06:56:34.039172Z"}},"outputs":[{"name":"stdout","text":"### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|im_end|>\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## 05 Tokenization","metadata":{"id":"UMhGDyBpCHoT"}},{"cell_type":"code","source":"def tokenize_data(example, max_length = max_length):\n  return tokenizer(example['prompt'], truncation = True, padding = 'max_length', max_length = max_length)","metadata":{"id":"m7bxU8fiewb7","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:34.041001Z","iopub.execute_input":"2024-12-08T06:56:34.041369Z","iopub.status.idle":"2024-12-08T06:56:34.064000Z","shell.execute_reply.started":"2024-12-08T06:56:34.041324Z","shell.execute_reply":"2024-12-08T06:56:34.063150Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"tokenized_dataset = formatted_dataset.map(tokenize_data)#, batched = True)#, remove_columns = 'text')\ntokenized_dataset","metadata":{"id":"M3BO26k-BmdS","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:34.065095Z","iopub.execute_input":"2024-12-08T06:56:34.065886Z","iopub.status.idle":"2024-12-08T06:56:43.346201Z","shell.execute_reply.started":"2024-12-08T06:56:34.065845Z","shell.execute_reply":"2024-12-08T06:56:43.345313Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ecd0d862d0d428991daeea6a59dccfe"}},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 10000\n})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"print(tokenized_dataset[0]['prompt'])","metadata":{"id":"wEHhMdV4pEFH","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.347303Z","iopub.execute_input":"2024-12-08T06:56:43.347582Z","iopub.status.idle":"2024-12-08T06:56:43.354927Z","shell.execute_reply.started":"2024-12-08T06:56:43.347556Z","shell.execute_reply":"2024-12-08T06:56:43.354038Z"}},"outputs":[{"name":"stdout","text":"### Question:\nJungkook is the 5th place. Find the number of people who crossed the finish line faster than Jungkook.\n### Answer:\nIf Jungkook is in 5th place, then 4 people crossed the finish line faster than him.<|im_end|>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"tokenized_dataset = tokenized_dataset.train_test_split(test_size = 0.1, seed = 42)\ntokenized_dataset","metadata":{"id":"C2m-e-ivDn1A","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.355980Z","iopub.execute_input":"2024-12-08T06:56:43.356255Z","iopub.status.idle":"2024-12-08T06:56:43.424093Z","shell.execute_reply.started":"2024-12-08T06:56:43.356222Z","shell.execute_reply":"2024-12-08T06:56:43.423236Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 9000\n    })\n    test: Dataset({\n        features: ['prompt', 'input_ids', 'attention_mask'],\n        num_rows: 1000\n    })\n})"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"train_dataset = tokenized_dataset['train']\ntest_dataset = tokenized_dataset['test']\ntrain_dataset","metadata":{"id":"QHs-BnR_zd9C","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.425171Z","iopub.execute_input":"2024-12-08T06:56:43.425430Z","iopub.status.idle":"2024-12-08T06:56:43.436556Z","shell.execute_reply.started":"2024-12-08T06:56:43.425405Z","shell.execute_reply":"2024-12-08T06:56:43.435694Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'input_ids', 'attention_mask'],\n    num_rows: 9000\n})"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"train_dataset.select(range(5)).to_pandas().head()","metadata":{"id":"-CUZuEENF2mW","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.437562Z","iopub.execute_input":"2024-12-08T06:56:43.438236Z","iopub.status.idle":"2024-12-08T06:56:43.466642Z","shell.execute_reply.started":"2024-12-08T06:56:43.438196Z","shell.execute_reply":"2024-12-08T06:56:43.465803Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"                                              prompt  \\\n0  ### Question:\\nThere is a two-digit natural nu...   \n1  ### Question:\\nIn a big box, there are marbles...   \n2  ### Question:\\nAdam goes to a small school, wh...   \n3  ### Question:\\nLisa is looking to attempt a Wo...   \n4  ### Question:\\nThere is a rectangular-shaped p...   \n\n                                           input_ids  \\\n0  [14374, 15846, 510, 3862, 374, 264, 1378, 4834...   \n1  [14374, 15846, 510, 641, 264, 2409, 3745, 11, ...   \n2  [14374, 15846, 510, 37575, 5780, 311, 264, 261...   \n3  [14374, 15846, 510, 72749, 374, 3330, 311, 477...   \n4  [14374, 15846, 510, 3862, 374, 264, 51424, 347...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>### Question:\\nThere is a two-digit natural nu...</td>\n      <td>[14374, 15846, 510, 3862, 374, 264, 1378, 4834...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>### Question:\\nIn a big box, there are marbles...</td>\n      <td>[14374, 15846, 510, 641, 264, 2409, 3745, 11, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>### Question:\\nAdam goes to a small school, wh...</td>\n      <td>[14374, 15846, 510, 37575, 5780, 311, 264, 261...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>### Question:\\nLisa is looking to attempt a Wo...</td>\n      <td>[14374, 15846, 510, 72749, 374, 3330, 311, 477...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>### Question:\\nThere is a rectangular-shaped p...</td>\n      <td>[14374, 15846, 510, 3862, 374, 264, 51424, 347...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"print(train_dataset[0]['prompt'])","metadata":{"id":"6PxxrK5Rd4gk","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.467731Z","iopub.execute_input":"2024-12-08T06:56:43.468544Z","iopub.status.idle":"2024-12-08T06:56:43.473938Z","shell.execute_reply.started":"2024-12-08T06:56:43.468504Z","shell.execute_reply":"2024-12-08T06:56:43.473070Z"}},"outputs":[{"name":"stdout","text":"### Question:\nThere is a two-digit natural number whose tens place is 3. Let A and B be the quotient of this number by 10 and the remainder of division by 10, respectively. If B multiplied by 10 plus A is 9 less than A multiplied by 10 plus B, what is the first number?\n### Answer:\nLet's denote the two-digit number as \\( XY \\), where \\( X \\) is the digit in the tens place and \\( Y \\) is the digit in the ones place. Since the tens place is 3, we have \\( X = 3 \\).\n\nAccording to the problem, \\( A \\) is the quotient of the number by 10, and \\( B \\) is the remainder of the division by 10. Therefore, \\( A = X = 3 \\) and \\( B = Y \\).\n\nThe problem states that \\( B \\times 10 + A \\) is 9 less than \\( A \\times 10 + B \\). This can be written as an equation:\n\n\\[ B \\times 10 + A = A \\times 10 + B - 9 \\]\n\nSubstituting \\( A \\) and \\( B \\) with \\( 3 \\) and \\( Y \\), respectively, we get:\n\n\\[ Y \\times 10 + 3 = 3 \\times 10 + Y - 9 \\]\n\nSimplifying the equation:\n\n\\[ 10Y + 3 = 30 + Y - 9 \\]\n\n\\[ 10Y + 3 = Y + 21 \\]\n\nSubtract \\( Y \\) from both sides:\n\n\\[ 9Y + 3 = 21 \\]\n\nSubtract 3 from both sides:\n\n\\[ 9Y = 18 \\]\n\nDivide both sides by 9:\n\n\\[ Y = 2 \\]\n\nSo the ones place digit is 2. Since we already know the tens place digit is 3, the two-digit number is \\( 32 \\).<|im_end|>\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"print(train_dataset[0]['input_ids'])","metadata":{"id":"HR79ppIiE78f","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.475246Z","iopub.execute_input":"2024-12-08T06:56:43.476066Z","iopub.status.idle":"2024-12-08T06:56:43.488138Z","shell.execute_reply.started":"2024-12-08T06:56:43.476020Z","shell.execute_reply":"2024-12-08T06:56:43.487392Z"}},"outputs":[{"name":"stdout","text":"[14374, 15846, 510, 3862, 374, 264, 1378, 48342, 5810, 1372, 6693, 22008, 1992, 374, 220, 18, 13, 6771, 362, 323, 425, 387, 279, 74762, 315, 419, 1372, 553, 220, 16, 15, 323, 279, 26313, 315, 12804, 553, 220, 16, 15, 11, 15576, 13, 1416, 425, 54916, 553, 220, 16, 15, 5519, 362, 374, 220, 24, 2686, 1091, 362, 54916, 553, 220, 16, 15, 5519, 425, 11, 1128, 374, 279, 1156, 1372, 5267, 14374, 21806, 510, 10061, 594, 78064, 279, 1378, 48342, 1372, 438, 17767, 57319, 1124, 701, 1380, 17767, 1599, 1124, 8, 374, 279, 15723, 304, 279, 22008, 1992, 323, 17767, 809, 1124, 8, 374, 279, 15723, 304, 279, 6174, 1992, 13, 8704, 279, 22008, 1992, 374, 220, 18, 11, 582, 614, 17767, 1599, 284, 220, 18, 1124, 3593, 11190, 311, 279, 3491, 11, 17767, 362, 1124, 8, 374, 279, 74762, 315, 279, 1372, 553, 220, 16, 15, 11, 323, 17767, 425, 1124, 8, 374, 279, 26313, 315, 279, 12804, 553, 220, 16, 15, 13, 15277, 11, 17767, 362, 284, 1599, 284, 220, 18, 1124, 8, 323, 17767, 425, 284, 809, 1124, 3593, 785, 3491, 5302, 429, 17767, 425, 1124, 15136, 220, 16, 15, 488, 362, 1124, 8, 374, 220, 24, 2686, 1091, 17767, 362, 1124, 15136, 220, 16, 15, 488, 425, 1124, 568, 1096, 646, 387, 5326, 438, 458, 23606, 1447, 78045, 425, 1124, 15136, 220, 16, 15, 488, 362, 284, 362, 1124, 15136, 220, 16, 15, 488, 425, 481, 220, 24, 1124, 2533, 3136, 3696, 10607, 17767, 362, 1124, 8, 323, 17767, 425, 1124, 8, 448, 17767, 220, 18, 1124, 8, 323, 17767, 809, 1124, 701, 15576, 11, 582, 633, 1447, 78045, 809, 1124, 15136, 220, 16, 15, 488, 220, 18, 284, 220, 18, 1124, 15136, 220, 16, 15, 488, 809, 481, 220, 24, 1124, 2533, 50, 6383, 7766, 279, 23606, 1447, 78045, 220, 16, 15, 56, 488, 220, 18, 284, 220, 18, 15, 488, 809, 481, 220, 24, 1124, 2533, 78045, 220, 16, 15, 56, 488, 220, 18, 284, 809, 488, 220, 17, 16, 1124, 2533, 3136, 2144, 17767, 809, 1124, 8, 504, 2176, 11067, 1447, 78045, 220, 24, 56, 488, 220, 18, 284, 220, 17, 16, 1124, 2533, 3136, 2144, 220, 18, 504, 2176, 11067, 1447, 78045, 220, 24, 56, 284, 220, 16, 23, 1124, 2533, 12509, 577, 2176, 11067]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"print(train_dataset[0]['attention_mask'])","metadata":{"id":"xGmCvvZTE82D","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.493863Z","iopub.execute_input":"2024-12-08T06:56:43.494139Z","iopub.status.idle":"2024-12-08T06:56:43.501005Z","shell.execute_reply.started":"2024-12-08T06:56:43.494091Z","shell.execute_reply":"2024-12-08T06:56:43.500150Z"}},"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"## 06 Data Collator Set Up","metadata":{"id":"JFX4u0vc0UkS"}},{"cell_type":"code","source":"#data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n#data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer)\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)","metadata":{"id":"F-mkiTYw0cZi","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.501883Z","iopub.execute_input":"2024-12-08T06:56:43.502128Z","iopub.status.idle":"2024-12-08T06:56:43.512082Z","shell.execute_reply.started":"2024-12-08T06:56:43.502085Z","shell.execute_reply":"2024-12-08T06:56:43.511326Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## 07 Evaluation Metrics Set Up","metadata":{"id":"hP1Mu0J6CTCb"}},{"cell_type":"code","source":"def compute_metrics(p: EvalPrediction):\n  preds = np.argmax(p.predictions, axis = 1)\n  precision, recall, f1, _ = precision_recall_fscore_support(\n    p.label_ids,\n    preds,\n    average = 'weighted'\n  )\n  matrix = {\n    'accuracy': accuracy_score(p.label_ids, preds),\n    'f1': f1, 'precision': precision,\n    'recall': recall\n  }\n  return matrix","metadata":{"id":"wzNdWpCI0c7a","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.512944Z","iopub.execute_input":"2024-12-08T06:56:43.513229Z","iopub.status.idle":"2024-12-08T06:56:43.527295Z","shell.execute_reply.started":"2024-12-08T06:56:43.513204Z","shell.execute_reply":"2024-12-08T06:56:43.526424Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"tEkgHY4fxFIJ","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.528370Z","iopub.execute_input":"2024-12-08T06:56:43.528716Z","iopub.status.idle":"2024-12-08T06:56:43.536850Z","shell.execute_reply.started":"2024-12-08T06:56:43.528678Z","shell.execute_reply":"2024-12-08T06:56:43.536152Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## 08 Set Up PEFT / LoRA / QLoRA","metadata":{"id":"VLFCnU8-ZoUa"}},{"cell_type":"code","source":"lora_alpha = 16\nlora_dropout = 0.1\nlora_r = 32\ntarget_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                  \"gate_proj\", \"up_proj\", \"down_proj\",]\n\n#target_modules = [\"qkv_proj\", \"proj_1\", \"proj_2\", \"out_proj\"]\n\npeft_config = LoraConfig(\n  lora_alpha = lora_alpha,\n  lora_dropout = lora_dropout,\n  r = lora_r,\n  bias = 'none',\n  task_type = 'CAUSAL_LM',\n  target_modules = target_modules,\n)","metadata":{"id":"67HK09faZqQh","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.537910Z","iopub.execute_input":"2024-12-08T06:56:43.538522Z","iopub.status.idle":"2024-12-08T06:56:43.548130Z","shell.execute_reply.started":"2024-12-08T06:56:43.538495Z","shell.execute_reply":"2024-12-08T06:56:43.547305Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"peft_model = get_peft_model(model, peft_config, adapter_name = 'LoRA')\npeft_model.print_trainable_parameters()","metadata":{"id":"3ZPOifXCZuhg","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:43.549054Z","iopub.execute_input":"2024-12-08T06:56:43.549366Z","iopub.status.idle":"2024-12-08T06:56:44.613448Z","shell.execute_reply.started":"2024-12-08T06:56:43.549341Z","shell.execute_reply":"2024-12-08T06:56:44.612483Z"}},"outputs":[{"name":"stdout","text":"trainable params: 80,740,352 || all params: 7,696,356,864 || trainable%: 1.0491\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"## 09 Training Model","metadata":{"id":"CVr-LToX1XCl"}},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"id":"uhliEMyp1thd","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:44.614676Z","iopub.execute_input":"2024-12-08T06:56:44.615010Z","iopub.status.idle":"2024-12-08T06:56:44.629361Z","shell.execute_reply.started":"2024-12-08T06:56:44.614961Z","shell.execute_reply":"2024-12-08T06:56:44.628398Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 4433712640\nTrainable parameters : 80740352\nTrainable percentage: 1.82%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"Xn5zb6xWJtu-","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:44.630509Z","iopub.execute_input":"2024-12-08T06:56:44.630777Z","iopub.status.idle":"2024-12-08T06:56:44.638753Z","shell.execute_reply.started":"2024-12-08T06:56:44.630751Z","shell.execute_reply":"2024-12-08T06:56:44.637930Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"save_path = './model'\n\nbatch_size = 1\nmax_steps = 200\ntraining_args = TrainingArguments(\n  output_dir = save_path,\n  gradient_accumulation_steps = 4,\n  evaluation_strategy = 'steps',\n  do_eval = True,\n  per_device_train_batch_size = batch_size,\n  per_device_eval_batch_size = 4,\n  log_level = 'debug',\n  save_strategy = 'no',\n  save_total_limit = 2,\n  save_safetensors = False,\n  fp16 = True,\n  logging_steps = 20,\n  learning_rate = 2e-5,\n  eval_steps = 20,\n  max_steps = max_steps,\n  warmup_steps = 30,\n  lr_scheduler_type = 'cosine',\n)\ntraining_args","metadata":{"id":"93ffvb0d4cG6","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:44.640561Z","iopub.execute_input":"2024-12-08T06:56:44.640837Z","iopub.status.idle":"2024-12-08T06:56:44.694832Z","shell.execute_reply.started":"2024-12-08T06:56:44.640811Z","shell.execute_reply":"2024-12-08T06:56:44.693899Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=1,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndispatch_batches=None,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=20,\neval_strategy=steps,\neval_use_gather_object=False,\nevaluation_strategy=steps,\nfp16=True,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=4,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=debug,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=./model/runs/Dec08_06-56-44_30a9c9ba5437,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=20,\nlogging_strategy=steps,\nlr_scheduler_kwargs={},\nlr_scheduler_type=cosine,\nmax_grad_norm=1.0,\nmax_steps=200,\nmetric_for_best_model=None,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_torch,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=./model,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=4,\nper_device_train_batch_size=1,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=./model,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=no,\nsave_total_limit=2,\nseed=42,\nskip_memory_metrics=True,\nsplit_batches=None,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=30,\nweight_decay=0.0,\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"trainer = SFTTrainer(\n  model = model,\n  train_dataset = train_dataset,#.select(range(10000)),\n  eval_dataset = test_dataset.select(range(200)),\n  dataset_text_field = 'prompt',\n  max_seq_length = max_length,\n  tokenizer = tokenizer,\n  args = training_args,\n  peft_config = peft_config,\n)\ntrainer","metadata":{"id":"EsKeJE3SMdk7","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:44.695951Z","iopub.execute_input":"2024-12-08T06:56:44.696266Z","iopub.status.idle":"2024-12-08T06:56:46.407805Z","shell.execute_reply.started":"2024-12-08T06:56:44.696235Z","shell.execute_reply":"2024-12-08T06:56:46.407012Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length. Will not be supported from version '0.13.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:300: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nmax_steps is given, it will override any value given in num_train_epochs\nUsing auto half precision backend\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"<trl.trainer.sft_trainer.SFTTrainer at 0x7c51c1f58ca0>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"MZVoQX8V1cI3","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T06:56:46.409004Z","iopub.execute_input":"2024-12-08T06:56:46.409380Z","iopub.status.idle":"2024-12-08T07:59:17.846317Z","shell.execute_reply.started":"2024-12-08T06:56:46.409338Z","shell.execute_reply":"2024-12-08T07:59:17.845326Z"}},"outputs":[{"name":"stderr","text":"Currently training with a batch size of: 1\nThe following columns in the training set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n***** Running training *****\n  Num examples = 9,000\n  Num Epochs = 1\n  Instantaneous batch size per device = 1\n  Total train batch size (w. parallel, distributed & accumulation) = 4\n  Gradient Accumulation steps = 4\n  Total optimization steps = 200\n  Number of trainable parameters = 80,740,352\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterlupakan100\u001b[0m (\u001b[33mterlupakan100-\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113153222221525, max=1.0…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"825389ec6ac8454aac0799bacdbbc694"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.3"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241208_065648-ozu25eix</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/terlupakan100-/huggingface/runs/ozu25eix' target=\"_blank\">./model</a></strong> to <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/terlupakan100-/huggingface' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/terlupakan100-/huggingface/runs/ozu25eix' target=\"_blank\">https://wandb.ai/terlupakan100-/huggingface/runs/ozu25eix</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 1:02:16, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>20</td>\n      <td>0.607600</td>\n      <td>0.581375</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.555200</td>\n      <td>0.469051</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.460700</td>\n      <td>0.408654</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.413700</td>\n      <td>0.383911</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.390000</td>\n      <td>0.372974</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.365600</td>\n      <td>0.368108</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.360600</td>\n      <td>0.365945</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.394700</td>\n      <td>0.364660</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.386300</td>\n      <td>0.364190</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.323600</td>\n      <td>0.364139</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\nThe following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=0.4257962107658386, metrics={'train_runtime': 3751.0057, 'train_samples_per_second': 0.213, 'train_steps_per_second': 0.053, 'total_flos': 1.3330206425088e+16, 'train_loss': 0.4257962107658386, 'epoch': 0.08888888888888889})"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"## 10 Model Evaluation","metadata":{"id":"v5N6fZsU1xiG"}},{"cell_type":"code","source":"evaluation_results = trainer.evaluate()\nprint('Evaluation Results:', evaluation_results)","metadata":{"id":"5d6DT3o0113O","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T07:59:17.847554Z","iopub.execute_input":"2024-12-08T07:59:17.847837Z","iopub.status.idle":"2024-12-08T08:02:27.879988Z","shell.execute_reply.started":"2024-12-08T07:59:17.847810Z","shell.execute_reply":"2024-12-08T08:02:27.879066Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `PeftModelForCausalLM.forward` and have been ignored: prompt. If prompt are not expected by `PeftModelForCausalLM.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 200\n  Batch size = 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 03:06]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 0.3641391396522522, 'eval_runtime': 190.0187, 'eval_samples_per_second': 1.053, 'eval_steps_per_second': 0.263, 'epoch': 0.08888888888888889}\n","output_type":"stream"}],"execution_count":39},{"cell_type":"markdown","source":"## 11 Save Model","metadata":{"id":"PjTPWhCj4JQj"}},{"cell_type":"code","source":"save_model = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\nsave_model.save_pretrained(save_path)","metadata":{"id":"OKAmko8h2VeV","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:02:27.881023Z","iopub.execute_input":"2024-12-08T08:02:27.881311Z","iopub.status.idle":"2024-12-08T08:02:30.256468Z","shell.execute_reply.started":"2024-12-08T08:02:27.881284Z","shell.execute_reply":"2024-12-08T08:02:30.255291Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/bb46c15ee4bb56c5b63245ef50fd7637234d6f75/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3584,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 18944,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 28,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 28,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 4,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 152064\n}\n\nloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/bb46c15ee4bb56c5b63245ef50fd7637234d6f75/config.json\nModel config Qwen2Config {\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3584,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 18944,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 28,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 28,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 4,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 152064\n}\n\n","output_type":"stream"}],"execution_count":40},{"cell_type":"markdown","source":"## 12 Load PEFT Model","metadata":{"id":"3NhWAM5h9Rn5"}},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"dlTaH2HoC26T","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:02:30.258066Z","iopub.execute_input":"2024-12-08T08:02:30.258496Z","iopub.status.idle":"2024-12-08T08:02:30.408801Z","shell.execute_reply.started":"2024-12-08T08:02:30.258449Z","shell.execute_reply":"2024-12-08T08:02:30.407810Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"peft_path = save_path + '/LoRA'\npeft_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:02:30.409892Z","iopub.execute_input":"2024-12-08T08:02:30.410211Z","iopub.status.idle":"2024-12-08T08:02:30.420667Z","shell.execute_reply.started":"2024-12-08T08:02:30.410182Z","shell.execute_reply":"2024-12-08T08:02:30.419820Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"'./model/LoRA'"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"peft_model = PeftModel.from_pretrained(model, peft_path)","metadata":{"id":"Nz2HT8nb9XJa","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:02:30.421823Z","iopub.execute_input":"2024-12-08T08:02:30.422531Z","iopub.status.idle":"2024-12-08T08:02:31.669153Z","shell.execute_reply.started":"2024-12-08T08:02:30.422503Z","shell.execute_reply":"2024-12-08T08:02:31.668415Z"}},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":"## 13 Reload & Recheck Base Model","metadata":{}},{"cell_type":"code","source":"model = load_model(model_name, base = False)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:02:31.670321Z","iopub.execute_input":"2024-12-08T08:02:31.670676Z","iopub.status.idle":"2024-12-08T08:04:09.705775Z","shell.execute_reply.started":"2024-12-08T08:02:31.670630Z","shell.execute_reply":"2024-12-08T08:04:09.705082Z"}},"outputs":[{"name":"stderr","text":"loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/bb46c15ee4bb56c5b63245ef50fd7637234d6f75/config.json\nModel config Qwen2Config {\n  \"_name_or_path\": \"Qwen/Qwen2.5-7B-Instruct\",\n  \"architectures\": [\n    \"Qwen2ForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 3584,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 18944,\n  \"max_position_embeddings\": 32768,\n  \"max_window_layers\": 28,\n  \"model_type\": \"qwen2\",\n  \"num_attention_heads\": 28,\n  \"num_hidden_layers\": 28,\n  \"num_key_value_heads\": 4,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": null,\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": null,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.46.3\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"vocab_size\": 152064\n}\n\nCUDA backend validation successful.\nOverriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\nThe device_map was not initialized. Setting device_map to {'': 0}. If you want to use the model for inference, please set device_map ='auto' \n`low_cpu_mem_usage` was None, now default to True since model is quantized.\nloading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/bb46c15ee4bb56c5b63245ef50fd7637234d6f75/model.safetensors.index.json\nInstantiating Qwen2ForCausalLM model under default dtype torch.float16.\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61b07db005654ab8867ee53584c5f784"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n\nAll the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-7B-Instruct.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\nloading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/bb46c15ee4bb56c5b63245ef50fd7637234d6f75/generation_config.json\nGenerate config GenerationConfig {\n  \"bos_token_id\": 151643,\n  \"do_sample\": true,\n  \"eos_token_id\": [\n    151645,\n    151643\n  ],\n  \"pad_token_id\": 151643,\n  \"repetition_penalty\": 1.05,\n  \"temperature\": 0.7,\n  \"top_k\": 20,\n  \"top_p\": 0.8\n}\n\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"Qwen2ForCausalLM(\n  (model): Qwen2Model(\n    (embed_tokens): Embedding(152064, 3584)\n    (layers): ModuleList(\n      (0-27): 28 x Qwen2DecoderLayer(\n        (self_attn): Qwen2SdpaAttention(\n          (q_proj): Linear4bit(in_features=3584, out_features=3584, bias=True)\n          (k_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n          (v_proj): Linear4bit(in_features=3584, out_features=512, bias=True)\n          (o_proj): Linear4bit(in_features=3584, out_features=3584, bias=False)\n          (rotary_emb): Qwen2RotaryEmbedding()\n        )\n        (mlp): Qwen2MLP(\n          (gate_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n          (up_proj): Linear4bit(in_features=3584, out_features=18944, bias=False)\n          (down_proj): Linear4bit(in_features=18944, out_features=3584, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n      )\n    )\n    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n    (rotary_emb): Qwen2RotaryEmbedding()\n  )\n  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n)"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:04:09.706941Z","iopub.execute_input":"2024-12-08T08:04:09.707782Z","iopub.status.idle":"2024-12-08T08:04:09.717825Z","shell.execute_reply.started":"2024-12-08T08:04:09.707739Z","shell.execute_reply":"2024-12-08T08:04:09.717057Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 4352972288\nTrainable parameters : 1090199040\nTrainable percentage: 25.04%\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:04:09.718963Z","iopub.execute_input":"2024-12-08T08:04:09.719590Z","iopub.status.idle":"2024-12-08T08:04:09.745198Z","shell.execute_reply.started":"2024-12-08T08:04:09.719548Z","shell.execute_reply":"2024-12-08T08:04:09.744479Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(152064, 3584)\n        (layers): ModuleList(\n          (0-27): 28 x Qwen2DecoderLayer(\n            (self_attn): Qwen2SdpaAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3584, out_features=32, bias=False)\n                  (default): Linear(in_features=3584, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=3584, bias=False)\n                  (default): Linear(in_features=32, out_features=3584, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3584, out_features=32, bias=False)\n                  (default): Linear(in_features=3584, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=512, bias=False)\n                  (default): Linear(in_features=32, out_features=512, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3584, out_features=512, bias=True)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3584, out_features=32, bias=False)\n                  (default): Linear(in_features=3584, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=512, bias=False)\n                  (default): Linear(in_features=32, out_features=512, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3584, out_features=3584, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3584, out_features=32, bias=False)\n                  (default): Linear(in_features=3584, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=3584, bias=False)\n                  (default): Linear(in_features=32, out_features=3584, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (rotary_emb): Qwen2RotaryEmbedding()\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3584, out_features=32, bias=False)\n                  (default): Linear(in_features=3584, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=18944, bias=False)\n                  (default): Linear(in_features=32, out_features=18944, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=3584, out_features=18944, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=3584, out_features=32, bias=False)\n                  (default): Linear(in_features=3584, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=18944, bias=False)\n                  (default): Linear(in_features=32, out_features=18944, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=18944, out_features=3584, bias=False)\n                (lora_dropout): ModuleDict(\n                  (LoRA): Dropout(p=0.1, inplace=False)\n                  (default): Dropout(p=0.1, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (LoRA): Linear(in_features=18944, out_features=32, bias=False)\n                  (default): Linear(in_features=18944, out_features=32, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (LoRA): Linear(in_features=32, out_features=3584, bias=False)\n                  (default): Linear(in_features=32, out_features=3584, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"total_params = sum(p.numel() for p in peft_model.parameters())\ntrainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\ntrainable_percentage = (trainable_params / total_params) * 100\n\nprint('Total parameters :', total_params)\nprint('Trainable parameters :', trainable_params)\nprint('Trainable percentage: {:.2f}%'.format(trainable_percentage))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:04:09.746341Z","iopub.execute_input":"2024-12-08T08:04:09.746688Z","iopub.status.idle":"2024-12-08T08:04:09.772183Z","shell.execute_reply.started":"2024-12-08T08:04:09.746650Z","shell.execute_reply":"2024-12-08T08:04:09.771394Z"}},"outputs":[{"name":"stdout","text":"Total parameters : 4514452992\nTrainable parameters : 0\nTrainable percentage: 0.00%\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"## 14 Pre Test & Post Test","metadata":{"id":"GrXYkyb89UJQ"}},{"cell_type":"code","source":"def pre_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:04:09.773215Z","iopub.execute_input":"2024-12-08T08:04:09.773452Z","iopub.status.idle":"2024-12-08T08:04:09.781413Z","shell.execute_reply.started":"2024-12-08T08:04:09.773429Z","shell.execute_reply":"2024-12-08T08:04:09.780705Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"def post_assistant(prompt):\n  inputs = tokenizer(\n  [\n    prompt_format.format(\n      prompt,\n      ''\n    )\n  ], return_tensors = 'pt').to(device)\n  generation_config = GenerationConfig(\n    do_sample = True,\n    top_k = 1,\n    temperature = 0.1,\n    max_new_tokens = 1024,\n    pad_token_id = tokenizer.eos_token_id\n  )\n  outputs = peft_model.generate(\n    **inputs,\n    generation_config = generation_config\n  )\n  return tokenizer.decode(outputs[0], skip_special_tokens = True)","metadata":{"id":"lgVU8Ci9RMu6","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:04:09.782319Z","iopub.execute_input":"2024-12-08T08:04:09.782551Z","iopub.status.idle":"2024-12-08T08:04:09.792073Z","shell.execute_reply.started":"2024-12-08T08:04:09.782528Z","shell.execute_reply":"2024-12-08T08:04:09.791357Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def print_side_by_side(pre_text, post_text, width = 50):\n  pre_wrapped = textwrap.wrap(pre_text, width)\n  post_wrapped = textwrap.wrap(post_text, width)\n    \n  print('PRE-TEST'.center(width), ' | ', 'POST-TEST'.center(width))\n  print(\n    str(sum(p.numel() for p in model.parameters())).center(width),\n    '|',\n    str(sum(p.numel() for p in peft_model.parameters())).center(width)\n  )\n  print('=' * width, '|', '=' * width)\n    \n  for pre, post in zip_longest(pre_wrapped, post_wrapped, fillvalue = ''):\n    print(pre.ljust(width), ' | ', post.ljust(width))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:04:09.793175Z","iopub.execute_input":"2024-12-08T08:04:09.793480Z","iopub.status.idle":"2024-12-08T08:04:09.803640Z","shell.execute_reply.started":"2024-12-08T08:04:09.793455Z","shell.execute_reply":"2024-12-08T08:04:09.802957Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"JlEhdEGGTN6T","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:28:50.497723Z","iopub.execute_input":"2024-12-08T08:28:50.498062Z","iopub.status.idle":"2024-12-08T08:29:27.289863Z","shell.execute_reply.started":"2024-12-08T08:28:50.498034Z","shell.execute_reply":"2024-12-08T08:29:27.288949Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4352972288                     |                     4514452992                    \n================================================== | ==================================================\n### Question: What is the volume, in cubic          |  ### Question: What is the volume, in cubic        \ncentimeters (cm3), of the largest cube you can      |  centimeters (cm3), of the largest cube you can    \nmake by cutting a rectangular cuboid block of wood  |  make by cutting a rectangular cuboid block of wood\nthat is 15 centimeters (cm) wide, 12 centimeters    |  that is 15 centimeters (cm) wide, 12 centimeters  \n(cm) long, and 8 centimeters (cm) high? ###         |  (cm) long, and 8 centimeters (cm) high? ###       \nAnswer: To find the volume of the largest cube      |  Answer: To find the volume of the largest cube    \nthat can be made from a rectangular cuboid block    |  that can be made from a rectangular cuboid block  \nof wood, we need to determine the side length of    |  of wood, we need to determine the side length of  \nthe cube that can fit within the dimensions of the  |  the cube that can fit within the dimensions of the\ncuboid. The side length of the cube must be the     |  cuboid. The side length of the cube must be the   \ngreatest common divisor (GCD) of the dimensions of  |  greatest common divisor (GCD) of the dimensions of\nthe cuboid.  1. **Identify the dimensions of the    |  the cuboid.  1. **Identify the dimensions of the  \ncuboid:**    - Width: 15 cm    - Length: 12 cm      |  cuboid:**    - Width: 15 cm    - Length: 12 cm    \n- Height: 8 cm  2. **Find the GCD of the            |  - Height: 8 cm  2. **Find the GCD of the          \ndimensions:**    - The GCD of 15, 12, and 8 is 1    |  dimensions:**    - The GCD of 15, 12, and 8 is 1  \ncm.  3. **Calculate the volume of the cube:**    -  |  cm.  3. **Calculate the volume of the cube:**    -\nThe side length of the cube is 1 cm.    - Volume    |  The side length of the cube is 1 cm.    - Volume  \nof a cube is given by \\( \\text{side length}^3 \\).   |  of a cube = side length^3 = 1^3 = 1 cm^3.         \n\\[ \\text{Volume} = 1^3 = 1 \\text{ cm}^3 \\]          |  Therefore, the volume of the largest cube you can \nTherefore, the volume of the largest cube you can   |  make from the rectangular cuboid block of wood is \nmake from the rectangular cuboid block of wood is   |  1 cubic centimeter (cm^3). The answer is 1 cm^3.  \n\\(\\boxed{1}\\) cubic centimeter (cm3). ###           |  \\[ \\boxed{1} \\]                                   \n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BxmnFTADTQsT","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:18:14.432008Z","iopub.execute_input":"2024-12-08T08:18:14.432303Z","iopub.status.idle":"2024-12-08T08:19:34.600031Z","shell.execute_reply.started":"2024-12-08T08:18:14.432270Z","shell.execute_reply":"2024-12-08T08:19:34.599074Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4352972288                     |                     4514452992                    \n================================================== | ==================================================\n### Question: A cleaning company produces two       |  ### Question: A cleaning company produces two     \nsanitizer sprays. One spray kills 50% of germs,     |  sanitizer sprays. One spray kills 50% of germs,   \nand another spray kills 25% of germs. However, a    |  and another spray kills 25% of germs. However, a  \ncertain percentage of the germs they kill are the   |  certain percentage of the germs they kill are the \nsame ones. After using both sanitizer sprays        |  same ones. After using both sanitizer sprays      \ntogether, 30% of germs would be left. What          |  together, 30% of germs would be left. What        \npercentage of germs do both sprays kill in common?  |  percentage of germs do both sprays kill in common?\n### Answer: Let's denote the percentage of germs    |  ### Answer: Let's denote the percentage of germs  \nkilled by the first spray as A, the percentage of   |  killed by the first spray as A, the percentage of \ngerms killed by the second spray as B, and the      |  germs killed by the second spray as B, and the    \npercentage of germs killed by both sprays as C.     |  percentage of germs killed by both sprays as C.   \nWe know that A = 50%, B = 25%, and the percentage   |  We know that A = 50%, B = 25%, and the percentage \nof germs left after using both sprays is 30%. This  |  of germs left after using both sprays is 30%. This\nmeans that the percentage of germs killed by both   |  means that the percentage of germs killed by both \nsprays together is 100% - 30% = 70%.  The formula   |  sprays together is 100% - 30% = 70%.  The formula \nfor the percentage of germs killed by both sprays   |  for the percentage of germs killed by both sprays \ntogether is:  A + B - C = 70%  Substituting the     |  together is:  A + B - C = 70%  Substituting the   \nknown values, we get:  50% + 25% - C = 70%          |  known values, we get:  50% + 25% - C = 70%        \nSolving for C, we get:  C = 50% + 25% - 70% = 5%    |  Solving for C, we get:  C = 50% + 25% - 70% = 5%  \nTherefore, the percentage of germs killed by both   |  Therefore, the percentage of germs killed by both \nsprays in common is 5%.  Therefore, the answer is   |  sprays in common is 5%.  Therefore, the answer is \n5%. ### Answer: 5. (original) ### Explanation: The  |  5%. ### Answer: 5. (original) ### Explanation: The\npercentage of germs killed by both sprays in        |  percentage of germs killed by both sprays in      \ncommon is 5%. ### Answer: 5. (revised) ###          |  common is 5%.                                     \nExplanation: The percentage of germs killed by      |                                                    \nboth sprays in common is 5%. This is because when   |                                                    \nboth sprays are used together, 70% of the germs     |                                                    \nare killed (100% - 30% left), and the sum of the    |                                                    \nindividual germs killed by each spray (50% + 25%)   |                                                    \nexceeds this by 5%, which represents the overlap    |                                                    \nor common germs killed by both sprays. ### Answer:  |                                                    \n5. (revised) ### Explanation: The percentage of     |                                                    \ngerms killed by both sprays in common is 5%. This   |                                                    \nis because when both sprays are used together, 70%  |                                                    \nof the germs are killed (100% - 30% left), and the  |                                                    \nsum of the individual germs killed by each spray    |                                                    \n(50% + 25%) exceeds this by 5%, which represents    |                                                    \nthe overlap or common germs killed by both sprays.  |                                                    \n### Answer: 5. (revised) ### Explanation: The       |                                                    \npercentage of germs killed by both sprays in        |                                                    \ncommon is 5%. This is because when both sprays are  |                                                    \nused together, 70% of the germs are killed (100% -  |                                                    \n30% left), and the sum of the individual germs      |                                                    \nkilled by each spray (50% + 25%) exceeds this by    |                                                    \n5%, which represents the overlap or common germs    |                                                    \nkilled by both sprays. ### Answer: 5. (revised)     |                                                    \n### Explanation: The percentage of germs killed by  |                                                    \nboth sprays in common is 5%. This is because when   |                                                    \nboth sprays are used together, 70% of the germs     |                                                    \nare killed (100% - 30% left), and the sum of the    |                                                    \nindividual germs killed by each spray (50% + 25%)   |                                                    \nexceeds this by 5%, which represents the overlap    |                                                    \nor common germs killed by both sprays. ### Answer:  |                                                    \n5. (revised) ### Explanation: The percentage of     |                                                    \ngerms killed by both sprays in common is 5%. This   |                                                    \nis because when both sprays are used together, 70%  |                                                    \nof the germs are killed (100% - 30% left), and the  |                                                    \nsum of the individual germs killed by each spray    |                                                    \n(50% + 25%) exceeds this by 5%, which represents    |                                                    \nthe overlap or common germs killed by both sprays.  |                                                    \n### Answer: 5. (revised) ### Explanation: The       |                                                    \npercentage of germs killed by both sprays in        |                                                    \ncommon is 5%. This is because when both sprays are  |                                                    \nused together, 70% of the germs are killed (100% -  |                                                    \n30% left), and the sum of the individual germs      |                                                    \nkilled by each spray (50% + 25%) exceeds this by    |                                                    \n5%, which represents the overlap or common germs    |                                                    \nkilled by both sprays. ### Answer: 5. (revised)     |                                                    \n### Explanation: The percentage of germs killed by  |                                                    \nboth sprays in common is 5%. This is because when   |                                                    \nboth sprays are used together, 70% of the germs     |                                                    \nare killed (100% - 30% left), and the sum of the    |                                                    \nindividual germs killed by each spray (50% + 25%)   |                                                    \nexceeds this by 5%, which represents the overlap    |                                                    \nor common germs killed by both sprays. ### Answer:  |                                                    \n5. (revised) ### Explanation: The percentage of     |                                                    \ngerms killed by both sprays in common is 5%. This   |                                                    \nis because when both sprays are used together, 70%  |                                                    \nof the germs are killed (100% - 30% left), and the  |                                                    \nsum                                                 |                                                    \n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"RDONbvZKTTqs","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:07:11.170205Z","iopub.execute_input":"2024-12-08T08:07:11.170488Z","iopub.status.idle":"2024-12-08T08:07:53.959840Z","shell.execute_reply.started":"2024-12-08T08:07:11.170460Z","shell.execute_reply":"2024-12-08T08:07:53.958902Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4352972288                     |                     4514452992                    \n================================================== | ==================================================\n### Question: What is the value of D among the      |  ### Question: What is the value of D among the    \nfour different numbers A, B, C, and D that satisfy  |  four different numbers A, B, C, and D that satisfy\nA+A=6, B-A=4, C+B=9, and D-C=7? ### Answer: To      |  A+A=6, B-A=4, C+B=9, and D-C=7? ### Answer: To    \nfind the value of D, we can use the given           |  find the value of D, we can use the given         \nequations to solve for A, B, and C first, and then  |  equations to solve for A, B, and C first, and then\nuse the value of C to find D.  1. From the          |  use the value of C to find D.  1. From the        \nequation A + A = 6, we can solve for A:    A = 6 /  |  equation A + A = 6, we can solve for A:    A = 6 /\n2 = 3  2. Using the value of A, we can solve for B  |  2 = 3  2. Using the value of A, we can solve for B\nfrom the equation B - A = 4:    B = 4 + A = 4 + 3   |  from the equation B - A = 4:    B = 4 + A = 4 + 3 \n= 7  3. Using the value of B, we can solve for C    |  = 7  3. Using the value of B, we can solve for C  \nfrom the equation C + B = 9:    C = 9 - B = 9 - 7   |  from the equation C + B = 9:    C = 9 - B = 9 - 7 \n= 2  4. Finally, using the value of C, we can       |  = 2  4. Finally, using the value of C, we can     \nsolve for D from the equation D - C = 7:    D = 7   |  solve for D from the equation D - C = 7:    D = 7 \n+ C = 7 + 2 = 9  Therefore, the value of D is 9.    |  + C = 7 + 2 = 9  Therefore, the value of D is 9.  \n### Answer: \\boxed{9}.  ### Explanation: This       |  ### Answer: \\boxed{9}.  ### Explanation: This     \nproblem involves basic arithmetic operations and    |  problem involves basic arithmetic operations and  \nsolving linear equations. It tests the ability to   |  solving linear equations. By using the given      \napply equations to find unknown values. The key is  |  equations to find the values of A, B, and C, and  \nto use the given equations to find the values of    |  then using the value of C to find D, we can solve \nA, B, and C, and then use the value of C to find    |  the problem. This question tests the ability to   \nD. This question assesses the understanding of the  |  solve linear equations and understand the         \nrelationship between addition and subtraction, as   |  relationship between numbers. It is a fundamental \nwell as the ability to solve linear equations. It   |  problem.                                          \nis a fundamental problem.                           |                                                    \n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"p7dBkB_7TjZY","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:14:29.537153Z","iopub.execute_input":"2024-12-08T08:14:29.537575Z","iopub.status.idle":"2024-12-08T08:15:00.506827Z","shell.execute_reply.started":"2024-12-08T08:14:29.537533Z","shell.execute_reply":"2024-12-08T08:15:00.505911Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4352972288                     |                     4514452992                    \n================================================== | ==================================================\n### Question: Dale owns 4 sports cars. The red one  |  ### Question: Dale owns 4 sports cars. The red one\ncan travel at twice the speed of the green one,     |  can travel at twice the speed of the green one,   \nbut the green one can travel at 8 times the speed   |  but the green one can travel at 8 times the speed \nof the blue one. The yellow one is broken and       |  of the blue one. The yellow one is broken and     \ncannot move at all. The red car can travel at a     |  cannot move at all. The red car can travel at a   \nspeed of 1280 miles per hour. What is the speed,    |  speed of 1280 miles per hour. What is the speed,  \nin miles per hour, of the blue car? ### Answer:     |  in miles per hour, of the blue car? ### Answer:   \nLet's denote the speed of the blue car as \\( x \\)   |  Let's denote the speed of the blue car as \\( x \\) \nmiles per hour.  Given that the green car can       |  miles per hour.  Given that the green car can     \ntravel at 8 times the speed of the blue car, the    |  travel at 8 times the speed of the blue car, the  \nspeed of the green car is \\( 8x \\) miles per hour.  |  speed of the green car is \\( 8x \\) miles per hour.\nThe red car can travel at twice the speed of the    |  The red car can travel at twice the speed of the  \ngreen car, so the speed of the red car is \\( 2      |  green car, so the speed of the red car is \\( 2    \n\\times 8x = 16x \\) miles per hour.  We know the     |  \\times 8x = 16x \\) miles per hour.  We know the   \nspeed of the red car is 1280 miles per hour, so we  |  red car can travel at 1280 miles per hour, so we  \ncan set up the equation: \\[ 16x = 1280 \\]  To find  |  set up the equation: \\[ 16x = 1280 \\]  To find \\( \n\\( x \\), we solve for \\( x \\): \\[ x =               |  x \\), we solve for \\( x \\): \\[ x = \\frac{1280}{16}\n\\frac{1280}{16} \\] \\[ x = 80 \\]  Therefore, the     |  \\] \\[ x = 80 \\]  Therefore, the speed of the blue \nspeed of the blue car is 80 miles per hour.  ###    |  car is 80 miles per hour.  ### Answer: \\[         \nAnswer: \\[ \\boxed{80} \\] miles per hour.            |  \\boxed{80} \\] miles per hour.                     \n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"loc = randint(0, len(dataset))\nprompt = dataset[loc]['question']\npre_text = pre_assistant(prompt)\npost_text = post_assistant(prompt)\nprint_side_by_side(pre_text, post_text)","metadata":{"id":"BUPoJAmnTnCq","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T08:30:04.203937Z","iopub.execute_input":"2024-12-08T08:30:04.204322Z","iopub.status.idle":"2024-12-08T08:32:39.344298Z","shell.execute_reply.started":"2024-12-08T08:30:04.204280Z","shell.execute_reply":"2024-12-08T08:32:39.343392Z"}},"outputs":[{"name":"stdout","text":"                     PRE-TEST                       |                      POST-TEST                     \n                    4352972288                     |                     4514452992                    \n================================================== | ==================================================\n### Question: I made an ade with 3 and 2/6 spoons   |  ### Question: I made an ade with 3 and 2/6 spoons \nof blueberry syrup and 21/6 spoons of grapefruit    |  of blueberry syrup and 21/6 spoons of grapefruit  \nsyrup. Find the answer with more blueberry syrup    |  syrup. Find the answer with more blueberry syrup  \nor grapefruit syrup. ### Answer: To find out which  |  or grapefruit syrup. ### Answer: To find out which\nsyrup has more, we need to compare the quantities   |  syrup has more, we need to compare the quantities \nof blueberry syrup and grapefruit syrup used in     |  of blueberry syrup and grapefruit syrup.  First,  \nthe ade.  First, let's simplify the fractions:  -   |  let's convert the fractions to a common           \nBlueberry syrup: \\(3 \\frac{2}{6}\\) spoons -         |  denominator to make the comparison easier. The    \nGrapefruit syrup: \\(21 \\frac{6}{6}\\) spoons         |  blueberry syrup is given as 3 and 2/6 spoons, and \nSimplify the fractions:  - Blueberry syrup: \\(3     |  the grapefruit syrup is given as 21/6 spoons.  1. \n\\frac{2}{6} = 3 \\frac{1}{3}\\) (since \\(2/6 =        |  Convert 3 and 2/6 to an improper fraction:    \\[  \n1/3\\)) - Grapefruit syrup: \\(21 \\frac{6}{6} = 21 +  |  3 \\frac{2}{6} = \\frac{3 \\times 6 + 2}{6} =        \n1 = 22\\) (since \\(6/6 = 1\\))  Now, we can compare   |  \\frac{18 + 2}{6} = \\frac{20}{6}    \\]  2. Now we  \nthe simplified quantities:  - Blueberry syrup: \\(3  |  have:    \\[    \\text{Blueberry syrup} =           \n\\frac{1}{3}\\) spoons - Grapefruit syrup: \\(22\\)     |  \\frac{20}{6} \\text{ spoons}    \\]    \\[           \nspoons  Clearly, \\(22\\) spoons of grapefruit syrup  |  \\text{Grapefruit syrup} = \\frac{21}{6} \\text{     \nis more than \\(3 \\frac{1}{3}\\) spoons of blueberry  |  spoons}    \\]  3. Compare the two fractions:    \\[\nsyrup.  ### Conclusion: There is more grapefruit    |  \\frac{20}{6} \\text{ and } \\frac{21}{6}    \\]      \nsyrup than blueberry syrup in the ade. The answer   |  Since the denominators are the same, we can       \nis grapefruit syrup. \\(\\boxed{\\text{Grapefruit      |  directly compare the numerators:    \\[    20 < 21 \nsyrup}}\\) is the correct answer. \\(\\boxed{22}\\)     |  \\]  Therefore, the grapefruit syrup has more than \nspoons of grapefruit syrup is more than \\(3         |  the blueberry syrup.  ### Conclusion: The         \n\\frac{1}{3}\\) spoons of blueberry syrup.            |  grapefruit syrup has more than the blueberry      \n\\(\\boxed{\\text{Grapefruit syrup}}\\) is the correct  |  syrup. The answer is the grapefruit syrup.        \nanswer. \\(\\boxed{22}\\) spoons of grapefruit syrup   |  $\\boxed{\\text{Grapefruit syrup}}$.  ###           \nis more than \\(3 \\frac{1}{3}\\) spoons of blueberry  |  Explanation: The problem involves comparing two   \nsyrup. \\(\\boxed{\\text{Grapefruit syrup}}\\) is the   |  fractions with the same denominator. By converting\ncorrect answer. \\(\\boxed{22}\\) spoons of            |  the mixed number to an improper fraction and then \ngrapefruit syrup is more than \\(3 \\frac{1}{3}\\)     |  comparing the numerators, we can determine which  \nspoons of blueberry syrup.                          |  syrup has more. The key is to ensure the          \n\\(\\boxed{\\text{Grapefruit syrup}}\\) is the correct  |  denominators are the same before comparing the    \nanswer. \\(\\boxed{22}\\) spoons of grapefruit syrup   |  numerators. $\\boxed{\\text{Grapefruit syrup}}$ has \nis more than \\(3 \\frac{1}{3}\\) spoons of blueberry  |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nsyrup. \\(\\boxed{\\text{Grapefruit syrup}}\\) is the   |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \ncorrect answer. \\(\\boxed{22}\\) spoons of            |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \ngrapefruit syrup is more than \\(3 \\frac{1}{3}\\)     |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nspoons of blueberry syrup.                          |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \n\\(\\boxed{\\text{Grapefruit syrup}}\\) is the correct  |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nanswer. \\(\\boxed{22}\\) spoons of grapefruit syrup   |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nis more than \\(3 \\frac{1}{3}\\) spoons of blueberry  |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nsyrup. \\(\\boxed{\\text{Grapefruit syrup}}\\) is the   |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \ncorrect answer. \\(\\boxed{22}\\) spoons of            |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \ngrapefruit syrup is more than \\(3 \\frac{1}{3}\\)     |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nspoons of blueberry syrup.                          |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \n\\(\\boxed{\\text{Grapefruit syrup}}\\) is the correct  |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nanswer. \\(\\boxed{22}\\) spoons of grapefruit syrup   |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nis more than \\(3 \\frac{1}{3}\\) spoons of blueberry  |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nsyrup. \\(\\boxed{\\text{Grapefruit syrup}}\\) is the   |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \ncorrect answer. \\(\\boxed{22}\\) spoons of            |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \ngrapefruit syrup is more than \\(3 \\frac{1}{3}\\)     |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nspoons of blueberry syrup.                          |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \n\\(\\boxed{\\text{Grapefruit syrup}}\\) is the correct  |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nanswer. \\(\\boxed{22}\\) spoons of grapefruit syrup   |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nis more than \\(3 \\frac{1}{3}\\) spoons of blueberry  |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nsyrup. \\(\\boxed{\\text{Grapefruit syrup}}\\) is the   |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \ncorrect answer. \\(\\boxed{22}\\) spoons of            |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \ngrapefruit syrup is more than \\(3 \\frac{1}{3}\\)     |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nspoons of blueberry syrup.                          |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \n\\(\\boxed{\\text{Grapefruit syrup}}\\) is the correct  |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nanswer. \\(\\boxed{22}\\) spoons of grapefruit syrup   |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nis more than \\(3 \\frac{1}{3}\\) spoons of blueberry  |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nsyrup. \\(\\boxed{\\text{Grapefruit syrup}}\\) is the   |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \ncorrect answer. \\(\\boxed{22}\\) spoons of            |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \ngrapefruit syrup is more than \\(3 \\frac{1}{3}\\)     |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nspoons of blueberry syrup.                          |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \n\\(\\boxed{\\text{Grapefruit syrup}}\\) is the correct  |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nanswer. \\(\\boxed{22}\\) spoons of grapefruit syrup   |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nis more than \\(3 \\frac{1}{3}\\) spoons of blueberry  |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \nsyrup. \\(\\boxed{\\text{Grapefruit syrup}}\\) is the   |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \ncorrect answer. \\(\\boxed{22}\\) spoons of            |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \ngrapefruit syrup is more than \\(3 \\frac{1}{3}\\)     |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \nspoons of blueberry syrup.                          |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \n\\(\\boxed{\\text{Grapefruit syrup}}                   |  more syrup. $\\boxed{\\text{Grapefruit syrup}}$ is  \n                                                    |  the answer. $\\boxed{\\text{Grapefruit syrup}}$ has \n                                                    |  more syrup. $\\boxed{\\text                         \n","output_type":"stream"}],"execution_count":71}]}