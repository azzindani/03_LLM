{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\LLM_Environment\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast, GPT2Config\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import statistics\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_PATH = str(pathlib.Path().resolve())\n",
    "DATASET_PATH = MAIN_PATH + '\\\\datasets'\n",
    "MODEL_PATH = MAIN_PATH + '\\\\models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert-base-cased',\n",
       " 'bert-base-multilingual-cased',\n",
       " 'bert-base-uncased',\n",
       " 'bert-large-cased',\n",
       " 'bert-large-uncased',\n",
       " 'flan-t5-base',\n",
       " 'flan-t5-large',\n",
       " 'flan-t5-small',\n",
       " 'gpt2',\n",
       " 'gpt2-large',\n",
       " 'gpt2-medium']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = os.listdir(MODEL_PATH)\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python\\\\LLM_Environment\\\\models\\\\gpt2-medium'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = MODEL_PATH + '\\\\' + models[10]\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = GPT2Config.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path, config=configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Recipes.csv', 'Recipes_1000.csv', 'train.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = os.listdir(DATASET_PATH)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Python\\\\LLM_Environment\\\\datasets\\\\Recipes_1000.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = DATASET_PATH + '\\\\' + filenames[1]\n",
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(file_path)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>name</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38</td>\n",
       "      <td>Low-Fat Berry Blue Frozen Dessert</td>\n",
       "      <td>blueberries, granulated sugar, vanilla yogurt,...</td>\n",
       "      <td>Toss 2 cups berries with sugar. Let stand for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>Biryani</td>\n",
       "      <td>saffron, milk, hot green chili peppers, onions...</td>\n",
       "      <td>Soak saffron in warm milk for 5 minutes and pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>Best Lemonade</td>\n",
       "      <td>sugar, lemons, rind of, lemon, zest of, fresh ...</td>\n",
       "      <td>Into a 1 quart Jar with tight fitting lid, put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>Carina's Tofu-Vegetable Kebabs</td>\n",
       "      <td>extra firm tofu, eggplant, zucchini, mushrooms...</td>\n",
       "      <td>Drain the tofu, carefully squeezing out excess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Cabbage Soup</td>\n",
       "      <td>plain tomato juice, cabbage, onion, carrots, c...</td>\n",
       "      <td>Mix everything together and bring to a boil. R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecipeId                               name  \\\n",
       "0        38  Low-Fat Berry Blue Frozen Dessert   \n",
       "1        39                            Biryani   \n",
       "2        40                      Best Lemonade   \n",
       "3        41     Carina's Tofu-Vegetable Kebabs   \n",
       "4        42                       Cabbage Soup   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  blueberries, granulated sugar, vanilla yogurt,...   \n",
       "1  saffron, milk, hot green chili peppers, onions...   \n",
       "2  sugar, lemons, rind of, lemon, zest of, fresh ...   \n",
       "3  extra firm tofu, eggplant, zucchini, mushrooms...   \n",
       "4  plain tomato juice, cabbage, onion, carrots, c...   \n",
       "\n",
       "                                        instructions  \n",
       "0  Toss 2 cups berries with sugar. Let stand for ...  \n",
       "1  Soak saffron in warm milk for 5 minutes and pu...  \n",
       "2  Into a 1 quart Jar with tight fitting lid, put...  \n",
       "3  Drain the tofu, carefully squeezing out excess...  \n",
       "4  Mix everything together and bring to a boil. R...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "d:\\Python\\LLM_Environment\\myenv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:545: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0: beef, salt, pepper, onion and a little salt and pepper. Pour 1/2 cup of the sauce over the chicken and then roll up the chicken to create a patty, like so: 1/2 – 1/2 cup of the sauce, 1 teaspoon salt, 1 teaspoon pepper, salt and 1 teaspoon minced garlic. Cut off 1/4 inch of the chicken (or shred it) and then cut up and wrap the chicken with a wrap to create a sandwich: 1/4 – 1/2 cup of sauce, 1 teaspoon salt, 1 teaspoon pepper, salt and 1...\n",
      "  ---\n",
      "1: beef, salt, pepper, onion powder, garlic powder, and salt. Add 1 Tbsp. of the chicken broth. Bring to a boil and add 1/4 tsp. more of the garlic powder. Lower the heat to a simmer and cook for 25-30 minutes or until the meat is cooked through. Once cooked, remove from the heat. While you're waiting for the chicken to cook, remove your chicken from the refrigerator and chop up the meat into small chunks. Then place the chunks into a large bowl. Once the chicken has been completely chopped, add in the rest of the...\n",
      "  ---\n",
      "2: beef, salt, pepper, onion, fresh garlic, fresh herbs, oregano, cumin, black pepper, thyme, oregano, salt and pepper.\n",
      "\n",
      "\n",
      "3. To serve, take 1 medium chicken breast fillet, cut into bite-sized pieces and place on a foil-lined platter. Spread 1/2 cup of this marinade with 2-3 slices of tender white bread. Top with 2 slices of chicken, 1-2 tablespoons of marinade, sliced red onion and 1-2 tablespoons of fresh garlic.\n",
      "\n",
      "\n",
      "4. Place...\n",
      "  ---\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "input_sequence = \"beef, salt, pepper\"\n",
    "input_ids = tokenizer.encode(input_sequence, return_tensors='pt')\n",
    "\n",
    "model = model.to(device)\n",
    "#combine both sampling techniques\n",
    "sample_outputs = model.generate(input_ids.to(device),\n",
    "                              do_sample = True, max_length = 120,\n",
    "                              top_k = 50, top_p = 0.85,\n",
    "                              num_return_sequences = 3)\n",
    "\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}...\".format(i, tokenizer.decode(sample_output, skip_special_tokens = True)))\n",
    "    print('  ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|startoftext|>Ingredients: blueberries, granulated sugar, vanilla yogurt, lemon juice. Instructions: Toss 2 cups berries with sugar. Let stand for 45 minutes, stirring occasionally. Transfer berry-sugar mixture to food processor. Add yogurt and process until smooth. Strain through fine sieve. Pour into baking pan (or transfer to ice cream maker and process according to manufacturers' directions). Freeze uncovered until edges are solid but centre is soft.  Transfer to processor and blend until smooth again. Return to pan and freeze until edges are solid. Transfer to processor and blend until smooth again. Fold in remaining 2 cups of blueberries. Pour into plastic mold and freeze overnight. Let soften slightly to serve.<|endoftext|>\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def form_string(ingredient,instruction):\n",
    "    # s = f\"<|startoftext|>Ingredients:\\n{ingredient.strip()}\\n\\nInstructions:\\n{instruction.strip()}<|endoftext|>\"\n",
    "    s = f\"<|startoftext|>Ingredients: {ingredient.strip()}. \" \\\n",
    "        f\"Instructions: {instruction.strip()}<|endoftext|>\"\n",
    "    return s\n",
    "\n",
    "def extract_string(recipe):\n",
    "    str = recipe.replace('<|startoftext|>', '').replace('<|endoftext|>', '')\n",
    "    inst_pos = str.find('Instructions: ')\n",
    "    ingredients = str[len('Ingredients: '): inst_pos-1]\n",
    "    instructions = str[inst_pos+len('Instructions: '):]\n",
    "    return ingredients, instructions\n",
    "\n",
    "data = df.apply(lambda x:form_string(\n",
    "    x['ingredients'], x['instructions']), axis=1).to_list()\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_path,\n",
    "                                              bos_token='<|startoftext|>',\n",
    "                                              eos_token='<|endoftext|>',\n",
    "                                              unk_token='<|unknown|>',\n",
    "                                              pad_token='<|pad|>'\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ĠPhoto', 5555)\n",
      "('Ġplus', 5556)\n",
      "('rick', 5557)\n",
      "('arks', 5558)\n",
      "('Ġalternative', 5559)\n",
      "('Ġpil', 5560)\n",
      "('Ġapprox', 5561)\n",
      "('that', 5562)\n",
      "('Ġobjects', 5563)\n",
      "('ĠRo', 5564)\n",
      "('ĠAndroid', 5565)\n"
     ]
    }
   ],
   "source": [
    "vocab_list = sorted(tokenizer.vocab.items(), key=lambda x:x[1])\n",
    "for i in range(5555, 5566):\n",
    "    print(vocab_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The max model length is 1024 for this model\n",
      "The end of sequence token <|endoftext|> has the id 50256\n",
      "The beginning of sequence token <|startoftext|> has the id 50257\n",
      "The unknown token <|unknown|> has the id 50258\n",
      "The padding token <|pad|> has the id 50259\n"
     ]
    }
   ],
   "source": [
    "print(\"The max model length is {} for this model\".format(tokenizer.model_max_length))\n",
    "print(\"The end of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"The beginning of sequence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"The unknown token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.unk_token_id), tokenizer.unk_token_id))\n",
    "print(\"The padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "max_length = 180  # maximum sentence length\n",
    "\n",
    "# standard PyTorch approach of loading data in using a Dataset class.\n",
    "class RecipeDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.input_ids = []\n",
    "        self.attn_masks = []\n",
    "        self.origin_ingredients = []\n",
    "        self.origin_instructions = []\n",
    "\n",
    "        for recipe in data:\n",
    "            encodings = tokenizer.encode_plus(recipe,\n",
    "                                              truncation=True,\n",
    "                                              padding='max_length',\n",
    "                                              max_length=max_length,\n",
    "                                              return_tensors='pt'       # return PyTorch tensor\n",
    "                                             )\n",
    "            self.input_ids.append(torch.squeeze(encodings['input_ids'],0))\n",
    "            # attention_mask tells model not to incorporate these PAD tokens into its interpretation of the sentence\n",
    "            self.attn_masks.append(torch.squeeze(encodings['attention_mask'],0))\n",
    "            ingredients, instructions = extract_string(recipe)\n",
    "            self.origin_ingredients.append(ingredients)\n",
    "            self.origin_instructions.append(instructions)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx], self.origin_ingredients[idx], self.origin_instructions[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  900 training samples\n",
      "  100 validation samples\n"
     ]
    }
   ],
   "source": [
    "dataset = RecipeDataset(data, tokenizer)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 1000\n",
      "dataset[0]: \n",
      "  input_ids: tensor([50257, 41222,    25,  4171, 20853,    11, 19468,  4817,  7543,    11,\n",
      "        16858, 32132,    11, 18873, 13135,    13, 27759,    25,   309,   793,\n",
      "          362, 14180, 36322,   351,  7543,    13,  3914,  1302,   329,  4153,\n",
      "         2431,    11, 26547, 10491,    13, 20558,   275,  6996,    12,    82,\n",
      "        35652, 11710,   284,  2057, 12649,    13,  3060, 32132,   290,  1429,\n",
      "         1566,  7209,    13,   520,  3201,   832,  3734,   264, 12311,    13,\n",
      "        39128,   656, 16871,  3425,   357,   273,  4351,   284,  4771,  8566,\n",
      "        16009,   290,  1429,  1864,   284, 11372,     6, 11678,   737, 34917,\n",
      "        18838,  1566, 13015,   389,  4735,   475,  7372,   318,  2705,    13,\n",
      "          220, 20558,   284, 12649,   290, 13516,  1566,  7209,   757,    13,\n",
      "         8229,   284,  3425,   290, 16611,  1566, 13015,   389,  4735,    13,\n",
      "        20558,   284, 12649,   290, 13516,  1566,  7209,   757,    13, 39957,\n",
      "          287,  5637,   362, 14180,   286,  4171, 20853,    13, 39128,   656,\n",
      "         7309, 15936,   290, 16611, 13417,    13,  3914, 39536,  4622,   284,\n",
      "         4691,    13, 50256, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
      "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
      "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
      "        50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259])\n",
      "  attn_masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset size {dataset.__len__()}\")\n",
    "print(f\"dataset[0]: \\n  input_ids: {dataset[0][0]}\\n  attn_masks: {dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order.\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight shape torch.Size([50257, 1024])\n",
      "Number of tokens: 50260\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weight shape {model.transformer.wte.weight.shape}\")\n",
    "# this step is necessary because I've added some tokens (bos_token, etc.) to the embeddings\n",
    "# otherwise the tokenizer and model tensors won't match up\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"Number of tokens: {len(tokenizer)}\")\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50260, 1024])\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = model.transformer.wte.weight # Word Token Embeddings\n",
    "\n",
    "print(word_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "learning_rate = 2e-5\n",
    "warmup_steps = 1e2\n",
    "# The epsilon parameter eps = 1e-8 is “a very small number to prevent any division by zero in the implementation”\n",
    "epsilon = 1e-8\n",
    "# optim = Adam(model.parameters(), lr=5e-5)\n",
    "optim = AdamW(model.parameters(), lr = learning_rate, eps = epsilon)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training steps is [number of batches] x [number of epochs].\n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optim,\n",
    "                                            num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(prompt):\n",
    "    input = f\"<|startoftext|>Ingredients: {prompt.strip()}\"\n",
    "    input = tokenizer(input, return_tensors=\"pt\")\n",
    "    input_ids      = input[\"input_ids\"]\n",
    "    attention_mask = input[\"attention_mask\"]\n",
    "\n",
    "    output = model.generate(input_ids.to(device),\n",
    "                            attention_mask=attention_mask.to(device),\n",
    "                            max_new_tokens=max_length,\n",
    "                            # temperature = 0.5,\n",
    "                            do_sample = True, top_k = 50, top_p = 0.85)\n",
    "                            # num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "    output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    450. Loss: 3.32277774810791.   Elapsed: 0:00:28.\n",
      "Ingredients: eggs, flour, butter, sugar, cocoa powder, salt, pepper, nutmeg, eggs. Instructions:Put all ingredients in a bowl. Stir until well blended. Stir in lemon juice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of    450. Loss: 1.347068190574646.   Elapsed: 0:00:59.\n",
      "Ingredients: eggs, flour, butter, sugar, baking soda, eggs, margarine, lemon juice, salt, baking powder, salt, eggs, butter, vanilla extract. Instructions: In a large bowl, beat the egg whites with 1 cup sugar and beat the egg whites and butter until light and fluffy, and fluffy. Fold in flour and add to the dry ingredients. Stir until well blended and a thick dough is formed. Roll out dough into a tight ball and place on lightly floured surface. Use a 1 inch cookie cutter to cut out circles. Place in a greased 9 inch pie pan, pour about 1/4 cup of lemon juice over the dough and bake at 350 degrees for 35-40 minutes or until lightly browned and lightly toasted. Remove from oven and sprinkle with lemon slices. Enjoy!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   300  of    450. Loss: 1.3673527240753174.   Elapsed: 0:01:32.\n",
      "Ingredients: eggs, flour, butter, sugar, salt, cinnamon. Instructions: Combine flour and baking powder in a large bowl. Using an electric mixer, beat the eggs until fluffy. Add the remaining ingredients. Stir until well blended. Divide the batter evenly into prepared pans. Bake for 25 minutes, or until a toothpick inserted in the middle comes out clean. Allow to cool completely on wire racks before using.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   400  of    450. Loss: 2.4715497493743896.   Elapsed: 0:02:03.\n",
      "Ingredients: eggs, flour, butter, sugar, salt, vanilla extract, egg yolk, cinnamon, nutmeg. Instructions: In a medium-sized bowl, combine eggs, flour, butter, sugar, salt, vanilla extract and eggs. Add in eggs and mix until combined. Beat in remaining ingredients until well blended. Beat in nutmeg. Instructions: In a large bowl, mix all dry ingredients and stir into a lightly greased large bowl. Beat together with a wooden spoon until smooth. Roll out dough on a lightly floured surface, until 1/4 inch thick and 4 cm in diameter. Shape into 8 even rounds. Place on parchment paper lined baking sheets or greased cookie sheet and bake until golden brown and firm, about 25 minutes.\n",
      "\n",
      "  Average training loss: 4.50\n",
      "  Training epoch took: 0:02:21\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.87\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    450. Loss: 2.021016836166382.   Elapsed: 0:00:29.\n",
      "Ingredients: eggs, flour, butter, sugar, baking soda, salt, vanilla extract. Instructions: In a large bowl, whisk together eggs, flour, butter, sugar, baking soda, salt. In another large bowl, stir together baking soda, cinnamon and vanilla. In another large bowl, beat together butter and sugar until stiff peaks form, about 5 minutes. Add cinnamon, vanilla and beat until blended, about 1 minute more. In another large bowl, beat together flour, sugar, baking soda, vanilla and flour. Beat until stiff peaks form, about 5 minutes. Add eggs, one at a time, beat gently to incorporate and beat until combined, about 1 minute more. Divide batter evenly between greased cookie sheets and refrigerate for 1 hour. Bake cookies at 375 degrees for 20 to 25 minutes, or until edges are lightly browned.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of    450. Loss: 2.3956758975982666.   Elapsed: 0:01:03.\n",
      "Ingredients: eggs, flour, butter, sugar, salt, pepper, milk, milk, margarine, brown sugar, butter, butter, eggs, flour, vinegar, vanilla extract, flour, sugar, flour, egg yolks, milk, egg whites, cream, salt, cocoa powder, sugar, vanilla extract. Instructions: Combine flour and butter in a large bowl. Beat in eggs, milk,  margarine, brown sugar, butter, sugar,   flour and mix well. Beat in    eggs and  flour mixture until well blended. Stir in egg yolks,  margarine,  vinegar and vanilla. Pour in prepared batter into a well greased pan. Bake at 350 degrees Fahrenheit for 30-35 minutes. Sprinkle over tops of cakes,    top with candied  nuts,  candied orange, candied oranges, candy,  candies, chocolate chips,  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   300  of    450. Loss: 1.2305002212524414.   Elapsed: 0:01:37.\n",
      "Ingredients: eggs, flour, butter, sugar, vanilla extract, baking powder, baking soda. Instructions: Heat oven to 350 degrees F. Line 2 or 3 9 inch pie crusts with parchment paper or spray with nonstick spray.   Place the butter in a large bowl; add the sugar, vanilla and baking powder and stir until sugar has dissolved.   Add eggs, flour and butter; stir until smooth.  Spread over prepared pie crusts;  place over a lightly greased 9 inch pan and bake until edges are set, 25 to 30 minutes or until a toothpick inserted into center comes out clean.  Allow to cool slightly before cutting into 1/2 inch thick squares.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   400  of    450. Loss: 1.2030420303344727.   Elapsed: 0:02:08.\n",
      "Ingredients: eggs, flour, butter, sugar, milk, vanilla extract, sugar, salt, baking soda, baking powder, baking soda water. Instructions: Combine flour, butter, sugar and milk. Stir in vanilla extract. Gradually stir in sugar until well blended. Stir in baking soda and baking powder. Stir in   salt. Spread mixture evenly over muffin tins. Bake 20-30 minutes or until tops are golden brown. Top with icing sugar. Refrigerate until firm. Makes 6 cups of    cupcake.\n",
      "\n",
      "  Average training loss: 1.85\n",
      "  Training epoch took: 0:02:25\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.79\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    450. Loss: 2.4820361137390137.   Elapsed: 0:00:29.\n",
      "Ingredients: eggs, flour, butter, sugar, cocoa powder, baking powder. Instructions: Mix together all ingredients except for butter. Stir in eggs and stir. Stir in cocoa powder, sugar, and baking powder. Spread on greased cookie sheets and bake in preheated 425°F oven for 25 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   200  of    450. Loss: 2.396599531173706.   Elapsed: 0:00:59.\n",
      "Ingredients: eggs, flour, butter, sugar, salt, salt, sugar, water, water, egg yolks. Instructions:    Mix the dry ingredients in a bowl. Add the eggs,  flour, butter and sugar.  Mix well. Add the salt and water and mix well.  Gradually add the flour until all the flour is used.  Mix all of the dry ingredients together until  it forms a ball.  Roll out to about 1/2 cm thick. Roll the dough to about 1/2  cm thick.  Brush each  dough circle with  beaten egg white, and sprinkle with sugar.  Bake in a preheated oven at 350 degrees for 35 minutes.     To serve:  Place  the  dough on a greased pie plate and brush with  beaten egg whites.  Cut up the dough and sprinkle with a little sugar.  Brush each with \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   300  of    450. Loss: 2.077214002609253.   Elapsed: 0:01:34.\n",
      "Ingredients: eggs, flour, butter, sugar, brown sugar, brown sugar, salt, vanilla extract, vanilla. Instructions: Combine eggs, flour, butter, and sugar in a large bowl. Add the brown sugar and salt to combine; whisk until smooth. Add the vanilla extract, and stir well. Pour into a greased 10 inch pie pan. Bake at 350°F for 30 to 35 minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   400  of    450. Loss: 0.8129180669784546.   Elapsed: 0:02:05.\n",
      "Ingredients: eggs, flour, butter, sugar, eggs, margarine, milk, margarine, vanilla extract, cinnamon, nutmeg, salt. Instructions: Place the flour in a food processor. Process until a fine flour is formed. Add butter, sugar and eggs. Process until the mixture is creamy and well blended. Add remaining ingredients, mixture should be dry enough to handle. Add a little salt. Fold in the margarine and vanilla. Make a well in the centre of the mixture. Drop into the well. Pour in the hot milk and let stand for a while. Cover with plastic wrap and freeze overnight. Invert onto a parchment paper and let rise another 15 minutes. In a food processor, combine the eggs, margarine and vanilla until combined. Beat well. Add the milk and margarine mixture to the mixture. Fold in the cinnamon, nutmeg and salt.\n",
      "\n",
      "  Average training loss: 1.78\n",
      "  Training epoch took: 0:02:24\n",
      "\n",
      "Running Validation...\n",
      "  Validation Loss: 1.76\n",
      "  Validation took: 0:00:05\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:07:24 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "total_t0 = time.time()\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()  # `train` just changes the *mode* (train vs. eval), it doesn't *perform* the training.\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):     # step from enumerate() = number of batches\n",
    "\n",
    "        b_input_ids = batch[0].to(device)   # tokens (of multiple documents in a batch)\n",
    "        b_labels    = batch[0].to(device)\n",
    "        b_masks     = batch[1].to(device)   # mask of [1] for a real word, [0] for a pad\n",
    "\n",
    "        model.zero_grad()\n",
    "        # loss = model(X.to(device), attention_mask=a.to(device), labels=X.to(device)).loss\n",
    "        outputs = model(  input_ids = b_input_ids,\n",
    "                          labels = b_labels,\n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids = None\n",
    "                        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        # Get sample every x batches.\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            sample_output = infer(\"eggs, flour, butter, sugar\")\n",
    "            print(sample_output)\n",
    "\n",
    "            # `train` just changes the *mode* (train vs. eval), it doesn't *perform* the training.\n",
    "            model.train()\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs  = model(input_ids = b_input_ids,\n",
    "                             attention_mask = b_masks,\n",
    "                             labels = b_labels)\n",
    "\n",
    "            loss = outputs[0]\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.496187</td>\n",
       "      <td>1.870418</td>\n",
       "      <td>0:02:21</td>\n",
       "      <td>0:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.846435</td>\n",
       "      <td>1.785793</td>\n",
       "      <td>0:02:25</td>\n",
       "      <td>0:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.781866</td>\n",
       "      <td>1.764926</td>\n",
       "      <td>0:02:24</td>\n",
       "      <td>0:00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss Training Time Validation Time\n",
       "epoch                                                          \n",
       "1           4.496187     1.870418       0:02:21         0:00:05\n",
       "2           1.846435     1.785793       0:02:25         0:00:05\n",
       "3           1.781866     1.764926       0:02:24         0:00:05"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame from our training statistics.\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Use the 'epoch' as the row index.\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model\\\\tokenizer_config.json',\n",
       " './model\\\\special_tokens_map.json',\n",
       " './model\\\\vocab.json',\n",
       " './model\\\\merges.txt',\n",
       " './model\\\\added_tokens.json',\n",
       " './model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = './model'\n",
    "\n",
    "print(\"Saving model to %s\" % model_save_path)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "# model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50260, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=3072, nx=1024)\n",
       "          (c_proj): Conv1D(nf=1024, nx=1024)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=4096, nx=1024)\n",
       "          (c_proj): Conv1D(nf=1024, nx=4096)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50260, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(model_save_path)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_save_path)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients: eggs, mushroom, butter, sugar, brown sugar, flour, baking powder, butter, eggs, milk. Instructions: Heat the butter in a medium saucepan over a moderate heat. Add the mushrooms, fry in the butter for about 5 minutes or until softened and translucent. Stir in the sugar, flour, baking powder and salt. Let the mixture cook slowly stirring occasionally until the mixture comes to a boil. Reduce the heat and simmer over low heat for about 3 hours or until the mixture has thickened. Remove from heat and reserve 2 cups of the butter to use in the next recipe.\n"
     ]
    }
   ],
   "source": [
    "# model = GPT2LMHeadModel.from_pretrained(model_save_path)\n",
    "# tokenizer = GPT2TokenizerFast.from_pretrained(model_save_path)\n",
    "# model.to(device)\n",
    "print(infer(\"eggs, mushroom, butter, sugar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ingredients: onion, garlic, chicken breast, onions, salt, pepper, garlic powder, butter, lemon juice, green onion, chicken breast, fresh basil. Instructions: In a heavy bottomed   ovenproof  saucepan, heat 1 cup of  the oil to 350 degrees. Add onion and saute over medium heat for 3-4 minutes, stirring occasionally. Add garlic and cook 3 minutes, turning, stirring occasionally. Add chicken and  add 2 cups  boiling water. Bring to a boil and reduce heat to simmer. Cook chicken uncovered  until juices run clear, about 2 minutes. Remove chicken from heat and return to  boiling water.  Remove the skin and shred with a fork; add to saucepan. Bring to a boil, stirring frequently, and cook  for 3 minutes. Remove chicken, skin and shreds.  Transfer chicken to a medium  bowl, add the basil and  stir to combine.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer(\"onion, garlic, chicken breast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients: avocado, lime, cilantro, lime juice, salt, pepper, sour cream, chicken broth, fresh cilantro, red wine vinegar, lemon juice, fresh cilantro, lime juice, fresh parsley, fresh cilantro, fresh cilantro, fresh basil, sour cream, sour cream, olive oil, cornstarch, cheddar cheese, brown rice, sour cream, mayonnaise. Instructions: Cut avocado into slices, dice and place slices on a baking sheet. Set aside. Drain avocado slices and rinse under cool water. Combine avocado slices and cilantro, lime juice, salt, pepper and sour cream in a saucepan. Bring to a boil over medium heat, stirring constantly.  Pour in broth, simmer 5 minutes. Stir in the cilantro, lime juice and vinegar, and bring to a boil. Reduce heat and simmer 10 minutes longer. Stir in the remaining broth. Add cheddar\n"
     ]
    }
   ],
   "source": [
    "print(infer(\"avocado, lime\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingredients: beef, salt, pepper, curry powder, lime juice, tomato paste, water, cayenne pepper, coconut milk. Instructions: In a large saucepan, bring beef to a boil. Cook until browned. Drain and let cool. Blend coconut milk with beef and salt. Heat mixture until hot but not thickening, stirring constantly. Add coconut and tomato paste, and stir well. Return to saucepan. Cook for 20 minutes. Remove from heat, stir in cayenne pepper, and stir until sauce is thick. Add cooked beef and coconut milk mixture. Bring to a boil over medium heat. Simmer stirring constantly until the coconut mixture has been thickened. Remove from heat and pour into cooled saucepan. Pour remaining coconut milk into a bowl. Heat over medium heat until mixture boils. Remove from heat. Spoon mixture into prepared baking dish. Bake in preheated oven at 400 degrees Fahrenheit for 20\n"
     ]
    }
   ],
   "source": [
    "print(infer(\"beef, salt, pepper\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "d:\\Python\\LLM_Environment\\myenv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "d:\\Python\\LLM_Environment\\myenv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "d:\\Python\\LLM_Environment\\myenv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.112175060372617e-232\n"
     ]
    }
   ],
   "source": [
    "# Using BLEU score to compare the real sentences with the generated ones\n",
    "\n",
    "scores=[]\n",
    "\n",
    "for i in range(10):\n",
    "    ingredients = val_dataset[i][2]\n",
    "    reference = val_dataset[i][3]\n",
    "    candidate = infer(ingredients)\n",
    "    scores.append(sentence_bleu(reference, candidate))\n",
    "\n",
    "print(statistics.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
